{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Modeling using Transformer\n",
        " The Transformer is a deep learning model introduced in the paper \"Attention is All You Need\" by Vaswani et al. It's particularly renowned for its effectiveness in natural language processing (NLP) tasks, including language translation, text generation, and language understanding."
      ],
      "metadata": {
        "id": "PVJpvPqWxtTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we are going to demonstrate the highlevel implementation of transformer by applying it in language modeling that is predicting next word in a sequence."
      ],
      "metadata": {
        "id": "d64t2V_Zy8Ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Imports\n",
        "Let's first imports all the libraries that will be required through out this notebook."
      ],
      "metadata": {
        "id": "h5w47_cCzaUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "import os\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import nn, Tensor\n",
        "from tempfile import TemporaryDirectory\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset"
      ],
      "metadata": {
        "id": "c0SKh5Txy46Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the dataset\n",
        "For language modeling, we are going to use Wikitext-2 dataset. We gonna access this dataset using `torchtext`."
      ],
      "metadata": {
        "id": "F-oyXL5q0zwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker\n",
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe5xvEhE0q5t",
        "outputId": "d6869ace-2ad3-4d60-c816-73fd3da877bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "h7nNEm8K1P8D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "id": "MYXTZvMr1kRO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that can convert a raw text into a flat tensor"
      ],
      "metadata": {
        "id": "myod8BU12D_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))"
      ],
      "metadata": {
        "id": "Oti_GzKv1siQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)"
      ],
      "metadata": {
        "id": "4o-doS3i2VK1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(val_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ca_gR12V7S",
        "outputId": "90143829-1eb0-4532-e47a-a80a13302150"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2049990])\n",
            "torch.Size([214417])\n",
            "torch.Size([241859])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkgSi2MK7NTe",
        "outputId": "d1c62457-7894-40d7-e7f6-c61fabaeb0b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   9, 3849, 3869,  ..., 2442, 4810,    3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "MZVW9OkH3oPo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's batch the data. Given a 1-D vector of sequential data, batchify() arranges the data into batch_size columns. If the data does not divide evenly into batch_size columns, then the data is trimmed to fit. For instance, with the alphabet as the data (total length of 26) and batch_size=4, we would divide the alphabet into sequences of length 6, resulting in 4 of such sequences.\n",
        "\n",
        "![Screenshot from 07-02-24 15:07:12](https://github.com/surajkarki66/Generative_AI_for_NLP/assets/50628520/3d26d44c-d63e-49f9-89b8-2dbe80e31b1a)\n",
        "\n",
        "Batching enables more parallelizable processing. However, batching means that the model treats each column independently; for example, the dependence of G and F can not be learned in the example above.\n",
        "\n"
      ],
      "metadata": {
        "id": "kQLACWeL32HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Arguments:\n",
        "        data: Tensor, shape ``[N]``\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape ``[N // bsz, bsz]``\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)"
      ],
      "metadata": {
        "id": "jxzoYqv93zyt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ],
      "metadata": {
        "id": "9cmbLfBg6Xp3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufVAGkm269x4",
        "outputId": "7fe3f5e0-169a-4c4c-843f-5393d4d9c8e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    9,    59,   564,  ..., 11652,  2435,     1],\n",
            "        [ 3849,    12,   300,  ...,    47,    30,  1990],\n",
            "        [ 3869,   315,    19,  ...,    97,  7720,     4],\n",
            "        ...,\n",
            "        [  587,  4011,    59,  ...,     1,  1439, 12313],\n",
            "        [ 4987,    29,     4,  ...,  3165, 17106,  2060],\n",
            "        [    6,     8,     1,  ...,    62,    18,     2]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfY-tINJ6_H7",
        "outputId": "1ed4a2c3-33a6-470c-c426-643e118d64ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([102499, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxa47ETj7CiX",
        "outputId": "047eec04-a780-42a0-b71c-ad0097f1c7b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    9,    59,   564,   223,   443, 13627,     2,   539,  2872,  2464,\n",
            "            0,   313,  4513,     1,     5,    47,    66, 11652,  2435,     1],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build functions to generate input and target sequence\n",
        "![Image](https://pytorch.org/tutorials/_images/transformer_input_target.png)"
      ],
      "metadata": {
        "id": "Sfkq4QEx8d27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bptt = 35\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
        "        i: int\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
        "        target has shape ``[seq_len * batch_size]``\n",
        "    \"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target"
      ],
      "metadata": {
        "id": "9HGYEJNM7-_Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model Building\n",
        "The famous architecure is given by the following figure.\n",
        "\n",
        "![image](https://pytorch.org/tutorials/_images/transformer_architecture.jpg)\n",
        "\n",
        "This is the high level implementation of a Transformer model, we are not going to build transformer from scratch. We train a `nn.TransformerEncoder` model on a causal language modeling task.\n",
        "\n",
        "Remember this notebook does not cover the training of `nn.TransformerDecoder`, as depicted in the right half of the diagram above. The language modeling task is to assign a probability for the likelihood of a given word (or a sequence of words) to follow a sequence of words.\n"
      ],
      "metadata": {
        "id": "_b8rP8um9KHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**General Idea**\n",
        "1. First, A sequence of tokens are passed to the embedding layer first, followed by a positional encoding layer to account for the order of the word.\n",
        "2. The `nn.TransformerEncoder` is made up of multiple layers of `nn.TransformerEncoderLayer`. Each layer helps the model understand the input data better.\n",
        "3.When using TransformerDecoder (another part of the Transformer model), it's important to prevent it from looking at future words in the sequence during training. So, we need a special mask (like a filter) to block out any information from future positions.\n",
        "4. In tasks like language modeling, where we predict the next word in a sentence, we want to make sure the model can't cheat by looking ahead. So, we mask out any words that come after the current word we're predicting by using attention mask.\n",
        "5. After the input sequence goes through the TransformerEncoder, we pass it through a linear layer. This layer helps convert the encoded information into predictions for the next word.\n",
        "6. The output of the linear layer gives us unnormalized scores, also called logits. These scores indicate how likely each word in the vocabulary is to be the next word in the sequence."
      ],
      "metadata": {
        "id": "oJJ6jrCv-lze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.embedding = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.linear = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.linear.bias.data.zero_()\n",
        "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            src: Tensor, shape ``[seq_len, batch_size]``\n",
        "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
        "        \"\"\"\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        if src_mask is None:\n",
        "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "            \"\"\"\n",
        "            src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.linear(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "KuNJdvlM9F6X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PositionalEncoding module injects some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension as the embeddings so that the two can be summed. Here, we use sine and cosine functions of different frequencies."
      ],
      "metadata": {
        "id": "zDCDKp9zBkZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "My86Mbo8Bjvs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Setup Model's Parameters and Hyper Parameters"
      ],
      "metadata": {
        "id": "ArPUps_UCJgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2  # number of nn.TransformerEncoderLayer  in nn.TransformerEncoder\n",
        "nhead = 2  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ],
      "metadata": {
        "id": "eBW9LGd-CCFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9424b0-4e47-4a0b-a485-31ed6ae9afec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train the model\n",
        "We use CrossEntropyLoss with the SGD (stochastic gradient descent) optimizer. The learning rate is initially set to 0.1 and follows a StepLR schedule. During training, we use nn.utils.clip_grad_norm_ to prevent gradients from exploding."
      ],
      "metadata": {
        "id": "hmDgNRjOC5vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.1  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        output = model(data)\n",
        "        output_flat = output.view(-1, ntokens)\n",
        "        loss = criterion(output_flat, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            seq_len = data.size(0)\n",
        "            output = model(data)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ],
      "metadata": {
        "id": "Ocenu6aZDBP3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 90\n",
        "\n",
        "with TemporaryDirectory() as tempdir:\n",
        "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start_time = time.time()\n",
        "        train(model)\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        val_ppl = math.exp(val_loss)\n",
        "        elapsed = time.time() - epoch_start_time\n",
        "        print('-' * 89)\n",
        "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "        print('-' * 89)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsU3hOtXDepv",
        "outputId": "a888f77a-7e0b-47b7-b479-5ca7e8ca0635"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 0.10 | ms/batch 13.84 | loss  6.52 | ppl   676.86\n",
            "| epoch   1 |   400/ 2928 batches | lr 0.10 | ms/batch 13.54 | loss  6.51 | ppl   674.43\n",
            "| epoch   1 |   600/ 2928 batches | lr 0.10 | ms/batch 13.54 | loss  6.47 | ppl   643.14\n",
            "| epoch   1 |   800/ 2928 batches | lr 0.10 | ms/batch 13.95 | loss  6.50 | ppl   662.95\n",
            "| epoch   1 |  1000/ 2928 batches | lr 0.10 | ms/batch 13.60 | loss  6.46 | ppl   637.95\n",
            "| epoch   1 |  1200/ 2928 batches | lr 0.10 | ms/batch 13.68 | loss  6.49 | ppl   657.44\n",
            "| epoch   1 |  1400/ 2928 batches | lr 0.10 | ms/batch 13.72 | loss  6.45 | ppl   635.84\n",
            "| epoch   1 |  1600/ 2928 batches | lr 0.10 | ms/batch 14.07 | loss  6.47 | ppl   643.00\n",
            "| epoch   1 |  1800/ 2928 batches | lr 0.10 | ms/batch 14.12 | loss  6.43 | ppl   617.98\n",
            "| epoch   1 |  2000/ 2928 batches | lr 0.10 | ms/batch 13.84 | loss  6.44 | ppl   626.46\n",
            "| epoch   1 |  2200/ 2928 batches | lr 0.10 | ms/batch 13.91 | loss  6.35 | ppl   573.92\n",
            "| epoch   1 |  2400/ 2928 batches | lr 0.10 | ms/batch 15.66 | loss  6.40 | ppl   601.24\n",
            "| epoch   1 |  2600/ 2928 batches | lr 0.10 | ms/batch 15.65 | loss  6.38 | ppl   589.05\n",
            "| epoch   1 |  2800/ 2928 batches | lr 0.10 | ms/batch 14.04 | loss  6.35 | ppl   572.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 43.25s | valid loss  6.12 | valid ppl   455.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 0.10 | ms/batch 17.13 | loss  6.35 | ppl   575.23\n",
            "| epoch   2 |   400/ 2928 batches | lr 0.10 | ms/batch 15.14 | loss  6.35 | ppl   573.49\n",
            "| epoch   2 |   600/ 2928 batches | lr 0.10 | ms/batch 14.55 | loss  6.28 | ppl   535.00\n",
            "| epoch   2 |   800/ 2928 batches | lr 0.10 | ms/batch 14.27 | loss  6.33 | ppl   560.87\n",
            "| epoch   2 |  1000/ 2928 batches | lr 0.10 | ms/batch 14.37 | loss  6.28 | ppl   535.79\n",
            "| epoch   2 |  1200/ 2928 batches | lr 0.10 | ms/batch 14.21 | loss  6.33 | ppl   561.10\n",
            "| epoch   2 |  1400/ 2928 batches | lr 0.10 | ms/batch 14.08 | loss  6.31 | ppl   547.96\n",
            "| epoch   2 |  1600/ 2928 batches | lr 0.10 | ms/batch 14.34 | loss  6.33 | ppl   558.49\n",
            "| epoch   2 |  1800/ 2928 batches | lr 0.10 | ms/batch 14.61 | loss  6.28 | ppl   535.63\n",
            "| epoch   2 |  2000/ 2928 batches | lr 0.10 | ms/batch 16.05 | loss  6.31 | ppl   547.63\n",
            "| epoch   2 |  2200/ 2928 batches | lr 0.10 | ms/batch 13.96 | loss  6.21 | ppl   498.60\n",
            "| epoch   2 |  2400/ 2928 batches | lr 0.10 | ms/batch 13.94 | loss  6.27 | ppl   527.26\n",
            "| epoch   2 |  2600/ 2928 batches | lr 0.10 | ms/batch 16.30 | loss  6.25 | ppl   520.20\n",
            "| epoch   2 |  2800/ 2928 batches | lr 0.10 | ms/batch 14.79 | loss  6.22 | ppl   504.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 45.12s | valid loss  6.01 | valid ppl   406.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 0.09 | ms/batch 13.88 | loss  6.25 | ppl   516.37\n",
            "| epoch   3 |   400/ 2928 batches | lr 0.09 | ms/batch 14.08 | loss  6.25 | ppl   516.84\n",
            "| epoch   3 |   600/ 2928 batches | lr 0.09 | ms/batch 14.06 | loss  6.17 | ppl   478.49\n",
            "| epoch   3 |   800/ 2928 batches | lr 0.09 | ms/batch 13.89 | loss  6.23 | ppl   505.23\n",
            "| epoch   3 |  1000/ 2928 batches | lr 0.09 | ms/batch 13.91 | loss  6.17 | ppl   479.71\n",
            "| epoch   3 |  1200/ 2928 batches | lr 0.09 | ms/batch 13.97 | loss  6.23 | ppl   506.84\n",
            "| epoch   3 |  1400/ 2928 batches | lr 0.09 | ms/batch 14.18 | loss  6.21 | ppl   495.27\n",
            "| epoch   3 |  1600/ 2928 batches | lr 0.09 | ms/batch 13.92 | loss  6.23 | ppl   507.58\n",
            "| epoch   3 |  1800/ 2928 batches | lr 0.09 | ms/batch 13.95 | loss  6.19 | ppl   485.69\n",
            "| epoch   3 |  2000/ 2928 batches | lr 0.09 | ms/batch 13.91 | loss  6.21 | ppl   498.87\n",
            "| epoch   3 |  2200/ 2928 batches | lr 0.09 | ms/batch 15.31 | loss  6.11 | ppl   452.59\n",
            "| epoch   3 |  2400/ 2928 batches | lr 0.09 | ms/batch 14.00 | loss  6.18 | ppl   482.80\n",
            "| epoch   3 |  2600/ 2928 batches | lr 0.09 | ms/batch 13.98 | loss  6.17 | ppl   478.28\n",
            "| epoch   3 |  2800/ 2928 batches | lr 0.09 | ms/batch 14.02 | loss  6.13 | ppl   461.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 43.20s | valid loss  5.93 | valid ppl   376.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |   200/ 2928 batches | lr 0.09 | ms/batch 14.09 | loss  6.17 | ppl   476.11\n",
            "| epoch   4 |   400/ 2928 batches | lr 0.09 | ms/batch 14.09 | loss  6.17 | ppl   479.68\n",
            "| epoch   4 |   600/ 2928 batches | lr 0.09 | ms/batch 14.07 | loss  6.09 | ppl   440.43\n",
            "| epoch   4 |   800/ 2928 batches | lr 0.09 | ms/batch 14.41 | loss  6.15 | ppl   467.17\n",
            "| epoch   4 |  1000/ 2928 batches | lr 0.09 | ms/batch 14.02 | loss  6.09 | ppl   442.16\n",
            "| epoch   4 |  1200/ 2928 batches | lr 0.09 | ms/batch 14.00 | loss  6.15 | ppl   468.70\n",
            "| epoch   4 |  1400/ 2928 batches | lr 0.09 | ms/batch 14.01 | loss  6.13 | ppl   460.46\n",
            "| epoch   4 |  1600/ 2928 batches | lr 0.09 | ms/batch 15.41 | loss  6.16 | ppl   473.42\n",
            "| epoch   4 |  1800/ 2928 batches | lr 0.09 | ms/batch 14.00 | loss  6.11 | ppl   450.06\n",
            "| epoch   4 |  2000/ 2928 batches | lr 0.09 | ms/batch 13.92 | loss  6.14 | ppl   464.46\n",
            "| epoch   4 |  2200/ 2928 batches | lr 0.09 | ms/batch 13.95 | loss  6.04 | ppl   420.20\n",
            "| epoch   4 |  2400/ 2928 batches | lr 0.09 | ms/batch 14.20 | loss  6.11 | ppl   450.69\n",
            "| epoch   4 |  2600/ 2928 batches | lr 0.09 | ms/batch 14.02 | loss  6.11 | ppl   448.44\n",
            "| epoch   4 |  2800/ 2928 batches | lr 0.09 | ms/batch 14.32 | loss  6.07 | ppl   430.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 43.29s | valid loss  5.87 | valid ppl   354.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |   200/ 2928 batches | lr 0.08 | ms/batch 14.32 | loss  6.10 | ppl   446.26\n",
            "| epoch   5 |   400/ 2928 batches | lr 0.08 | ms/batch 14.68 | loss  6.11 | ppl   450.84\n",
            "| epoch   5 |   600/ 2928 batches | lr 0.08 | ms/batch 14.00 | loss  6.02 | ppl   412.63\n",
            "| epoch   5 |   800/ 2928 batches | lr 0.08 | ms/batch 13.93 | loss  6.08 | ppl   438.39\n",
            "| epoch   5 |  1000/ 2928 batches | lr 0.08 | ms/batch 14.18 | loss  6.03 | ppl   414.87\n",
            "| epoch   5 |  1200/ 2928 batches | lr 0.08 | ms/batch 14.06 | loss  6.09 | ppl   440.31\n",
            "| epoch   5 |  1400/ 2928 batches | lr 0.08 | ms/batch 13.99 | loss  6.07 | ppl   433.40\n",
            "| epoch   5 |  1600/ 2928 batches | lr 0.08 | ms/batch 13.98 | loss  6.10 | ppl   447.20\n",
            "| epoch   5 |  1800/ 2928 batches | lr 0.08 | ms/batch 14.10 | loss  6.05 | ppl   424.07\n",
            "| epoch   5 |  2000/ 2928 batches | lr 0.08 | ms/batch 14.16 | loss  6.08 | ppl   438.27\n",
            "| epoch   5 |  2200/ 2928 batches | lr 0.08 | ms/batch 14.01 | loss  5.98 | ppl   396.00\n",
            "| epoch   5 |  2400/ 2928 batches | lr 0.08 | ms/batch 13.96 | loss  6.05 | ppl   425.97\n",
            "| epoch   5 |  2600/ 2928 batches | lr 0.08 | ms/batch 14.03 | loss  6.05 | ppl   425.33\n",
            "| epoch   5 |  2800/ 2928 batches | lr 0.08 | ms/batch 14.24 | loss  6.01 | ppl   408.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 43.13s | valid loss  5.82 | valid ppl   337.67\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |   200/ 2928 batches | lr 0.08 | ms/batch 14.00 | loss  6.05 | ppl   423.05\n",
            "| epoch   6 |   400/ 2928 batches | lr 0.08 | ms/batch 14.09 | loss  6.07 | ppl   430.56\n",
            "| epoch   6 |   600/ 2928 batches | lr 0.08 | ms/batch 14.19 | loss  5.97 | ppl   391.96\n",
            "| epoch   6 |   800/ 2928 batches | lr 0.08 | ms/batch 14.00 | loss  6.03 | ppl   416.13\n",
            "| epoch   6 |  1000/ 2928 batches | lr 0.08 | ms/batch 14.06 | loss  5.97 | ppl   392.85\n",
            "| epoch   6 |  1200/ 2928 batches | lr 0.08 | ms/batch 14.30 | loss  6.04 | ppl   417.95\n",
            "| epoch   6 |  1400/ 2928 batches | lr 0.08 | ms/batch 16.87 | loss  6.02 | ppl   411.89\n",
            "| epoch   6 |  1600/ 2928 batches | lr 0.08 | ms/batch 14.83 | loss  6.05 | ppl   424.93\n",
            "| epoch   6 |  1800/ 2928 batches | lr 0.08 | ms/batch 14.05 | loss  6.00 | ppl   404.44\n",
            "| epoch   6 |  2000/ 2928 batches | lr 0.08 | ms/batch 14.18 | loss  6.04 | ppl   418.70\n",
            "| epoch   6 |  2200/ 2928 batches | lr 0.08 | ms/batch 15.89 | loss  5.93 | ppl   376.71\n",
            "| epoch   6 |  2400/ 2928 batches | lr 0.08 | ms/batch 15.65 | loss  6.01 | ppl   406.76\n",
            "| epoch   6 |  2600/ 2928 batches | lr 0.08 | ms/batch 14.65 | loss  6.01 | ppl   406.04\n",
            "| epoch   6 |  2800/ 2928 batches | lr 0.08 | ms/batch 14.84 | loss  5.96 | ppl   389.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 45.38s | valid loss  5.78 | valid ppl   324.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |   200/ 2928 batches | lr 0.07 | ms/batch 15.11 | loss  6.00 | ppl   405.03\n",
            "| epoch   7 |   400/ 2928 batches | lr 0.07 | ms/batch 14.33 | loss  6.02 | ppl   412.60\n",
            "| epoch   7 |   600/ 2928 batches | lr 0.07 | ms/batch 15.17 | loss  5.93 | ppl   375.32\n",
            "| epoch   7 |   800/ 2928 batches | lr 0.07 | ms/batch 14.49 | loss  5.99 | ppl   397.65\n",
            "| epoch   7 |  1000/ 2928 batches | lr 0.07 | ms/batch 14.37 | loss  5.93 | ppl   376.42\n",
            "| epoch   7 |  1200/ 2928 batches | lr 0.07 | ms/batch 14.15 | loss  5.99 | ppl   399.72\n",
            "| epoch   7 |  1400/ 2928 batches | lr 0.07 | ms/batch 15.04 | loss  5.98 | ppl   395.14\n",
            "| epoch   7 |  1600/ 2928 batches | lr 0.07 | ms/batch 14.52 | loss  6.01 | ppl   408.58\n",
            "| epoch   7 |  1800/ 2928 batches | lr 0.07 | ms/batch 14.24 | loss  5.96 | ppl   388.68\n",
            "| epoch   7 |  2000/ 2928 batches | lr 0.07 | ms/batch 14.26 | loss  6.00 | ppl   401.66\n",
            "| epoch   7 |  2200/ 2928 batches | lr 0.07 | ms/batch 14.61 | loss  5.89 | ppl   360.93\n",
            "| epoch   7 |  2400/ 2928 batches | lr 0.07 | ms/batch 14.24 | loss  5.97 | ppl   389.96\n",
            "| epoch   7 |  2600/ 2928 batches | lr 0.07 | ms/batch 14.05 | loss  5.97 | ppl   391.59\n",
            "| epoch   7 |  2800/ 2928 batches | lr 0.07 | ms/batch 14.38 | loss  5.93 | ppl   374.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 44.33s | valid loss  5.75 | valid ppl   314.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |   200/ 2928 batches | lr 0.07 | ms/batch 14.69 | loss  5.97 | ppl   390.43\n",
            "| epoch   8 |   400/ 2928 batches | lr 0.07 | ms/batch 14.30 | loss  5.99 | ppl   397.70\n",
            "| epoch   8 |   600/ 2928 batches | lr 0.07 | ms/batch 14.28 | loss  5.89 | ppl   359.94\n",
            "| epoch   8 |   800/ 2928 batches | lr 0.07 | ms/batch 14.76 | loss  5.95 | ppl   383.86\n",
            "| epoch   8 |  1000/ 2928 batches | lr 0.07 | ms/batch 14.62 | loss  5.89 | ppl   361.74\n",
            "| epoch   8 |  1200/ 2928 batches | lr 0.07 | ms/batch 14.22 | loss  5.95 | ppl   385.12\n",
            "| epoch   8 |  1400/ 2928 batches | lr 0.07 | ms/batch 14.18 | loss  5.94 | ppl   380.58\n",
            "| epoch   8 |  1600/ 2928 batches | lr 0.07 | ms/batch 14.32 | loss  5.98 | ppl   394.88\n",
            "| epoch   8 |  1800/ 2928 batches | lr 0.07 | ms/batch 14.94 | loss  5.93 | ppl   375.25\n",
            "| epoch   8 |  2000/ 2928 batches | lr 0.07 | ms/batch 14.20 | loss  5.96 | ppl   387.68\n",
            "| epoch   8 |  2200/ 2928 batches | lr 0.07 | ms/batch 14.29 | loss  5.85 | ppl   347.63\n",
            "| epoch   8 |  2400/ 2928 batches | lr 0.07 | ms/batch 14.14 | loss  5.93 | ppl   377.30\n",
            "| epoch   8 |  2600/ 2928 batches | lr 0.07 | ms/batch 14.95 | loss  5.94 | ppl   378.56\n",
            "| epoch   8 |  2800/ 2928 batches | lr 0.07 | ms/batch 14.14 | loss  5.89 | ppl   361.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 44.06s | valid loss  5.72 | valid ppl   305.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |   200/ 2928 batches | lr 0.07 | ms/batch 14.07 | loss  5.93 | ppl   377.73\n",
            "| epoch   9 |   400/ 2928 batches | lr 0.07 | ms/batch 14.23 | loss  5.96 | ppl   385.83\n",
            "| epoch   9 |   600/ 2928 batches | lr 0.07 | ms/batch 13.92 | loss  5.85 | ppl   348.41\n",
            "| epoch   9 |   800/ 2928 batches | lr 0.07 | ms/batch 13.95 | loss  5.92 | ppl   371.31\n",
            "| epoch   9 |  1000/ 2928 batches | lr 0.07 | ms/batch 14.30 | loss  5.86 | ppl   350.17\n",
            "| epoch   9 |  1200/ 2928 batches | lr 0.07 | ms/batch 14.33 | loss  5.92 | ppl   372.24\n",
            "| epoch   9 |  1400/ 2928 batches | lr 0.07 | ms/batch 13.94 | loss  5.91 | ppl   368.81\n",
            "| epoch   9 |  1600/ 2928 batches | lr 0.07 | ms/batch 14.03 | loss  5.95 | ppl   383.05\n",
            "| epoch   9 |  1800/ 2928 batches | lr 0.07 | ms/batch 13.97 | loss  5.90 | ppl   363.42\n",
            "| epoch   9 |  2000/ 2928 batches | lr 0.07 | ms/batch 14.29 | loss  5.93 | ppl   375.86\n",
            "| epoch   9 |  2200/ 2928 batches | lr 0.07 | ms/batch 13.94 | loss  5.82 | ppl   336.53\n",
            "| epoch   9 |  2400/ 2928 batches | lr 0.07 | ms/batch 13.97 | loss  5.90 | ppl   365.13\n",
            "| epoch   9 |  2600/ 2928 batches | lr 0.07 | ms/batch 13.96 | loss  5.91 | ppl   367.35\n",
            "| epoch   9 |  2800/ 2928 batches | lr 0.07 | ms/batch 14.22 | loss  5.86 | ppl   350.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 43.02s | valid loss  5.70 | valid ppl   298.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |   200/ 2928 batches | lr 0.06 | ms/batch 13.99 | loss  5.91 | ppl   367.05\n",
            "| epoch  10 |   400/ 2928 batches | lr 0.06 | ms/batch 13.98 | loss  5.93 | ppl   375.73\n",
            "| epoch  10 |   600/ 2928 batches | lr 0.06 | ms/batch 14.29 | loss  5.82 | ppl   338.19\n",
            "| epoch  10 |   800/ 2928 batches | lr 0.06 | ms/batch 13.98 | loss  5.89 | ppl   359.95\n",
            "| epoch  10 |  1000/ 2928 batches | lr 0.06 | ms/batch 13.96 | loss  5.83 | ppl   339.57\n",
            "| epoch  10 |  1200/ 2928 batches | lr 0.06 | ms/batch 13.97 | loss  5.89 | ppl   361.38\n",
            "| epoch  10 |  1400/ 2928 batches | lr 0.06 | ms/batch 14.16 | loss  5.88 | ppl   359.00\n",
            "| epoch  10 |  1600/ 2928 batches | lr 0.06 | ms/batch 14.08 | loss  5.92 | ppl   372.09\n",
            "| epoch  10 |  1800/ 2928 batches | lr 0.06 | ms/batch 13.95 | loss  5.87 | ppl   354.25\n",
            "| epoch  10 |  2000/ 2928 batches | lr 0.06 | ms/batch 13.95 | loss  5.90 | ppl   366.37\n",
            "| epoch  10 |  2200/ 2928 batches | lr 0.06 | ms/batch 14.02 | loss  5.79 | ppl   326.73\n",
            "| epoch  10 |  2400/ 2928 batches | lr 0.06 | ms/batch 14.21 | loss  5.88 | ppl   357.21\n",
            "| epoch  10 |  2600/ 2928 batches | lr 0.06 | ms/batch 14.71 | loss  5.88 | ppl   358.17\n",
            "| epoch  10 |  2800/ 2928 batches | lr 0.06 | ms/batch 13.96 | loss  5.83 | ppl   341.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 43.18s | valid loss  5.68 | valid ppl   292.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |   200/ 2928 batches | lr 0.06 | ms/batch 14.16 | loss  5.88 | ppl   357.94\n",
            "| epoch  11 |   400/ 2928 batches | lr 0.06 | ms/batch 13.95 | loss  5.90 | ppl   366.62\n",
            "| epoch  11 |   600/ 2928 batches | lr 0.06 | ms/batch 13.94 | loss  5.79 | ppl   328.59\n",
            "| epoch  11 |   800/ 2928 batches | lr 0.06 | ms/batch 14.07 | loss  5.86 | ppl   351.43\n",
            "| epoch  11 |  1000/ 2928 batches | lr 0.06 | ms/batch 14.19 | loss  5.80 | ppl   330.14\n",
            "| epoch  11 |  1200/ 2928 batches | lr 0.06 | ms/batch 13.99 | loss  5.87 | ppl   352.65\n",
            "| epoch  11 |  1400/ 2928 batches | lr 0.06 | ms/batch 13.97 | loss  5.86 | ppl   350.20\n",
            "| epoch  11 |  1600/ 2928 batches | lr 0.06 | ms/batch 13.97 | loss  5.90 | ppl   363.41\n",
            "| epoch  11 |  1800/ 2928 batches | lr 0.06 | ms/batch 14.31 | loss  5.84 | ppl   344.66\n",
            "| epoch  11 |  2000/ 2928 batches | lr 0.06 | ms/batch 13.95 | loss  5.88 | ppl   356.91\n",
            "| epoch  11 |  2200/ 2928 batches | lr 0.06 | ms/batch 13.94 | loss  5.76 | ppl   318.38\n",
            "| epoch  11 |  2400/ 2928 batches | lr 0.06 | ms/batch 13.98 | loss  5.85 | ppl   348.64\n",
            "| epoch  11 |  2600/ 2928 batches | lr 0.06 | ms/batch 14.33 | loss  5.86 | ppl   349.06\n",
            "| epoch  11 |  2800/ 2928 batches | lr 0.06 | ms/batch 13.95 | loss  5.81 | ppl   333.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 42.91s | valid loss  5.66 | valid ppl   286.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |   200/ 2928 batches | lr 0.06 | ms/batch 14.01 | loss  5.86 | ppl   349.97\n",
            "| epoch  12 |   400/ 2928 batches | lr 0.06 | ms/batch 14.29 | loss  5.88 | ppl   358.62\n",
            "| epoch  12 |   600/ 2928 batches | lr 0.06 | ms/batch 13.98 | loss  5.77 | ppl   320.55\n",
            "| epoch  12 |   800/ 2928 batches | lr 0.06 | ms/batch 13.93 | loss  5.84 | ppl   343.42\n",
            "| epoch  12 |  1000/ 2928 batches | lr 0.06 | ms/batch 13.93 | loss  5.78 | ppl   322.37\n",
            "| epoch  12 |  1200/ 2928 batches | lr 0.06 | ms/batch 14.29 | loss  5.84 | ppl   343.97\n",
            "| epoch  12 |  1400/ 2928 batches | lr 0.06 | ms/batch 13.94 | loss  5.83 | ppl   342.06\n",
            "| epoch  12 |  1600/ 2928 batches | lr 0.06 | ms/batch 13.99 | loss  5.87 | ppl   355.30\n",
            "| epoch  12 |  1800/ 2928 batches | lr 0.06 | ms/batch 13.98 | loss  5.82 | ppl   337.03\n",
            "| epoch  12 |  2000/ 2928 batches | lr 0.06 | ms/batch 14.21 | loss  5.86 | ppl   349.31\n",
            "| epoch  12 |  2200/ 2928 batches | lr 0.06 | ms/batch 14.09 | loss  5.74 | ppl   311.57\n",
            "| epoch  12 |  2400/ 2928 batches | lr 0.06 | ms/batch 13.98 | loss  5.83 | ppl   340.05\n",
            "| epoch  12 |  2600/ 2928 batches | lr 0.06 | ms/batch 13.96 | loss  5.83 | ppl   341.97\n",
            "| epoch  12 |  2800/ 2928 batches | lr 0.06 | ms/batch 14.10 | loss  5.79 | ppl   325.64\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 42.96s | valid loss  5.64 | valid ppl   281.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |   200/ 2928 batches | lr 0.05 | ms/batch 14.03 | loss  5.84 | ppl   342.46\n",
            "| epoch  13 |   400/ 2928 batches | lr 0.05 | ms/batch 13.99 | loss  5.86 | ppl   350.98\n",
            "| epoch  13 |   600/ 2928 batches | lr 0.05 | ms/batch 14.18 | loss  5.75 | ppl   313.69\n",
            "| epoch  13 |   800/ 2928 batches | lr 0.05 | ms/batch 14.09 | loss  5.82 | ppl   335.67\n",
            "| epoch  13 |  1000/ 2928 batches | lr 0.05 | ms/batch 13.95 | loss  5.76 | ppl   316.32\n",
            "| epoch  13 |  1200/ 2928 batches | lr 0.05 | ms/batch 13.98 | loss  5.82 | ppl   335.88\n",
            "| epoch  13 |  1400/ 2928 batches | lr 0.05 | ms/batch 14.04 | loss  5.82 | ppl   335.68\n",
            "| epoch  13 |  1600/ 2928 batches | lr 0.05 | ms/batch 14.16 | loss  5.85 | ppl   347.54\n",
            "| epoch  13 |  1800/ 2928 batches | lr 0.05 | ms/batch 13.94 | loss  5.80 | ppl   330.83\n",
            "| epoch  13 |  2000/ 2928 batches | lr 0.05 | ms/batch 13.96 | loss  5.83 | ppl   342.02\n",
            "| epoch  13 |  2200/ 2928 batches | lr 0.05 | ms/batch 13.91 | loss  5.72 | ppl   304.88\n",
            "| epoch  13 |  2400/ 2928 batches | lr 0.05 | ms/batch 14.26 | loss  5.81 | ppl   333.82\n",
            "| epoch  13 |  2600/ 2928 batches | lr 0.05 | ms/batch 13.93 | loss  5.81 | ppl   334.49\n",
            "| epoch  13 |  2800/ 2928 batches | lr 0.05 | ms/batch 13.97 | loss  5.76 | ppl   318.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 42.90s | valid loss  5.62 | valid ppl   277.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |   200/ 2928 batches | lr 0.05 | ms/batch 14.26 | loss  5.82 | ppl   336.20\n",
            "| epoch  14 |   400/ 2928 batches | lr 0.05 | ms/batch 13.97 | loss  5.84 | ppl   344.95\n",
            "| epoch  14 |   600/ 2928 batches | lr 0.05 | ms/batch 13.98 | loss  5.73 | ppl   308.22\n",
            "| epoch  14 |   800/ 2928 batches | lr 0.05 | ms/batch 13.94 | loss  5.80 | ppl   329.52\n",
            "| epoch  14 |  1000/ 2928 batches | lr 0.05 | ms/batch 14.30 | loss  5.74 | ppl   309.77\n",
            "| epoch  14 |  1200/ 2928 batches | lr 0.05 | ms/batch 13.95 | loss  5.80 | ppl   331.09\n",
            "| epoch  14 |  1400/ 2928 batches | lr 0.05 | ms/batch 13.94 | loss  5.80 | ppl   329.28\n",
            "| epoch  14 |  1600/ 2928 batches | lr 0.05 | ms/batch 13.92 | loss  5.83 | ppl   341.86\n",
            "| epoch  14 |  1800/ 2928 batches | lr 0.05 | ms/batch 14.26 | loss  5.78 | ppl   324.31\n",
            "| epoch  14 |  2000/ 2928 batches | lr 0.05 | ms/batch 13.98 | loss  5.82 | ppl   335.97\n",
            "| epoch  14 |  2200/ 2928 batches | lr 0.05 | ms/batch 13.95 | loss  5.70 | ppl   299.19\n",
            "| epoch  14 |  2400/ 2928 batches | lr 0.05 | ms/batch 13.95 | loss  5.79 | ppl   327.76\n",
            "| epoch  14 |  2600/ 2928 batches | lr 0.05 | ms/batch 14.22 | loss  5.80 | ppl   329.16\n",
            "| epoch  14 |  2800/ 2928 batches | lr 0.05 | ms/batch 13.99 | loss  5.75 | ppl   313.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 42.91s | valid loss  5.61 | valid ppl   273.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |   200/ 2928 batches | lr 0.05 | ms/batch 14.06 | loss  5.80 | ppl   330.52\n",
            "| epoch  15 |   400/ 2928 batches | lr 0.05 | ms/batch 14.27 | loss  5.83 | ppl   338.70\n",
            "| epoch  15 |   600/ 2928 batches | lr 0.05 | ms/batch 13.92 | loss  5.71 | ppl   302.69\n",
            "| epoch  15 |   800/ 2928 batches | lr 0.05 | ms/batch 13.93 | loss  5.78 | ppl   323.38\n",
            "| epoch  15 |  1000/ 2928 batches | lr 0.05 | ms/batch 14.01 | loss  5.72 | ppl   303.81\n",
            "| epoch  15 |  1200/ 2928 batches | lr 0.05 | ms/batch 14.18 | loss  5.78 | ppl   324.60\n",
            "| epoch  15 |  1400/ 2928 batches | lr 0.05 | ms/batch 14.06 | loss  5.78 | ppl   323.36\n",
            "| epoch  15 |  1600/ 2928 batches | lr 0.05 | ms/batch 13.95 | loss  5.82 | ppl   335.62\n",
            "| epoch  15 |  1800/ 2928 batches | lr 0.05 | ms/batch 13.94 | loss  5.77 | ppl   319.16\n",
            "| epoch  15 |  2000/ 2928 batches | lr 0.05 | ms/batch 14.05 | loss  5.80 | ppl   330.38\n",
            "| epoch  15 |  2200/ 2928 batches | lr 0.05 | ms/batch 14.17 | loss  5.68 | ppl   293.48\n",
            "| epoch  15 |  2400/ 2928 batches | lr 0.05 | ms/batch 13.97 | loss  5.78 | ppl   322.37\n",
            "| epoch  15 |  2600/ 2928 batches | lr 0.05 | ms/batch 13.95 | loss  5.78 | ppl   323.63\n",
            "| epoch  15 |  2800/ 2928 batches | lr 0.05 | ms/batch 14.03 | loss  5.73 | ppl   308.35\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 42.96s | valid loss  5.60 | valid ppl   269.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |   200/ 2928 batches | lr 0.05 | ms/batch 14.01 | loss  5.79 | ppl   325.46\n",
            "| epoch  16 |   400/ 2928 batches | lr 0.05 | ms/batch 13.97 | loss  5.81 | ppl   334.85\n",
            "| epoch  16 |   600/ 2928 batches | lr 0.05 | ms/batch 14.01 | loss  5.70 | ppl   297.43\n",
            "| epoch  16 |   800/ 2928 batches | lr 0.05 | ms/batch 14.22 | loss  5.76 | ppl   318.41\n",
            "| epoch  16 |  1000/ 2928 batches | lr 0.05 | ms/batch 13.97 | loss  5.70 | ppl   299.63\n",
            "| epoch  16 |  1200/ 2928 batches | lr 0.05 | ms/batch 13.93 | loss  5.77 | ppl   319.19\n",
            "| epoch  16 |  1400/ 2928 batches | lr 0.05 | ms/batch 13.99 | loss  5.76 | ppl   318.85\n",
            "| epoch  16 |  1600/ 2928 batches | lr 0.05 | ms/batch 14.25 | loss  5.80 | ppl   331.16\n",
            "| epoch  16 |  1800/ 2928 batches | lr 0.05 | ms/batch 13.96 | loss  5.75 | ppl   314.67\n",
            "| epoch  16 |  2000/ 2928 batches | lr 0.05 | ms/batch 13.94 | loss  5.78 | ppl   325.25\n",
            "| epoch  16 |  2200/ 2928 batches | lr 0.05 | ms/batch 13.98 | loss  5.67 | ppl   289.28\n",
            "| epoch  16 |  2400/ 2928 batches | lr 0.05 | ms/batch 14.28 | loss  5.76 | ppl   316.72\n",
            "| epoch  16 |  2600/ 2928 batches | lr 0.05 | ms/batch 13.94 | loss  5.76 | ppl   318.46\n",
            "| epoch  16 |  2800/ 2928 batches | lr 0.05 | ms/batch 13.99 | loss  5.71 | ppl   302.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 42.87s | valid loss  5.59 | valid ppl   267.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |   200/ 2928 batches | lr 0.04 | ms/batch 14.40 | loss  5.77 | ppl   320.63\n",
            "| epoch  17 |   400/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.80 | ppl   329.52\n",
            "| epoch  17 |   600/ 2928 batches | lr 0.04 | ms/batch 13.94 | loss  5.68 | ppl   292.69\n",
            "| epoch  17 |   800/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.75 | ppl   314.93\n",
            "| epoch  17 |  1000/ 2928 batches | lr 0.04 | ms/batch 14.24 | loss  5.69 | ppl   294.96\n",
            "| epoch  17 |  1200/ 2928 batches | lr 0.04 | ms/batch 14.10 | loss  5.75 | ppl   314.70\n",
            "| epoch  17 |  1400/ 2928 batches | lr 0.04 | ms/batch 14.10 | loss  5.75 | ppl   313.87\n",
            "| epoch  17 |  1600/ 2928 batches | lr 0.04 | ms/batch 13.98 | loss  5.79 | ppl   326.20\n",
            "| epoch  17 |  1800/ 2928 batches | lr 0.04 | ms/batch 14.19 | loss  5.74 | ppl   309.55\n",
            "| epoch  17 |  2000/ 2928 batches | lr 0.04 | ms/batch 14.16 | loss  5.77 | ppl   321.04\n",
            "| epoch  17 |  2200/ 2928 batches | lr 0.04 | ms/batch 13.98 | loss  5.65 | ppl   284.11\n",
            "| epoch  17 |  2400/ 2928 batches | lr 0.04 | ms/batch 13.98 | loss  5.74 | ppl   312.28\n",
            "| epoch  17 |  2600/ 2928 batches | lr 0.04 | ms/batch 14.10 | loss  5.75 | ppl   313.88\n",
            "| epoch  17 |  2800/ 2928 batches | lr 0.04 | ms/batch 14.26 | loss  5.70 | ppl   298.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 43.09s | valid loss  5.58 | valid ppl   263.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |   200/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.76 | ppl   316.26\n",
            "| epoch  18 |   400/ 2928 batches | lr 0.04 | ms/batch 14.20 | loss  5.78 | ppl   325.12\n",
            "| epoch  18 |   600/ 2928 batches | lr 0.04 | ms/batch 14.26 | loss  5.67 | ppl   289.00\n",
            "| epoch  18 |   800/ 2928 batches | lr 0.04 | ms/batch 14.05 | loss  5.73 | ppl   309.17\n",
            "| epoch  18 |  1000/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.67 | ppl   290.57\n",
            "| epoch  18 |  1200/ 2928 batches | lr 0.04 | ms/batch 14.05 | loss  5.74 | ppl   309.98\n",
            "| epoch  18 |  1400/ 2928 batches | lr 0.04 | ms/batch 14.25 | loss  5.74 | ppl   309.90\n",
            "| epoch  18 |  1600/ 2928 batches | lr 0.04 | ms/batch 13.97 | loss  5.78 | ppl   322.89\n",
            "| epoch  18 |  1800/ 2928 batches | lr 0.04 | ms/batch 13.97 | loss  5.72 | ppl   305.40\n",
            "| epoch  18 |  2000/ 2928 batches | lr 0.04 | ms/batch 13.99 | loss  5.76 | ppl   316.83\n",
            "| epoch  18 |  2200/ 2928 batches | lr 0.04 | ms/batch 14.32 | loss  5.64 | ppl   281.47\n",
            "| epoch  18 |  2400/ 2928 batches | lr 0.04 | ms/batch 13.95 | loss  5.73 | ppl   308.73\n",
            "| epoch  18 |  2600/ 2928 batches | lr 0.04 | ms/batch 13.97 | loss  5.74 | ppl   310.18\n",
            "| epoch  18 |  2800/ 2928 batches | lr 0.04 | ms/batch 13.96 | loss  5.69 | ppl   294.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 43.20s | valid loss  5.57 | valid ppl   261.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |   200/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.74 | ppl   312.15\n",
            "| epoch  19 |   400/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.77 | ppl   320.58\n",
            "| epoch  19 |   600/ 2928 batches | lr 0.04 | ms/batch 13.98 | loss  5.65 | ppl   284.24\n",
            "| epoch  19 |   800/ 2928 batches | lr 0.04 | ms/batch 14.34 | loss  5.72 | ppl   305.93\n",
            "| epoch  19 |  1000/ 2928 batches | lr 0.04 | ms/batch 13.98 | loss  5.66 | ppl   286.91\n",
            "| epoch  19 |  1200/ 2928 batches | lr 0.04 | ms/batch 13.99 | loss  5.73 | ppl   306.73\n",
            "| epoch  19 |  1400/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.72 | ppl   305.71\n",
            "| epoch  19 |  1600/ 2928 batches | lr 0.04 | ms/batch 14.38 | loss  5.76 | ppl   318.30\n",
            "| epoch  19 |  1800/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.71 | ppl   301.31\n",
            "| epoch  19 |  2000/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.75 | ppl   312.97\n",
            "| epoch  19 |  2200/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.63 | ppl   277.85\n",
            "| epoch  19 |  2400/ 2928 batches | lr 0.04 | ms/batch 14.20 | loss  5.72 | ppl   305.03\n",
            "| epoch  19 |  2600/ 2928 batches | lr 0.04 | ms/batch 14.12 | loss  5.73 | ppl   306.54\n",
            "| epoch  19 |  2800/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.67 | ppl   290.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 43.02s | valid loss  5.56 | valid ppl   258.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |   200/ 2928 batches | lr 0.04 | ms/batch 14.42 | loss  5.73 | ppl   309.04\n",
            "| epoch  20 |   400/ 2928 batches | lr 0.04 | ms/batch 14.06 | loss  5.76 | ppl   318.28\n",
            "| epoch  20 |   600/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.64 | ppl   280.99\n",
            "| epoch  20 |   800/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.71 | ppl   301.77\n",
            "| epoch  20 |  1000/ 2928 batches | lr 0.04 | ms/batch 14.20 | loss  5.65 | ppl   283.80\n",
            "| epoch  20 |  1200/ 2928 batches | lr 0.04 | ms/batch 14.17 | loss  5.71 | ppl   303.16\n",
            "| epoch  20 |  1400/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.71 | ppl   302.63\n",
            "| epoch  20 |  1600/ 2928 batches | lr 0.04 | ms/batch 14.04 | loss  5.75 | ppl   314.44\n",
            "| epoch  20 |  1800/ 2928 batches | lr 0.04 | ms/batch 14.12 | loss  5.70 | ppl   297.90\n",
            "| epoch  20 |  2000/ 2928 batches | lr 0.04 | ms/batch 14.30 | loss  5.73 | ppl   309.36\n",
            "| epoch  20 |  2200/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.61 | ppl   274.19\n",
            "| epoch  20 |  2400/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.71 | ppl   301.74\n",
            "| epoch  20 |  2600/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.71 | ppl   303.10\n",
            "| epoch  20 |  2800/ 2928 batches | lr 0.04 | ms/batch 14.37 | loss  5.66 | ppl   287.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 43.15s | valid loss  5.55 | valid ppl   256.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |   200/ 2928 batches | lr 0.04 | ms/batch 14.06 | loss  5.72 | ppl   304.43\n",
            "| epoch  21 |   400/ 2928 batches | lr 0.04 | ms/batch 14.12 | loss  5.75 | ppl   314.78\n",
            "| epoch  21 |   600/ 2928 batches | lr 0.04 | ms/batch 14.29 | loss  5.63 | ppl   277.89\n",
            "| epoch  21 |   800/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.70 | ppl   297.96\n",
            "| epoch  21 |  1000/ 2928 batches | lr 0.04 | ms/batch 14.07 | loss  5.64 | ppl   280.79\n",
            "| epoch  21 |  1200/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.70 | ppl   299.76\n",
            "| epoch  21 |  1400/ 2928 batches | lr 0.04 | ms/batch 14.33 | loss  5.70 | ppl   299.28\n",
            "| epoch  21 |  1600/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.74 | ppl   310.57\n",
            "| epoch  21 |  1800/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.69 | ppl   294.73\n",
            "| epoch  21 |  2000/ 2928 batches | lr 0.04 | ms/batch 14.02 | loss  5.72 | ppl   305.65\n",
            "| epoch  21 |  2200/ 2928 batches | lr 0.04 | ms/batch 14.38 | loss  5.60 | ppl   271.67\n",
            "| epoch  21 |  2400/ 2928 batches | lr 0.04 | ms/batch 14.00 | loss  5.70 | ppl   297.97\n",
            "| epoch  21 |  2600/ 2928 batches | lr 0.04 | ms/batch 14.01 | loss  5.70 | ppl   299.04\n",
            "| epoch  21 |  2800/ 2928 batches | lr 0.04 | ms/batch 14.03 | loss  5.65 | ppl   284.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 43.32s | valid loss  5.54 | valid ppl   254.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |   200/ 2928 batches | lr 0.03 | ms/batch 14.07 | loss  5.71 | ppl   302.11\n",
            "| epoch  22 |   400/ 2928 batches | lr 0.03 | ms/batch 13.95 | loss  5.74 | ppl   311.85\n",
            "| epoch  22 |   600/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.62 | ppl   274.75\n",
            "| epoch  22 |   800/ 2928 batches | lr 0.03 | ms/batch 14.38 | loss  5.69 | ppl   296.18\n",
            "| epoch  22 |  1000/ 2928 batches | lr 0.03 | ms/batch 14.03 | loss  5.62 | ppl   276.98\n",
            "| epoch  22 |  1200/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.69 | ppl   296.34\n",
            "| epoch  22 |  1400/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.69 | ppl   296.44\n",
            "| epoch  22 |  1600/ 2928 batches | lr 0.03 | ms/batch 14.20 | loss  5.73 | ppl   308.53\n",
            "| epoch  22 |  1800/ 2928 batches | lr 0.03 | ms/batch 14.06 | loss  5.68 | ppl   291.81\n",
            "| epoch  22 |  2000/ 2928 batches | lr 0.03 | ms/batch 14.01 | loss  5.71 | ppl   303.05\n",
            "| epoch  22 |  2200/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.59 | ppl   268.99\n",
            "| epoch  22 |  2400/ 2928 batches | lr 0.03 | ms/batch 14.15 | loss  5.69 | ppl   295.93\n",
            "| epoch  22 |  2600/ 2928 batches | lr 0.03 | ms/batch 14.24 | loss  5.69 | ppl   296.87\n",
            "| epoch  22 |  2800/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.64 | ppl   282.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 43.01s | valid loss  5.53 | valid ppl   252.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |   200/ 2928 batches | lr 0.03 | ms/batch 14.22 | loss  5.70 | ppl   298.52\n",
            "| epoch  23 |   400/ 2928 batches | lr 0.03 | ms/batch 14.15 | loss  5.73 | ppl   308.86\n",
            "| epoch  23 |   600/ 2928 batches | lr 0.03 | ms/batch 14.02 | loss  5.61 | ppl   272.04\n",
            "| epoch  23 |   800/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.68 | ppl   292.85\n",
            "| epoch  23 |  1000/ 2928 batches | lr 0.03 | ms/batch 14.05 | loss  5.62 | ppl   274.78\n",
            "| epoch  23 |  1200/ 2928 batches | lr 0.03 | ms/batch 14.19 | loss  5.68 | ppl   293.38\n",
            "| epoch  23 |  1400/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.68 | ppl   293.51\n",
            "| epoch  23 |  1600/ 2928 batches | lr 0.03 | ms/batch 13.95 | loss  5.72 | ppl   304.88\n",
            "| epoch  23 |  1800/ 2928 batches | lr 0.03 | ms/batch 13.94 | loss  5.67 | ppl   289.31\n",
            "| epoch  23 |  2000/ 2928 batches | lr 0.03 | ms/batch 14.33 | loss  5.70 | ppl   300.11\n",
            "| epoch  23 |  2200/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.59 | ppl   266.68\n",
            "| epoch  23 |  2400/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.68 | ppl   293.44\n",
            "| epoch  23 |  2600/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.68 | ppl   294.18\n",
            "| epoch  23 |  2800/ 2928 batches | lr 0.03 | ms/batch 14.32 | loss  5.63 | ppl   278.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 43.04s | valid loss  5.53 | valid ppl   250.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |   200/ 2928 batches | lr 0.03 | ms/batch 14.03 | loss  5.69 | ppl   296.59\n",
            "| epoch  24 |   400/ 2928 batches | lr 0.03 | ms/batch 14.02 | loss  5.73 | ppl   306.53\n",
            "| epoch  24 |   600/ 2928 batches | lr 0.03 | ms/batch 14.30 | loss  5.60 | ppl   269.74\n",
            "| epoch  24 |   800/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.67 | ppl   290.24\n",
            "| epoch  24 |  1000/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.61 | ppl   272.12\n",
            "| epoch  24 |  1200/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.67 | ppl   289.65\n",
            "| epoch  24 |  1400/ 2928 batches | lr 0.03 | ms/batch 14.31 | loss  5.67 | ppl   290.69\n",
            "| epoch  24 |  1600/ 2928 batches | lr 0.03 | ms/batch 14.01 | loss  5.71 | ppl   302.43\n",
            "| epoch  24 |  1800/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.66 | ppl   286.66\n",
            "| epoch  24 |  2000/ 2928 batches | lr 0.03 | ms/batch 13.95 | loss  5.70 | ppl   297.52\n",
            "| epoch  24 |  2200/ 2928 batches | lr 0.03 | ms/batch 14.21 | loss  5.57 | ppl   263.39\n",
            "| epoch  24 |  2400/ 2928 batches | lr 0.03 | ms/batch 14.06 | loss  5.67 | ppl   290.54\n",
            "| epoch  24 |  2600/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.68 | ppl   291.76\n",
            "| epoch  24 |  2800/ 2928 batches | lr 0.03 | ms/batch 13.95 | loss  5.62 | ppl   276.64\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 43.23s | valid loss  5.52 | valid ppl   249.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |   200/ 2928 batches | lr 0.03 | ms/batch 14.04 | loss  5.68 | ppl   293.47\n",
            "| epoch  25 |   400/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.72 | ppl   304.38\n",
            "| epoch  25 |   600/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.59 | ppl   266.63\n",
            "| epoch  25 |   800/ 2928 batches | lr 0.03 | ms/batch 14.31 | loss  5.66 | ppl   288.34\n",
            "| epoch  25 |  1000/ 2928 batches | lr 0.03 | ms/batch 14.06 | loss  5.60 | ppl   269.48\n",
            "| epoch  25 |  1200/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.66 | ppl   288.35\n",
            "| epoch  25 |  1400/ 2928 batches | lr 0.03 | ms/batch 13.94 | loss  5.66 | ppl   288.54\n",
            "| epoch  25 |  1600/ 2928 batches | lr 0.03 | ms/batch 14.11 | loss  5.70 | ppl   299.53\n",
            "| epoch  25 |  1800/ 2928 batches | lr 0.03 | ms/batch 14.14 | loss  5.65 | ppl   284.70\n",
            "| epoch  25 |  2000/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.69 | ppl   294.76\n",
            "| epoch  25 |  2200/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.57 | ppl   261.26\n",
            "| epoch  25 |  2400/ 2928 batches | lr 0.03 | ms/batch 14.01 | loss  5.67 | ppl   288.61\n",
            "| epoch  25 |  2600/ 2928 batches | lr 0.03 | ms/batch 14.30 | loss  5.67 | ppl   288.92\n",
            "| epoch  25 |  2800/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.62 | ppl   274.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 42.94s | valid loss  5.51 | valid ppl   247.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |   200/ 2928 batches | lr 0.03 | ms/batch 14.18 | loss  5.67 | ppl   291.33\n",
            "| epoch  26 |   400/ 2928 batches | lr 0.03 | ms/batch 14.23 | loss  5.71 | ppl   301.62\n",
            "| epoch  26 |   600/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.58 | ppl   264.76\n",
            "| epoch  26 |   800/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.65 | ppl   285.51\n",
            "| epoch  26 |  1000/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.59 | ppl   268.07\n",
            "| epoch  26 |  1200/ 2928 batches | lr 0.03 | ms/batch 14.30 | loss  5.65 | ppl   285.05\n",
            "| epoch  26 |  1400/ 2928 batches | lr 0.03 | ms/batch 13.96 | loss  5.66 | ppl   286.30\n",
            "| epoch  26 |  1600/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.70 | ppl   298.36\n",
            "| epoch  26 |  1800/ 2928 batches | lr 0.03 | ms/batch 14.01 | loss  5.64 | ppl   282.49\n",
            "| epoch  26 |  2000/ 2928 batches | lr 0.03 | ms/batch 14.39 | loss  5.68 | ppl   293.47\n",
            "| epoch  26 |  2200/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.56 | ppl   259.29\n",
            "| epoch  26 |  2400/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.66 | ppl   285.85\n",
            "| epoch  26 |  2600/ 2928 batches | lr 0.03 | ms/batch 14.02 | loss  5.66 | ppl   286.54\n",
            "| epoch  26 |  2800/ 2928 batches | lr 0.03 | ms/batch 14.34 | loss  5.61 | ppl   272.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 43.06s | valid loss  5.51 | valid ppl   246.44\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |   200/ 2928 batches | lr 0.03 | ms/batch 14.04 | loss  5.67 | ppl   289.91\n",
            "| epoch  27 |   400/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.70 | ppl   300.00\n",
            "| epoch  27 |   600/ 2928 batches | lr 0.03 | ms/batch 14.36 | loss  5.57 | ppl   262.91\n",
            "| epoch  27 |   800/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.65 | ppl   283.70\n",
            "| epoch  27 |  1000/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.58 | ppl   265.60\n",
            "| epoch  27 |  1200/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.65 | ppl   284.39\n",
            "| epoch  27 |  1400/ 2928 batches | lr 0.03 | ms/batch 14.24 | loss  5.65 | ppl   284.28\n",
            "| epoch  27 |  1600/ 2928 batches | lr 0.03 | ms/batch 14.13 | loss  5.69 | ppl   295.32\n",
            "| epoch  27 |  1800/ 2928 batches | lr 0.03 | ms/batch 13.97 | loss  5.64 | ppl   280.50\n",
            "| epoch  27 |  2000/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.67 | ppl   290.82\n",
            "| epoch  27 |  2200/ 2928 batches | lr 0.03 | ms/batch 14.14 | loss  5.55 | ppl   257.71\n",
            "| epoch  27 |  2400/ 2928 batches | lr 0.03 | ms/batch 14.21 | loss  5.65 | ppl   284.52\n",
            "| epoch  27 |  2600/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.65 | ppl   285.52\n",
            "| epoch  27 |  2800/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.60 | ppl   270.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 43.14s | valid loss  5.50 | valid ppl   245.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |   200/ 2928 batches | lr 0.03 | ms/batch 14.22 | loss  5.66 | ppl   287.29\n",
            "| epoch  28 |   400/ 2928 batches | lr 0.03 | ms/batch 14.03 | loss  5.70 | ppl   297.43\n",
            "| epoch  28 |   600/ 2928 batches | lr 0.03 | ms/batch 14.02 | loss  5.56 | ppl   261.03\n",
            "| epoch  28 |   800/ 2928 batches | lr 0.03 | ms/batch 14.12 | loss  5.64 | ppl   282.26\n",
            "| epoch  28 |  1000/ 2928 batches | lr 0.03 | ms/batch 14.22 | loss  5.57 | ppl   263.55\n",
            "| epoch  28 |  1200/ 2928 batches | lr 0.03 | ms/batch 14.01 | loss  5.64 | ppl   282.00\n",
            "| epoch  28 |  1400/ 2928 batches | lr 0.03 | ms/batch 13.98 | loss  5.64 | ppl   282.15\n",
            "| epoch  28 |  1600/ 2928 batches | lr 0.03 | ms/batch 14.02 | loss  5.68 | ppl   294.02\n",
            "| epoch  28 |  1800/ 2928 batches | lr 0.03 | ms/batch 14.35 | loss  5.63 | ppl   278.75\n",
            "| epoch  28 |  2000/ 2928 batches | lr 0.03 | ms/batch 14.02 | loss  5.66 | ppl   288.39\n",
            "| epoch  28 |  2200/ 2928 batches | lr 0.03 | ms/batch 14.00 | loss  5.55 | ppl   256.17\n",
            "| epoch  28 |  2400/ 2928 batches | lr 0.03 | ms/batch 14.01 | loss  5.64 | ppl   282.25\n",
            "| epoch  28 |  2600/ 2928 batches | lr 0.03 | ms/batch 14.32 | loss  5.65 | ppl   282.97\n",
            "| epoch  28 |  2800/ 2928 batches | lr 0.03 | ms/batch 13.99 | loss  5.59 | ppl   268.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 43.07s | valid loss  5.50 | valid ppl   243.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |   200/ 2928 batches | lr 0.02 | ms/batch 14.07 | loss  5.65 | ppl   285.48\n",
            "| epoch  29 |   400/ 2928 batches | lr 0.02 | ms/batch 14.35 | loss  5.69 | ppl   296.21\n",
            "| epoch  29 |   600/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.56 | ppl   259.21\n",
            "| epoch  29 |   800/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.64 | ppl   280.43\n",
            "| epoch  29 |  1000/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.57 | ppl   261.34\n",
            "| epoch  29 |  1200/ 2928 batches | lr 0.02 | ms/batch 14.32 | loss  5.64 | ppl   280.11\n",
            "| epoch  29 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.64 | ppl   280.07\n",
            "| epoch  29 |  1600/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.68 | ppl   291.75\n",
            "| epoch  29 |  1800/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.62 | ppl   276.42\n",
            "| epoch  29 |  2000/ 2928 batches | lr 0.02 | ms/batch 14.25 | loss  5.66 | ppl   286.23\n",
            "| epoch  29 |  2200/ 2928 batches | lr 0.02 | ms/batch 14.05 | loss  5.54 | ppl   254.58\n",
            "| epoch  29 |  2400/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.64 | ppl   280.41\n",
            "| epoch  29 |  2600/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.64 | ppl   281.28\n",
            "| epoch  29 |  2800/ 2928 batches | lr 0.02 | ms/batch 14.10 | loss  5.59 | ppl   266.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 43.03s | valid loss  5.49 | valid ppl   242.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |   200/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.65 | ppl   283.48\n",
            "| epoch  30 |   400/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.68 | ppl   294.09\n",
            "| epoch  30 |   600/ 2928 batches | lr 0.02 | ms/batch 14.23 | loss  5.55 | ppl   257.75\n",
            "| epoch  30 |   800/ 2928 batches | lr 0.02 | ms/batch 14.11 | loss  5.63 | ppl   277.67\n",
            "| epoch  30 |  1000/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.56 | ppl   259.98\n",
            "| epoch  30 |  1200/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.63 | ppl   278.46\n",
            "| epoch  30 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.11 | loss  5.63 | ppl   279.00\n",
            "| epoch  30 |  1600/ 2928 batches | lr 0.02 | ms/batch 14.16 | loss  5.67 | ppl   289.87\n",
            "| epoch  30 |  1800/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.62 | ppl   274.65\n",
            "| epoch  30 |  2000/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.65 | ppl   285.34\n",
            "| epoch  30 |  2200/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.53 | ppl   252.70\n",
            "| epoch  30 |  2400/ 2928 batches | lr 0.02 | ms/batch 14.28 | loss  5.63 | ppl   278.91\n",
            "| epoch  30 |  2600/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.63 | ppl   279.83\n",
            "| epoch  30 |  2800/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.58 | ppl   265.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 43.01s | valid loss  5.49 | valid ppl   241.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  31 |   200/ 2928 batches | lr 0.02 | ms/batch 14.25 | loss  5.64 | ppl   281.98\n",
            "| epoch  31 |   400/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.68 | ppl   291.94\n",
            "| epoch  31 |   600/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.55 | ppl   255.98\n",
            "| epoch  31 |   800/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.62 | ppl   276.62\n",
            "| epoch  31 |  1000/ 2928 batches | lr 0.02 | ms/batch 14.29 | loss  5.55 | ppl   258.13\n",
            "| epoch  31 |  1200/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.62 | ppl   277.05\n",
            "| epoch  31 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.63 | ppl   277.98\n",
            "| epoch  31 |  1600/ 2928 batches | lr 0.02 | ms/batch 13.95 | loss  5.67 | ppl   289.03\n",
            "| epoch  31 |  1800/ 2928 batches | lr 0.02 | ms/batch 14.33 | loss  5.61 | ppl   273.64\n",
            "| epoch  31 |  2000/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.65 | ppl   283.86\n",
            "| epoch  31 |  2200/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.53 | ppl   251.24\n",
            "| epoch  31 |  2400/ 2928 batches | lr 0.02 | ms/batch 13.96 | loss  5.63 | ppl   277.49\n",
            "| epoch  31 |  2600/ 2928 batches | lr 0.02 | ms/batch 14.31 | loss  5.63 | ppl   277.89\n",
            "| epoch  31 |  2800/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.57 | ppl   263.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 43.00s | valid loss  5.48 | valid ppl   240.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |   200/ 2928 batches | lr 0.02 | ms/batch 14.01 | loss  5.64 | ppl   280.24\n",
            "| epoch  32 |   400/ 2928 batches | lr 0.02 | ms/batch 14.36 | loss  5.67 | ppl   290.98\n",
            "| epoch  32 |   600/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.54 | ppl   254.82\n",
            "| epoch  32 |   800/ 2928 batches | lr 0.02 | ms/batch 14.01 | loss  5.62 | ppl   274.52\n",
            "| epoch  32 |  1000/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.55 | ppl   256.78\n",
            "| epoch  32 |  1200/ 2928 batches | lr 0.02 | ms/batch 14.24 | loss  5.62 | ppl   274.82\n",
            "| epoch  32 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.04 | loss  5.62 | ppl   275.95\n",
            "| epoch  32 |  1600/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.66 | ppl   286.98\n",
            "| epoch  32 |  1800/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.61 | ppl   271.80\n",
            "| epoch  32 |  2000/ 2928 batches | lr 0.02 | ms/batch 14.13 | loss  5.64 | ppl   282.10\n",
            "| epoch  32 |  2200/ 2928 batches | lr 0.02 | ms/batch 14.18 | loss  5.52 | ppl   249.03\n",
            "| epoch  32 |  2400/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.62 | ppl   275.66\n",
            "| epoch  32 |  2600/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.62 | ppl   276.12\n",
            "| epoch  32 |  2800/ 2928 batches | lr 0.02 | ms/batch 14.06 | loss  5.57 | ppl   262.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 43.03s | valid loss  5.48 | valid ppl   239.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |   200/ 2928 batches | lr 0.02 | ms/batch 14.04 | loss  5.63 | ppl   279.51\n",
            "| epoch  33 |   400/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.67 | ppl   289.93\n",
            "| epoch  33 |   600/ 2928 batches | lr 0.02 | ms/batch 14.10 | loss  5.54 | ppl   253.46\n",
            "| epoch  33 |   800/ 2928 batches | lr 0.02 | ms/batch 14.20 | loss  5.61 | ppl   273.53\n",
            "| epoch  33 |  1000/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.54 | ppl   255.72\n",
            "| epoch  33 |  1200/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.61 | ppl   274.05\n",
            "| epoch  33 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.62 | ppl   274.91\n",
            "| epoch  33 |  1600/ 2928 batches | lr 0.02 | ms/batch 14.27 | loss  5.66 | ppl   285.82\n",
            "| epoch  33 |  1800/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.60 | ppl   270.94\n",
            "| epoch  33 |  2000/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.64 | ppl   280.65\n",
            "| epoch  33 |  2200/ 2928 batches | lr 0.02 | ms/batch 14.04 | loss  5.52 | ppl   248.80\n",
            "| epoch  33 |  2400/ 2928 batches | lr 0.02 | ms/batch 14.33 | loss  5.62 | ppl   275.50\n",
            "| epoch  33 |  2600/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.62 | ppl   275.24\n",
            "| epoch  33 |  2800/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.57 | ppl   261.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 42.99s | valid loss  5.47 | valid ppl   238.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |   200/ 2928 batches | lr 0.02 | ms/batch 14.35 | loss  5.63 | ppl   277.87\n",
            "| epoch  34 |   400/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.66 | ppl   288.06\n",
            "| epoch  34 |   600/ 2928 batches | lr 0.02 | ms/batch 14.05 | loss  5.53 | ppl   251.75\n",
            "| epoch  34 |   800/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.61 | ppl   272.22\n",
            "| epoch  34 |  1000/ 2928 batches | lr 0.02 | ms/batch 14.35 | loss  5.54 | ppl   254.99\n",
            "| epoch  34 |  1200/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.61 | ppl   272.31\n",
            "| epoch  34 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.61 | ppl   273.14\n",
            "| epoch  34 |  1600/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.65 | ppl   284.99\n",
            "| epoch  34 |  1800/ 2928 batches | lr 0.02 | ms/batch 14.32 | loss  5.60 | ppl   269.68\n",
            "| epoch  34 |  2000/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.63 | ppl   278.76\n",
            "| epoch  34 |  2200/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.51 | ppl   247.69\n",
            "| epoch  34 |  2400/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.61 | ppl   272.99\n",
            "| epoch  34 |  2600/ 2928 batches | lr 0.02 | ms/batch 14.12 | loss  5.61 | ppl   273.47\n",
            "| epoch  34 |  2800/ 2928 batches | lr 0.02 | ms/batch 14.18 | loss  5.56 | ppl   259.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 43.05s | valid loss  5.47 | valid ppl   237.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |   200/ 2928 batches | lr 0.02 | ms/batch 14.04 | loss  5.62 | ppl   276.43\n",
            "| epoch  35 |   400/ 2928 batches | lr 0.02 | ms/batch 14.27 | loss  5.66 | ppl   286.75\n",
            "| epoch  35 |   600/ 2928 batches | lr 0.02 | ms/batch 14.14 | loss  5.52 | ppl   250.61\n",
            "| epoch  35 |   800/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.61 | ppl   272.10\n",
            "| epoch  35 |  1000/ 2928 batches | lr 0.02 | ms/batch 14.03 | loss  5.54 | ppl   253.44\n",
            "| epoch  35 |  1200/ 2928 batches | lr 0.02 | ms/batch 14.10 | loss  5.60 | ppl   271.50\n",
            "| epoch  35 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.22 | loss  5.61 | ppl   271.98\n",
            "| epoch  35 |  1600/ 2928 batches | lr 0.02 | ms/batch 14.03 | loss  5.65 | ppl   283.23\n",
            "| epoch  35 |  1800/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.59 | ppl   268.10\n",
            "| epoch  35 |  2000/ 2928 batches | lr 0.02 | ms/batch 14.03 | loss  5.63 | ppl   278.68\n",
            "| epoch  35 |  2200/ 2928 batches | lr 0.02 | ms/batch 14.33 | loss  5.51 | ppl   246.42\n",
            "| epoch  35 |  2400/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.61 | ppl   272.34\n",
            "| epoch  35 |  2600/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.61 | ppl   273.17\n",
            "| epoch  35 |  2800/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.56 | ppl   259.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 43.18s | valid loss  5.47 | valid ppl   237.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |   200/ 2928 batches | lr 0.02 | ms/batch 14.03 | loss  5.62 | ppl   275.99\n",
            "| epoch  36 |   400/ 2928 batches | lr 0.02 | ms/batch 14.06 | loss  5.66 | ppl   286.42\n",
            "| epoch  36 |   600/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.52 | ppl   249.63\n",
            "| epoch  36 |   800/ 2928 batches | lr 0.02 | ms/batch 14.35 | loss  5.60 | ppl   270.18\n",
            "| epoch  36 |  1000/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.53 | ppl   252.53\n",
            "| epoch  36 |  1200/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.60 | ppl   270.31\n",
            "| epoch  36 |  1400/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.60 | ppl   271.14\n",
            "| epoch  36 |  1600/ 2928 batches | lr 0.02 | ms/batch 14.32 | loss  5.64 | ppl   282.20\n",
            "| epoch  36 |  1800/ 2928 batches | lr 0.02 | ms/batch 14.01 | loss  5.59 | ppl   267.10\n",
            "| epoch  36 |  2000/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.62 | ppl   277.16\n",
            "| epoch  36 |  2200/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.50 | ppl   245.30\n",
            "| epoch  36 |  2400/ 2928 batches | lr 0.02 | ms/batch 14.30 | loss  5.60 | ppl   271.45\n",
            "| epoch  36 |  2600/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.61 | ppl   271.86\n",
            "| epoch  36 |  2800/ 2928 batches | lr 0.02 | ms/batch 13.96 | loss  5.55 | ppl   257.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 43.00s | valid loss  5.47 | valid ppl   236.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |   200/ 2928 batches | lr 0.02 | ms/batch 14.38 | loss  5.61 | ppl   274.24\n",
            "| epoch  37 |   400/ 2928 batches | lr 0.02 | ms/batch 14.00 | loss  5.65 | ppl   284.72\n",
            "| epoch  37 |   600/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.52 | ppl   248.86\n",
            "| epoch  37 |   800/ 2928 batches | lr 0.02 | ms/batch 14.02 | loss  5.60 | ppl   269.70\n",
            "| epoch  37 |  1000/ 2928 batches | lr 0.02 | ms/batch 14.23 | loss  5.52 | ppl   250.77\n",
            "| epoch  37 |  1200/ 2928 batches | lr 0.02 | ms/batch 14.09 | loss  5.59 | ppl   268.76\n",
            "| epoch  37 |  1400/ 2928 batches | lr 0.02 | ms/batch 14.04 | loss  5.60 | ppl   269.97\n",
            "| epoch  37 |  1600/ 2928 batches | lr 0.02 | ms/batch 13.98 | loss  5.64 | ppl   281.08\n",
            "| epoch  37 |  1800/ 2928 batches | lr 0.02 | ms/batch 14.17 | loss  5.58 | ppl   266.22\n",
            "| epoch  37 |  2000/ 2928 batches | lr 0.02 | ms/batch 14.15 | loss  5.62 | ppl   275.84\n",
            "| epoch  37 |  2200/ 2928 batches | lr 0.02 | ms/batch 13.99 | loss  5.50 | ppl   244.64\n",
            "| epoch  37 |  2400/ 2928 batches | lr 0.02 | ms/batch 13.97 | loss  5.60 | ppl   269.59\n",
            "| epoch  37 |  2600/ 2928 batches | lr 0.02 | ms/batch 14.04 | loss  5.60 | ppl   270.67\n",
            "| epoch  37 |  2800/ 2928 batches | lr 0.02 | ms/batch 14.24 | loss  5.55 | ppl   256.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 43.05s | valid loss  5.46 | valid ppl   235.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |   200/ 2928 batches | lr 0.01 | ms/batch 14.05 | loss  5.61 | ppl   273.53\n",
            "| epoch  38 |   400/ 2928 batches | lr 0.01 | ms/batch 14.08 | loss  5.65 | ppl   283.90\n",
            "| epoch  38 |   600/ 2928 batches | lr 0.01 | ms/batch 14.24 | loss  5.51 | ppl   247.00\n",
            "| epoch  38 |   800/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.59 | ppl   267.77\n",
            "| epoch  38 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.00 | loss  5.52 | ppl   249.69\n",
            "| epoch  38 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.59 | ppl   267.72\n",
            "| epoch  38 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.28 | loss  5.59 | ppl   268.35\n",
            "| epoch  38 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.64 | ppl   280.38\n",
            "| epoch  38 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.58 | ppl   265.50\n",
            "| epoch  38 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.62 | ppl   275.26\n",
            "| epoch  38 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.32 | loss  5.50 | ppl   243.47\n",
            "| epoch  38 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.59 | ppl   268.76\n",
            "| epoch  38 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.60 | ppl   269.27\n",
            "| epoch  38 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.55 | ppl   256.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 43.15s | valid loss  5.46 | valid ppl   234.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |   200/ 2928 batches | lr 0.01 | ms/batch 14.07 | loss  5.61 | ppl   271.99\n",
            "| epoch  39 |   400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.64 | ppl   282.60\n",
            "| epoch  39 |   600/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.51 | ppl   246.17\n",
            "| epoch  39 |   800/ 2928 batches | lr 0.01 | ms/batch 14.28 | loss  5.59 | ppl   266.85\n",
            "| epoch  39 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.52 | ppl   249.35\n",
            "| epoch  39 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.59 | ppl   267.25\n",
            "| epoch  39 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.59 | ppl   267.91\n",
            "| epoch  39 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.63 | ppl   279.58\n",
            "| epoch  39 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.58 | ppl   263.80\n",
            "| epoch  39 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.61 | ppl   273.90\n",
            "| epoch  39 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.49 | ppl   241.96\n",
            "| epoch  39 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.27 | loss  5.59 | ppl   268.15\n",
            "| epoch  39 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.29 | loss  5.59 | ppl   268.61\n",
            "| epoch  39 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.15 | loss  5.54 | ppl   254.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 43.08s | valid loss  5.46 | valid ppl   234.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |   200/ 2928 batches | lr 0.01 | ms/batch 14.54 | loss  5.61 | ppl   271.89\n",
            "| epoch  40 |   400/ 2928 batches | lr 0.01 | ms/batch 14.23 | loss  5.64 | ppl   282.59\n",
            "| epoch  40 |   600/ 2928 batches | lr 0.01 | ms/batch 14.18 | loss  5.50 | ppl   245.81\n",
            "| epoch  40 |   800/ 2928 batches | lr 0.01 | ms/batch 14.19 | loss  5.58 | ppl   265.99\n",
            "| epoch  40 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.36 | loss  5.52 | ppl   248.51\n",
            "| epoch  40 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.23 | loss  5.59 | ppl   266.72\n",
            "| epoch  40 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.10 | loss  5.59 | ppl   267.46\n",
            "| epoch  40 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.08 | loss  5.63 | ppl   277.34\n",
            "| epoch  40 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.19 | loss  5.57 | ppl   263.32\n",
            "| epoch  40 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.25 | loss  5.61 | ppl   273.94\n",
            "| epoch  40 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.48 | ppl   241.00\n",
            "| epoch  40 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.59 | ppl   267.19\n",
            "| epoch  40 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.59 | ppl   267.91\n",
            "| epoch  40 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.25 | loss  5.54 | ppl   253.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 43.28s | valid loss  5.45 | valid ppl   233.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  41 |   200/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.60 | ppl   270.63\n",
            "| epoch  41 |   400/ 2928 batches | lr 0.01 | ms/batch 14.04 | loss  5.64 | ppl   280.98\n",
            "| epoch  41 |   600/ 2928 batches | lr 0.01 | ms/batch 14.23 | loss  5.50 | ppl   244.65\n",
            "| epoch  41 |   800/ 2928 batches | lr 0.01 | ms/batch 13.92 | loss  5.58 | ppl   265.09\n",
            "| epoch  41 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.93 | loss  5.51 | ppl   247.44\n",
            "| epoch  41 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.91 | loss  5.58 | ppl   265.71\n",
            "| epoch  41 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.59 | ppl   266.62\n",
            "| epoch  41 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.63 | ppl   277.29\n",
            "| epoch  41 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.57 | ppl   261.76\n",
            "| epoch  41 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.61 | ppl   272.39\n",
            "| epoch  41 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.48 | ppl   240.74\n",
            "| epoch  41 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.58 | ppl   266.29\n",
            "| epoch  41 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.59 | ppl   267.40\n",
            "| epoch  41 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.53 | ppl   252.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 43.12s | valid loss  5.45 | valid ppl   233.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |   200/ 2928 batches | lr 0.01 | ms/batch 14.05 | loss  5.60 | ppl   269.75\n",
            "| epoch  42 |   400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.64 | ppl   280.59\n",
            "| epoch  42 |   600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.50 | ppl   243.51\n",
            "| epoch  42 |   800/ 2928 batches | lr 0.01 | ms/batch 14.35 | loss  5.58 | ppl   264.55\n",
            "| epoch  42 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.51 | ppl   246.63\n",
            "| epoch  42 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.58 | ppl   264.83\n",
            "| epoch  42 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.58 | ppl   265.30\n",
            "| epoch  42 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.62 | ppl   275.52\n",
            "| epoch  42 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.12 | loss  5.57 | ppl   261.59\n",
            "| epoch  42 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.60 | ppl   271.63\n",
            "| epoch  42 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.48 | ppl   239.55\n",
            "| epoch  42 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.14 | loss  5.58 | ppl   265.38\n",
            "| epoch  42 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.23 | loss  5.59 | ppl   266.68\n",
            "| epoch  42 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.53 | ppl   251.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 43.01s | valid loss  5.45 | valid ppl   232.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |   200/ 2928 batches | lr 0.01 | ms/batch 14.24 | loss  5.59 | ppl   268.55\n",
            "| epoch  43 |   400/ 2928 batches | lr 0.01 | ms/batch 14.08 | loss  5.64 | ppl   280.12\n",
            "| epoch  43 |   600/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.49 | ppl   243.16\n",
            "| epoch  43 |   800/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.57 | ppl   263.20\n",
            "| epoch  43 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.09 | loss  5.50 | ppl   245.57\n",
            "| epoch  43 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.19 | loss  5.57 | ppl   263.26\n",
            "| epoch  43 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.92 | loss  5.58 | ppl   264.08\n",
            "| epoch  43 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.93 | loss  5.62 | ppl   275.70\n",
            "| epoch  43 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.56 | ppl   261.04\n",
            "| epoch  43 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.60 | ppl   270.28\n",
            "| epoch  43 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.48 | ppl   238.97\n",
            "| epoch  43 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.92 | loss  5.58 | ppl   264.71\n",
            "| epoch  43 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.93 | loss  5.58 | ppl   265.16\n",
            "| epoch  43 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.25 | loss  5.53 | ppl   251.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 42.91s | valid loss  5.45 | valid ppl   231.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |   200/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.59 | ppl   268.00\n",
            "| epoch  44 |   400/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.63 | ppl   279.01\n",
            "| epoch  44 |   600/ 2928 batches | lr 0.01 | ms/batch 14.32 | loss  5.49 | ppl   242.77\n",
            "| epoch  44 |   800/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.57 | ppl   262.78\n",
            "| epoch  44 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.00 | loss  5.50 | ppl   245.61\n",
            "| epoch  44 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.57 | ppl   262.99\n",
            "| epoch  44 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.29 | loss  5.58 | ppl   264.21\n",
            "| epoch  44 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.61 | ppl   274.18\n",
            "| epoch  44 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.56 | ppl   260.39\n",
            "| epoch  44 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.60 | ppl   269.97\n",
            "| epoch  44 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.47 | ppl   238.30\n",
            "| epoch  44 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.08 | loss  5.58 | ppl   264.16\n",
            "| epoch  44 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.58 | ppl   264.08\n",
            "| epoch  44 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.53 | ppl   251.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 43.23s | valid loss  5.44 | valid ppl   231.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |   200/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.59 | ppl   267.66\n",
            "| epoch  45 |   400/ 2928 batches | lr 0.01 | ms/batch 14.03 | loss  5.63 | ppl   278.23\n",
            "| epoch  45 |   600/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.49 | ppl   241.87\n",
            "| epoch  45 |   800/ 2928 batches | lr 0.01 | ms/batch 14.23 | loss  5.57 | ppl   262.26\n",
            "| epoch  45 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.05 | loss  5.50 | ppl   245.00\n",
            "| epoch  45 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.57 | ppl   262.05\n",
            "| epoch  45 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.58 | ppl   264.11\n",
            "| epoch  45 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.11 | loss  5.62 | ppl   275.04\n",
            "| epoch  45 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.16 | loss  5.56 | ppl   260.15\n",
            "| epoch  45 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.60 | ppl   269.21\n",
            "| epoch  45 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.47 | ppl   238.30\n",
            "| epoch  45 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.05 | loss  5.57 | ppl   263.38\n",
            "| epoch  45 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.29 | loss  5.57 | ppl   263.46\n",
            "| epoch  45 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.52 | ppl   249.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 42.93s | valid loss  5.44 | valid ppl   231.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |   200/ 2928 batches | lr 0.01 | ms/batch 14.18 | loss  5.59 | ppl   267.10\n",
            "| epoch  46 |   400/ 2928 batches | lr 0.01 | ms/batch 14.19 | loss  5.63 | ppl   277.64\n",
            "| epoch  46 |   600/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.49 | ppl   241.07\n",
            "| epoch  46 |   800/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.57 | ppl   261.44\n",
            "| epoch  46 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.50 | ppl   244.33\n",
            "| epoch  46 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.57 | ppl   261.61\n",
            "| epoch  46 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.57 | ppl   262.49\n",
            "| epoch  46 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.61 | ppl   272.96\n",
            "| epoch  46 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.56 | ppl   258.72\n",
            "| epoch  46 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.24 | loss  5.60 | ppl   269.39\n",
            "| epoch  46 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.47 | ppl   237.60\n",
            "| epoch  46 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.57 | ppl   263.14\n",
            "| epoch  46 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.57 | ppl   262.95\n",
            "| epoch  46 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.25 | loss  5.52 | ppl   249.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 42.95s | valid loss  5.44 | valid ppl   230.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |   200/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.58 | ppl   266.31\n",
            "| epoch  47 |   400/ 2928 batches | lr 0.01 | ms/batch 14.00 | loss  5.62 | ppl   276.50\n",
            "| epoch  47 |   600/ 2928 batches | lr 0.01 | ms/batch 14.37 | loss  5.48 | ppl   240.51\n",
            "| epoch  47 |   800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.56 | ppl   260.96\n",
            "| epoch  47 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.49 | ppl   243.42\n",
            "| epoch  47 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.57 | ppl   261.14\n",
            "| epoch  47 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.22 | loss  5.57 | ppl   262.26\n",
            "| epoch  47 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.03 | loss  5.61 | ppl   272.12\n",
            "| epoch  47 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.55 | ppl   258.26\n",
            "| epoch  47 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.92 | loss  5.59 | ppl   268.00\n",
            "| epoch  47 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.13 | loss  5.47 | ppl   237.23\n",
            "| epoch  47 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.17 | loss  5.57 | ppl   261.94\n",
            "| epoch  47 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.57 | ppl   263.12\n",
            "| epoch  47 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.52 | ppl   248.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 43.08s | valid loss  5.44 | valid ppl   230.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |   200/ 2928 batches | lr 0.01 | ms/batch 14.14 | loss  5.58 | ppl   265.38\n",
            "| epoch  48 |   400/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.62 | ppl   276.52\n",
            "| epoch  48 |   600/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.48 | ppl   240.20\n",
            "| epoch  48 |   800/ 2928 batches | lr 0.01 | ms/batch 14.06 | loss  5.56 | ppl   260.35\n",
            "| epoch  48 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.16 | loss  5.49 | ppl   242.46\n",
            "| epoch  48 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.56 | ppl   260.59\n",
            "| epoch  48 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.57 | ppl   262.01\n",
            "| epoch  48 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.61 | ppl   272.72\n",
            "| epoch  48 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.29 | loss  5.55 | ppl   257.83\n",
            "| epoch  48 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.59 | ppl   267.28\n",
            "| epoch  48 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.47 | ppl   236.66\n",
            "| epoch  48 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.57 | ppl   261.34\n",
            "| epoch  48 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.57 | ppl   262.08\n",
            "| epoch  48 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.52 | ppl   248.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 42.92s | valid loss  5.44 | valid ppl   229.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |   200/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.58 | ppl   265.65\n",
            "| epoch  49 |   400/ 2928 batches | lr 0.01 | ms/batch 14.31 | loss  5.62 | ppl   276.37\n",
            "| epoch  49 |   600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.48 | ppl   239.17\n",
            "| epoch  49 |   800/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.56 | ppl   260.01\n",
            "| epoch  49 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.49 | ppl   242.97\n",
            "| epoch  49 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.31 | loss  5.56 | ppl   259.75\n",
            "| epoch  49 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.56 | ppl   260.84\n",
            "| epoch  49 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.61 | ppl   271.79\n",
            "| epoch  49 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.55 | ppl   257.01\n",
            "| epoch  49 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.19 | loss  5.59 | ppl   267.31\n",
            "| epoch  49 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.05 | loss  5.46 | ppl   236.06\n",
            "| epoch  49 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.56 | ppl   261.10\n",
            "| epoch  49 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.57 | ppl   261.66\n",
            "| epoch  49 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.10 | loss  5.51 | ppl   247.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 43.02s | valid loss  5.43 | valid ppl   229.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |   200/ 2928 batches | lr 0.01 | ms/batch 14.04 | loss  5.58 | ppl   264.41\n",
            "| epoch  50 |   400/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.62 | ppl   275.74\n",
            "| epoch  50 |   600/ 2928 batches | lr 0.01 | ms/batch 14.20 | loss  5.48 | ppl   238.84\n",
            "| epoch  50 |   800/ 2928 batches | lr 0.01 | ms/batch 14.09 | loss  5.56 | ppl   259.10\n",
            "| epoch  50 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.49 | ppl   242.11\n",
            "| epoch  50 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.56 | ppl   259.15\n",
            "| epoch  50 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.11 | loss  5.56 | ppl   260.71\n",
            "| epoch  50 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.17 | loss  5.60 | ppl   271.08\n",
            "| epoch  50 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.55 | ppl   257.13\n",
            "| epoch  50 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.59 | ppl   266.55\n",
            "| epoch  50 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.03 | loss  5.46 | ppl   235.57\n",
            "| epoch  50 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.56 | ppl   260.68\n",
            "| epoch  50 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.56 | ppl   261.06\n",
            "| epoch  50 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.51 | ppl   247.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 43.01s | valid loss  5.43 | valid ppl   228.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  51 |   200/ 2928 batches | lr 0.01 | ms/batch 14.29 | loss  5.58 | ppl   264.18\n",
            "| epoch  51 |   400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.62 | ppl   275.14\n",
            "| epoch  51 |   600/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.47 | ppl   238.25\n",
            "| epoch  51 |   800/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.56 | ppl   258.94\n",
            "| epoch  51 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.32 | loss  5.49 | ppl   241.71\n",
            "| epoch  51 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.56 | ppl   259.13\n",
            "| epoch  51 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.56 | ppl   260.30\n",
            "| epoch  51 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.60 | ppl   271.08\n",
            "| epoch  51 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.32 | loss  5.55 | ppl   256.13\n",
            "| epoch  51 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.58 | ppl   266.08\n",
            "| epoch  51 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.46 | ppl   235.03\n",
            "| epoch  51 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.56 | ppl   260.19\n",
            "| epoch  51 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.27 | loss  5.56 | ppl   261.07\n",
            "| epoch  51 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.51 | ppl   246.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 42.95s | valid loss  5.43 | valid ppl   228.64\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |   200/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.57 | ppl   263.24\n",
            "| epoch  52 |   400/ 2928 batches | lr 0.01 | ms/batch 14.33 | loss  5.62 | ppl   275.09\n",
            "| epoch  52 |   600/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.47 | ppl   238.17\n",
            "| epoch  52 |   800/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.55 | ppl   258.33\n",
            "| epoch  52 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.48 | ppl   241.03\n",
            "| epoch  52 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.21 | loss  5.56 | ppl   258.86\n",
            "| epoch  52 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.08 | loss  5.56 | ppl   259.24\n",
            "| epoch  52 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.60 | ppl   270.58\n",
            "| epoch  52 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.54 | ppl   255.78\n",
            "| epoch  52 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.08 | loss  5.58 | ppl   265.31\n",
            "| epoch  52 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.20 | loss  5.46 | ppl   234.53\n",
            "| epoch  52 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.56 | ppl   259.43\n",
            "| epoch  52 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.56 | ppl   260.45\n",
            "| epoch  52 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.51 | ppl   246.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 42.97s | valid loss  5.43 | valid ppl   228.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |   200/ 2928 batches | lr 0.01 | ms/batch 14.04 | loss  5.57 | ppl   263.22\n",
            "| epoch  53 |   400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.61 | ppl   273.71\n",
            "| epoch  53 |   600/ 2928 batches | lr 0.01 | ms/batch 14.04 | loss  5.47 | ppl   238.27\n",
            "| epoch  53 |   800/ 2928 batches | lr 0.01 | ms/batch 14.25 | loss  5.55 | ppl   258.18\n",
            "| epoch  53 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.48 | ppl   240.40\n",
            "| epoch  53 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.56 | ppl   258.56\n",
            "| epoch  53 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.56 | ppl   258.78\n",
            "| epoch  53 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.60 | ppl   269.48\n",
            "| epoch  53 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.54 | ppl   255.47\n",
            "| epoch  53 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.58 | ppl   264.98\n",
            "| epoch  53 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.93 | loss  5.45 | ppl   233.84\n",
            "| epoch  53 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.27 | loss  5.56 | ppl   259.58\n",
            "| epoch  53 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.56 | ppl   259.99\n",
            "| epoch  53 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.51 | ppl   246.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 42.90s | valid loss  5.43 | valid ppl   227.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |   200/ 2928 batches | lr 0.01 | ms/batch 14.31 | loss  5.57 | ppl   263.50\n",
            "| epoch  54 |   400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.61 | ppl   273.36\n",
            "| epoch  54 |   600/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.47 | ppl   237.26\n",
            "| epoch  54 |   800/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.55 | ppl   258.09\n",
            "| epoch  54 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.48 | ppl   240.65\n",
            "| epoch  54 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.55 | ppl   257.67\n",
            "| epoch  54 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.56 | ppl   258.60\n",
            "| epoch  54 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.59 | ppl   268.91\n",
            "| epoch  54 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.17 | loss  5.54 | ppl   254.49\n",
            "| epoch  54 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.11 | loss  5.58 | ppl   264.70\n",
            "| epoch  54 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.46 | ppl   234.03\n",
            "| epoch  54 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.55 | ppl   258.41\n",
            "| epoch  54 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.11 | loss  5.56 | ppl   259.81\n",
            "| epoch  54 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.22 | loss  5.50 | ppl   245.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 42.96s | valid loss  5.43 | valid ppl   227.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |   200/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.57 | ppl   262.56\n",
            "| epoch  55 |   400/ 2928 batches | lr 0.01 | ms/batch 14.14 | loss  5.61 | ppl   273.45\n",
            "| epoch  55 |   600/ 2928 batches | lr 0.01 | ms/batch 14.12 | loss  5.46 | ppl   235.99\n",
            "| epoch  55 |   800/ 2928 batches | lr 0.01 | ms/batch 14.00 | loss  5.55 | ppl   256.97\n",
            "| epoch  55 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.94 | loss  5.48 | ppl   239.46\n",
            "| epoch  55 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.06 | loss  5.55 | ppl   257.29\n",
            "| epoch  55 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.20 | loss  5.55 | ppl   258.28\n",
            "| epoch  55 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.59 | ppl   268.34\n",
            "| epoch  55 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.54 | ppl   254.78\n",
            "| epoch  55 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.58 | ppl   264.34\n",
            "| epoch  55 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.27 | loss  5.46 | ppl   233.95\n",
            "| epoch  55 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.55 | ppl   258.30\n",
            "| epoch  55 |  2600/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.56 | ppl   258.64\n",
            "| epoch  55 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.50 | ppl   245.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 43.07s | valid loss  5.43 | valid ppl   227.35\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |   200/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.57 | ppl   261.73\n",
            "| epoch  56 |   400/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.61 | ppl   273.17\n",
            "| epoch  56 |   600/ 2928 batches | lr 0.01 | ms/batch 14.04 | loss  5.47 | ppl   236.62\n",
            "| epoch  56 |   800/ 2928 batches | lr 0.01 | ms/batch 14.31 | loss  5.55 | ppl   257.35\n",
            "| epoch  56 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.48 | ppl   239.70\n",
            "| epoch  56 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.55 | ppl   256.62\n",
            "| epoch  56 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.55 | ppl   257.57\n",
            "| epoch  56 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.29 | loss  5.59 | ppl   269.02\n",
            "| epoch  56 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.00 | loss  5.54 | ppl   254.27\n",
            "| epoch  56 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.57 | ppl   263.66\n",
            "| epoch  56 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.45 | ppl   233.36\n",
            "| epoch  56 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.22 | loss  5.55 | ppl   258.02\n",
            "| epoch  56 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.05 | loss  5.56 | ppl   259.17\n",
            "| epoch  56 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.03 | loss  5.50 | ppl   244.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 42.95s | valid loss  5.43 | valid ppl   227.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |   200/ 2928 batches | lr 0.01 | ms/batch 14.40 | loss  5.57 | ppl   261.31\n",
            "| epoch  57 |   400/ 2928 batches | lr 0.01 | ms/batch 14.06 | loss  5.61 | ppl   272.20\n",
            "| epoch  57 |   600/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.47 | ppl   236.40\n",
            "| epoch  57 |   800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.55 | ppl   256.28\n",
            "| epoch  57 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.20 | loss  5.48 | ppl   239.23\n",
            "| epoch  57 |  1200/ 2928 batches | lr 0.01 | ms/batch 14.10 | loss  5.55 | ppl   256.55\n",
            "| epoch  57 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.55 | ppl   257.42\n",
            "| epoch  57 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.59 | ppl   268.13\n",
            "| epoch  57 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.10 | loss  5.54 | ppl   254.49\n",
            "| epoch  57 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.27 | loss  5.58 | ppl   263.80\n",
            "| epoch  57 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.00 | loss  5.45 | ppl   233.21\n",
            "| epoch  57 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.55 | ppl   257.85\n",
            "| epoch  57 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.03 | loss  5.56 | ppl   258.91\n",
            "| epoch  57 |  2800/ 2928 batches | lr 0.01 | ms/batch 14.26 | loss  5.50 | ppl   244.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 43.05s | valid loss  5.42 | valid ppl   226.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |   200/ 2928 batches | lr 0.01 | ms/batch 14.07 | loss  5.57 | ppl   261.52\n",
            "| epoch  58 |   400/ 2928 batches | lr 0.01 | ms/batch 14.10 | loss  5.61 | ppl   272.04\n",
            "| epoch  58 |   600/ 2928 batches | lr 0.01 | ms/batch 14.24 | loss  5.46 | ppl   235.97\n",
            "| epoch  58 |   800/ 2928 batches | lr 0.01 | ms/batch 13.99 | loss  5.55 | ppl   256.70\n",
            "| epoch  58 |  1000/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.48 | ppl   238.93\n",
            "| epoch  58 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.55 | ppl   256.23\n",
            "| epoch  58 |  1400/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.55 | ppl   257.57\n",
            "| epoch  58 |  1600/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.59 | ppl   268.35\n",
            "| epoch  58 |  1800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.54 | ppl   253.82\n",
            "| epoch  58 |  2000/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.58 | ppl   264.16\n",
            "| epoch  58 |  2200/ 2928 batches | lr 0.01 | ms/batch 14.32 | loss  5.45 | ppl   232.27\n",
            "| epoch  58 |  2400/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.55 | ppl   257.12\n",
            "| epoch  58 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.01 | loss  5.55 | ppl   258.20\n",
            "| epoch  58 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.50 | ppl   243.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 43.22s | valid loss  5.42 | valid ppl   226.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |   200/ 2928 batches | lr 0.01 | ms/batch 14.06 | loss  5.57 | ppl   261.17\n",
            "| epoch  59 |   400/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.61 | ppl   272.69\n",
            "| epoch  59 |   600/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.46 | ppl   235.86\n",
            "| epoch  59 |   800/ 2928 batches | lr 0.01 | ms/batch 14.30 | loss  5.54 | ppl   255.72\n",
            "| epoch  59 |  1000/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.48 | ppl   239.00\n",
            "| epoch  59 |  1200/ 2928 batches | lr 0.01 | ms/batch 13.97 | loss  5.54 | ppl   255.61\n",
            "| epoch  59 |  1400/ 2928 batches | lr 0.01 | ms/batch 13.98 | loss  5.55 | ppl   257.57\n",
            "| epoch  59 |  1600/ 2928 batches | lr 0.01 | ms/batch 14.22 | loss  5.59 | ppl   268.12\n",
            "| epoch  59 |  1800/ 2928 batches | lr 0.01 | ms/batch 14.02 | loss  5.54 | ppl   253.58\n",
            "| epoch  59 |  2000/ 2928 batches | lr 0.01 | ms/batch 13.95 | loss  5.57 | ppl   262.85\n",
            "| epoch  59 |  2200/ 2928 batches | lr 0.01 | ms/batch 13.96 | loss  5.45 | ppl   232.35\n",
            "| epoch  59 |  2400/ 2928 batches | lr 0.01 | ms/batch 14.11 | loss  5.55 | ppl   257.25\n",
            "| epoch  59 |  2600/ 2928 batches | lr 0.01 | ms/batch 14.14 | loss  5.55 | ppl   257.89\n",
            "| epoch  59 |  2800/ 2928 batches | lr 0.01 | ms/batch 13.91 | loss  5.50 | ppl   243.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 42.88s | valid loss  5.42 | valid ppl   226.35\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |   200/ 2928 batches | lr 0.00 | ms/batch 14.17 | loss  5.56 | ppl   260.42\n",
            "| epoch  60 |   400/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.61 | ppl   271.84\n",
            "| epoch  60 |   600/ 2928 batches | lr 0.00 | ms/batch 13.93 | loss  5.46 | ppl   235.62\n",
            "| epoch  60 |   800/ 2928 batches | lr 0.00 | ms/batch 13.88 | loss  5.54 | ppl   255.36\n",
            "| epoch  60 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.47 | ppl   238.30\n",
            "| epoch  60 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.54 | ppl   255.38\n",
            "| epoch  60 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.93 | loss  5.55 | ppl   256.65\n",
            "| epoch  60 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.87 | loss  5.59 | ppl   267.45\n",
            "| epoch  60 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.53 | ppl   253.21\n",
            "| epoch  60 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.22 | loss  5.57 | ppl   262.05\n",
            "| epoch  60 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.45 | ppl   232.50\n",
            "| epoch  60 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.55 | ppl   256.84\n",
            "| epoch  60 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.55 | ppl   257.52\n",
            "| epoch  60 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.29 | loss  5.50 | ppl   243.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time: 42.85s | valid loss  5.42 | valid ppl   226.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  61 |   200/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.56 | ppl   260.27\n",
            "| epoch  61 |   400/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.61 | ppl   271.90\n",
            "| epoch  61 |   600/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.46 | ppl   234.95\n",
            "| epoch  61 |   800/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   255.84\n",
            "| epoch  61 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.47 | ppl   238.25\n",
            "| epoch  61 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.54 | ppl   255.71\n",
            "| epoch  61 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.27 | loss  5.55 | ppl   256.95\n",
            "| epoch  61 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.59 | ppl   267.71\n",
            "| epoch  61 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.53 | ppl   252.53\n",
            "| epoch  61 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.57 | ppl   262.24\n",
            "| epoch  61 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.26 | loss  5.45 | ppl   231.94\n",
            "| epoch  61 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.55 | ppl   256.11\n",
            "| epoch  61 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.55 | ppl   257.70\n",
            "| epoch  61 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.49 | ppl   243.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time: 43.26s | valid loss  5.42 | valid ppl   225.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |   200/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.56 | ppl   259.96\n",
            "| epoch  62 |   400/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.60 | ppl   271.61\n",
            "| epoch  62 |   600/ 2928 batches | lr 0.00 | ms/batch 13.92 | loss  5.46 | ppl   234.89\n",
            "| epoch  62 |   800/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.54 | ppl   255.36\n",
            "| epoch  62 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.47 | ppl   237.50\n",
            "| epoch  62 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.54 | ppl   255.69\n",
            "| epoch  62 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.55 | ppl   257.11\n",
            "| epoch  62 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.11 | loss  5.59 | ppl   266.76\n",
            "| epoch  62 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.53 | ppl   252.60\n",
            "| epoch  62 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.93 | loss  5.57 | ppl   262.76\n",
            "| epoch  62 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.45 | ppl   231.92\n",
            "| epoch  62 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.55 | ppl   256.16\n",
            "| epoch  62 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.23 | loss  5.55 | ppl   257.26\n",
            "| epoch  62 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.50 | ppl   243.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time: 42.87s | valid loss  5.42 | valid ppl   225.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |   200/ 2928 batches | lr 0.00 | ms/batch 14.13 | loss  5.56 | ppl   260.46\n",
            "| epoch  63 |   400/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.60 | ppl   270.55\n",
            "| epoch  63 |   600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.45 | ppl   233.77\n",
            "| epoch  63 |   800/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.54 | ppl   255.04\n",
            "| epoch  63 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.47 | ppl   237.39\n",
            "| epoch  63 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.30 | loss  5.54 | ppl   255.04\n",
            "| epoch  63 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.55 | ppl   256.06\n",
            "| epoch  63 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.59 | ppl   266.74\n",
            "| epoch  63 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   252.49\n",
            "| epoch  63 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.57 | ppl   261.75\n",
            "| epoch  63 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.44 | ppl   231.52\n",
            "| epoch  63 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.55 | ppl   256.05\n",
            "| epoch  63 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.55 | ppl   256.80\n",
            "| epoch  63 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.29 | loss  5.49 | ppl   242.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time: 43.05s | valid loss  5.42 | valid ppl   225.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |   200/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.56 | ppl   259.44\n",
            "| epoch  64 |   400/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.60 | ppl   270.56\n",
            "| epoch  64 |   600/ 2928 batches | lr 0.00 | ms/batch 14.36 | loss  5.46 | ppl   234.87\n",
            "| epoch  64 |   800/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.54 | ppl   254.56\n",
            "| epoch  64 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.92 | loss  5.47 | ppl   237.32\n",
            "| epoch  64 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.54 | ppl   254.84\n",
            "| epoch  64 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.21 | loss  5.55 | ppl   256.36\n",
            "| epoch  64 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.59 | ppl   266.95\n",
            "| epoch  64 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.53 | ppl   252.57\n",
            "| epoch  64 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.90 | loss  5.57 | ppl   261.27\n",
            "| epoch  64 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.44 | ppl   230.93\n",
            "| epoch  64 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.54 | ppl   255.90\n",
            "| epoch  64 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.55 | ppl   257.23\n",
            "| epoch  64 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.49 | ppl   242.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time: 43.07s | valid loss  5.42 | valid ppl   225.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |   200/ 2928 batches | lr 0.00 | ms/batch 14.13 | loss  5.56 | ppl   259.00\n",
            "| epoch  65 |   400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.60 | ppl   271.25\n",
            "| epoch  65 |   600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.46 | ppl   234.61\n",
            "| epoch  65 |   800/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.54 | ppl   254.30\n",
            "| epoch  65 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.20 | loss  5.47 | ppl   237.02\n",
            "| epoch  65 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.54 | ppl   253.95\n",
            "| epoch  65 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.55 | ppl   256.01\n",
            "| epoch  65 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.58 | ppl   266.17\n",
            "| epoch  65 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.25 | loss  5.53 | ppl   252.24\n",
            "| epoch  65 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.56 | ppl   261.06\n",
            "| epoch  65 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.44 | ppl   230.63\n",
            "| epoch  65 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   255.89\n",
            "| epoch  65 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.55 | ppl   256.43\n",
            "| epoch  65 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.49 | ppl   242.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time: 43.01s | valid loss  5.42 | valid ppl   225.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |   200/ 2928 batches | lr 0.00 | ms/batch 14.10 | loss  5.56 | ppl   259.43\n",
            "| epoch  66 |   400/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.60 | ppl   270.80\n",
            "| epoch  66 |   600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.46 | ppl   234.71\n",
            "| epoch  66 |   800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.54 | ppl   254.20\n",
            "| epoch  66 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.47 | ppl   237.22\n",
            "| epoch  66 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.30 | loss  5.54 | ppl   254.49\n",
            "| epoch  66 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.54 | ppl   255.61\n",
            "| epoch  66 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.58 | ppl   266.03\n",
            "| epoch  66 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.53 | ppl   252.03\n",
            "| epoch  66 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.57 | ppl   261.80\n",
            "| epoch  66 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.44 | ppl   230.76\n",
            "| epoch  66 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   255.69\n",
            "| epoch  66 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.54 | ppl   255.65\n",
            "| epoch  66 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.19 | loss  5.49 | ppl   241.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time: 43.04s | valid loss  5.42 | valid ppl   224.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |   200/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.56 | ppl   259.07\n",
            "| epoch  67 |   400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.60 | ppl   269.80\n",
            "| epoch  67 |   600/ 2928 batches | lr 0.00 | ms/batch 14.20 | loss  5.46 | ppl   234.24\n",
            "| epoch  67 |   800/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.54 | ppl   254.64\n",
            "| epoch  67 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.47 | ppl   237.04\n",
            "| epoch  67 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.54 | ppl   253.92\n",
            "| epoch  67 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.13 | loss  5.54 | ppl   255.62\n",
            "| epoch  67 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.58 | ppl   266.07\n",
            "| epoch  67 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.53 | ppl   252.05\n",
            "| epoch  67 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.57 | ppl   261.52\n",
            "| epoch  67 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.44 | ppl   230.77\n",
            "| epoch  67 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.19 | loss  5.54 | ppl   254.57\n",
            "| epoch  67 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.91 | loss  5.55 | ppl   256.53\n",
            "| epoch  67 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.49 | ppl   242.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time: 42.97s | valid loss  5.42 | valid ppl   224.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |   200/ 2928 batches | lr 0.00 | ms/batch 14.19 | loss  5.56 | ppl   258.86\n",
            "| epoch  68 |   400/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.60 | ppl   269.53\n",
            "| epoch  68 |   600/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.45 | ppl   233.67\n",
            "| epoch  68 |   800/ 2928 batches | lr 0.00 | ms/batch 14.16 | loss  5.54 | ppl   254.29\n",
            "| epoch  68 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.45 | loss  5.47 | ppl   237.35\n",
            "| epoch  68 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.53 | ppl   253.29\n",
            "| epoch  68 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.54 | ppl   255.14\n",
            "| epoch  68 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.58 | ppl   265.51\n",
            "| epoch  68 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.53 | ppl   251.30\n",
            "| epoch  68 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.56 | ppl   261.05\n",
            "| epoch  68 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.44 | ppl   230.69\n",
            "| epoch  68 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.54 | ppl   254.46\n",
            "| epoch  68 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.55 | ppl   256.57\n",
            "| epoch  68 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.49 | ppl   242.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time: 43.04s | valid loss  5.41 | valid ppl   224.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |   200/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.55 | ppl   258.06\n",
            "| epoch  69 |   400/ 2928 batches | lr 0.00 | ms/batch 14.34 | loss  5.60 | ppl   269.85\n",
            "| epoch  69 |   600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.45 | ppl   233.61\n",
            "| epoch  69 |   800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.54 | ppl   254.12\n",
            "| epoch  69 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.47 | ppl   237.22\n",
            "| epoch  69 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.26 | loss  5.53 | ppl   252.74\n",
            "| epoch  69 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.54 | ppl   255.33\n",
            "| epoch  69 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.59 | ppl   266.41\n",
            "| epoch  69 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.53 | ppl   251.13\n",
            "| epoch  69 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.19 | loss  5.57 | ppl   261.48\n",
            "| epoch  69 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.15 | loss  5.44 | ppl   229.77\n",
            "| epoch  69 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.54 | ppl   254.45\n",
            "| epoch  69 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.54 | ppl   255.21\n",
            "| epoch  69 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.49 | ppl   241.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time: 43.11s | valid loss  5.41 | valid ppl   224.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |   200/ 2928 batches | lr 0.00 | ms/batch 14.10 | loss  5.55 | ppl   258.30\n",
            "| epoch  70 |   400/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.60 | ppl   269.40\n",
            "| epoch  70 |   600/ 2928 batches | lr 0.00 | ms/batch 14.16 | loss  5.45 | ppl   233.52\n",
            "| epoch  70 |   800/ 2928 batches | lr 0.00 | ms/batch 14.17 | loss  5.53 | ppl   253.32\n",
            "| epoch  70 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.47 | ppl   236.35\n",
            "| epoch  70 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.54 | ppl   253.62\n",
            "| epoch  70 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.54 | ppl   254.52\n",
            "| epoch  70 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.58 | ppl   265.50\n",
            "| epoch  70 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.52 | ppl   250.66\n",
            "| epoch  70 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.56 | ppl   260.74\n",
            "| epoch  70 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.44 | ppl   230.05\n",
            "| epoch  70 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.44 | loss  5.54 | ppl   254.30\n",
            "| epoch  70 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.54 | ppl   255.17\n",
            "| epoch  70 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.49 | ppl   241.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time: 43.12s | valid loss  5.41 | valid ppl   224.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  71 |   200/ 2928 batches | lr 0.00 | ms/batch 14.41 | loss  5.55 | ppl   257.81\n",
            "| epoch  71 |   400/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.60 | ppl   269.60\n",
            "| epoch  71 |   600/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.45 | ppl   233.91\n",
            "| epoch  71 |   800/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.53 | ppl   253.04\n",
            "| epoch  71 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.39 | loss  5.46 | ppl   235.99\n",
            "| epoch  71 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.53 | ppl   252.65\n",
            "| epoch  71 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.54 | ppl   254.60\n",
            "| epoch  71 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.58 | ppl   265.53\n",
            "| epoch  71 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.53 | ppl   250.98\n",
            "| epoch  71 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.56 | ppl   260.77\n",
            "| epoch  71 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.44 | ppl   230.25\n",
            "| epoch  71 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.54 | ppl   254.12\n",
            "| epoch  71 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.20 | loss  5.54 | ppl   255.50\n",
            "| epoch  71 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.48 | ppl   240.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time: 43.09s | valid loss  5.41 | valid ppl   224.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |   200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.55 | ppl   257.22\n",
            "| epoch  72 |   400/ 2928 batches | lr 0.00 | ms/batch 14.29 | loss  5.60 | ppl   269.16\n",
            "| epoch  72 |   600/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.45 | ppl   233.28\n",
            "| epoch  72 |   800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.53 | ppl   253.30\n",
            "| epoch  72 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.47 | ppl   236.74\n",
            "| epoch  72 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.16 | loss  5.53 | ppl   253.32\n",
            "| epoch  72 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.16 | loss  5.54 | ppl   254.74\n",
            "| epoch  72 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.58 | ppl   264.97\n",
            "| epoch  72 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.52 | ppl   250.50\n",
            "| epoch  72 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.56 | ppl   260.03\n",
            "| epoch  72 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.27 | loss  5.44 | ppl   230.01\n",
            "| epoch  72 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.54 | ppl   253.76\n",
            "| epoch  72 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   255.15\n",
            "| epoch  72 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.48 | ppl   240.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time: 43.12s | valid loss  5.41 | valid ppl   224.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |   200/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.55 | ppl   257.57\n",
            "| epoch  73 |   400/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.60 | ppl   269.56\n",
            "| epoch  73 |   600/ 2928 batches | lr 0.00 | ms/batch 14.12 | loss  5.45 | ppl   232.98\n",
            "| epoch  73 |   800/ 2928 batches | lr 0.00 | ms/batch 14.35 | loss  5.53 | ppl   252.95\n",
            "| epoch  73 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.46 | ppl   235.90\n",
            "| epoch  73 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   252.99\n",
            "| epoch  73 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.54 | ppl   254.73\n",
            "| epoch  73 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.28 | loss  5.58 | ppl   265.19\n",
            "| epoch  73 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.52 | ppl   250.80\n",
            "| epoch  73 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.56 | ppl   260.38\n",
            "| epoch  73 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.44 | ppl   229.85\n",
            "| epoch  73 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.54 | ppl   254.22\n",
            "| epoch  73 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.54 | ppl   255.57\n",
            "| epoch  73 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.48 | ppl   240.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time: 43.00s | valid loss  5.41 | valid ppl   224.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |   200/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.55 | ppl   257.31\n",
            "| epoch  74 |   400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.59 | ppl   268.47\n",
            "| epoch  74 |   600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.45 | ppl   233.41\n",
            "| epoch  74 |   800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.53 | ppl   253.07\n",
            "| epoch  74 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.34 | loss  5.46 | ppl   236.10\n",
            "| epoch  74 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.54 | ppl   253.49\n",
            "| epoch  74 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.54 | ppl   254.15\n",
            "| epoch  74 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.58 | ppl   264.94\n",
            "| epoch  74 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.22 | loss  5.52 | ppl   250.78\n",
            "| epoch  74 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.12 | loss  5.56 | ppl   259.37\n",
            "| epoch  74 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.44 | ppl   229.60\n",
            "| epoch  74 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.54 | ppl   253.94\n",
            "| epoch  74 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.54 | ppl   255.33\n",
            "| epoch  74 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.48 | ppl   240.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time: 43.09s | valid loss  5.41 | valid ppl   223.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  75 |   200/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.55 | ppl   257.31\n",
            "| epoch  75 |   400/ 2928 batches | lr 0.00 | ms/batch 14.17 | loss  5.59 | ppl   268.48\n",
            "| epoch  75 |   600/ 2928 batches | lr 0.00 | ms/batch 14.17 | loss  5.45 | ppl   232.96\n",
            "| epoch  75 |   800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.54 | ppl   253.51\n",
            "| epoch  75 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.46 | ppl   235.17\n",
            "| epoch  75 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.53 | ppl   252.75\n",
            "| epoch  75 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.26 | loss  5.54 | ppl   254.47\n",
            "| epoch  75 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.58 | ppl   265.32\n",
            "| epoch  75 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.52 | ppl   249.98\n",
            "| epoch  75 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.56 | ppl   259.92\n",
            "| epoch  75 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.35 | loss  5.44 | ppl   230.09\n",
            "| epoch  75 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.54 | ppl   253.95\n",
            "| epoch  75 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.54 | ppl   254.38\n",
            "| epoch  75 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.48 | ppl   240.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time: 43.20s | valid loss  5.41 | valid ppl   223.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |   200/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.55 | ppl   257.51\n",
            "| epoch  76 |   400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.59 | ppl   268.75\n",
            "| epoch  76 |   600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.45 | ppl   232.61\n",
            "| epoch  76 |   800/ 2928 batches | lr 0.00 | ms/batch 14.39 | loss  5.53 | ppl   252.70\n",
            "| epoch  76 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.46 | ppl   235.77\n",
            "| epoch  76 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.53 | ppl   252.93\n",
            "| epoch  76 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.54 | ppl   254.30\n",
            "| epoch  76 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.37 | loss  5.58 | ppl   264.65\n",
            "| epoch  76 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.52 | ppl   250.16\n",
            "| epoch  76 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.56 | ppl   259.76\n",
            "| epoch  76 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.43 | ppl   228.98\n",
            "| epoch  76 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.23 | loss  5.54 | ppl   253.74\n",
            "| epoch  76 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.12 | loss  5.54 | ppl   254.79\n",
            "| epoch  76 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.48 | ppl   240.74\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time: 43.04s | valid loss  5.41 | valid ppl   223.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |   200/ 2928 batches | lr 0.00 | ms/batch 14.35 | loss  5.55 | ppl   257.39\n",
            "| epoch  77 |   400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.59 | ppl   268.64\n",
            "| epoch  77 |   600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.45 | ppl   232.62\n",
            "| epoch  77 |   800/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.53 | ppl   252.06\n",
            "| epoch  77 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.19 | loss  5.46 | ppl   235.93\n",
            "| epoch  77 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.53 | ppl   252.33\n",
            "| epoch  77 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.54 | ppl   254.34\n",
            "| epoch  77 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.58 | ppl   264.79\n",
            "| epoch  77 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.52 | ppl   250.09\n",
            "| epoch  77 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.56 | ppl   259.55\n",
            "| epoch  77 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.43 | ppl   228.70\n",
            "| epoch  77 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.94 | loss  5.54 | ppl   253.84\n",
            "| epoch  77 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.54 | ppl   254.79\n",
            "| epoch  77 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.48 | ppl   240.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time: 43.03s | valid loss  5.41 | valid ppl   223.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |   200/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.55 | ppl   257.08\n",
            "| epoch  78 |   400/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.59 | ppl   268.76\n",
            "| epoch  78 |   600/ 2928 batches | lr 0.00 | ms/batch 14.25 | loss  5.45 | ppl   232.82\n",
            "| epoch  78 |   800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   252.78\n",
            "| epoch  78 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.46 | ppl   234.91\n",
            "| epoch  78 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.53 | ppl   252.70\n",
            "| epoch  78 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.34 | loss  5.54 | ppl   253.97\n",
            "| epoch  78 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.58 | ppl   264.07\n",
            "| epoch  78 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.52 | ppl   249.76\n",
            "| epoch  78 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.56 | ppl   259.63\n",
            "| epoch  78 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.43 | ppl   229.13\n",
            "| epoch  78 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.54 | ppl   253.72\n",
            "| epoch  78 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.54 | ppl   254.79\n",
            "| epoch  78 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.48 | ppl   240.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time: 43.26s | valid loss  5.41 | valid ppl   223.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |   200/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.55 | ppl   257.59\n",
            "| epoch  79 |   400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.59 | ppl   268.15\n",
            "| epoch  79 |   600/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.45 | ppl   232.70\n",
            "| epoch  79 |   800/ 2928 batches | lr 0.00 | ms/batch 14.37 | loss  5.53 | ppl   252.39\n",
            "| epoch  79 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.46 | ppl   234.83\n",
            "| epoch  79 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.53 | ppl   251.33\n",
            "| epoch  79 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.54 | ppl   253.68\n",
            "| epoch  79 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.25 | loss  5.58 | ppl   264.09\n",
            "| epoch  79 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.16 | loss  5.52 | ppl   250.63\n",
            "| epoch  79 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.56 | ppl   259.14\n",
            "| epoch  79 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.43 | ppl   228.75\n",
            "| epoch  79 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.20 | loss  5.53 | ppl   253.09\n",
            "| epoch  79 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.28 | loss  5.54 | ppl   253.88\n",
            "| epoch  79 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.48 | ppl   240.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time: 43.15s | valid loss  5.41 | valid ppl   223.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |   200/ 2928 batches | lr 0.00 | ms/batch 14.30 | loss  5.55 | ppl   256.84\n",
            "| epoch  80 |   400/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.59 | ppl   268.84\n",
            "| epoch  80 |   600/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.45 | ppl   232.26\n",
            "| epoch  80 |   800/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.53 | ppl   252.66\n",
            "| epoch  80 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.46 | ppl   235.13\n",
            "| epoch  80 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.53 | ppl   251.60\n",
            "| epoch  80 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.54 | ppl   253.51\n",
            "| epoch  80 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.58 | ppl   264.59\n",
            "| epoch  80 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.06 | loss  5.52 | ppl   249.38\n",
            "| epoch  80 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.38 | loss  5.56 | ppl   259.24\n",
            "| epoch  80 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.43 | ppl   229.10\n",
            "| epoch  80 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.54 | ppl   253.53\n",
            "| epoch  80 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.54 | ppl   254.54\n",
            "| epoch  80 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.34 | loss  5.48 | ppl   240.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time: 43.18s | valid loss  5.41 | valid ppl   223.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  81 |   200/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.55 | ppl   257.46\n",
            "| epoch  81 |   400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.59 | ppl   268.72\n",
            "| epoch  81 |   600/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.45 | ppl   232.24\n",
            "| epoch  81 |   800/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.53 | ppl   252.22\n",
            "| epoch  81 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.46 | ppl   235.27\n",
            "| epoch  81 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.53 | ppl   251.85\n",
            "| epoch  81 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.54 | ppl   254.12\n",
            "| epoch  81 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.58 | ppl   264.04\n",
            "| epoch  81 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.52 | ppl   249.63\n",
            "| epoch  81 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.56 | ppl   258.94\n",
            "| epoch  81 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.16 | loss  5.43 | ppl   228.30\n",
            "| epoch  81 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.10 | loss  5.53 | ppl   253.36\n",
            "| epoch  81 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.54 | ppl   254.26\n",
            "| epoch  81 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.48 | ppl   239.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time: 43.36s | valid loss  5.41 | valid ppl   223.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |   200/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.55 | ppl   256.14\n",
            "| epoch  82 |   400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.59 | ppl   268.47\n",
            "| epoch  82 |   600/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.45 | ppl   231.94\n",
            "| epoch  82 |   800/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.53 | ppl   252.33\n",
            "| epoch  82 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.46 | ppl   235.57\n",
            "| epoch  82 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   251.50\n",
            "| epoch  82 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.54 | ppl   254.15\n",
            "| epoch  82 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.13 | loss  5.57 | ppl   263.54\n",
            "| epoch  82 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.52 | ppl   249.31\n",
            "| epoch  82 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.56 | ppl   259.26\n",
            "| epoch  82 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.43 | ppl   229.29\n",
            "| epoch  82 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.53 | ppl   252.72\n",
            "| epoch  82 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.54 | ppl   253.75\n",
            "| epoch  82 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.48 | ppl   240.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time: 43.01s | valid loss  5.41 | valid ppl   223.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |   200/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.55 | ppl   256.89\n",
            "| epoch  83 |   400/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.59 | ppl   267.84\n",
            "| epoch  83 |   600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.45 | ppl   231.94\n",
            "| epoch  83 |   800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.53 | ppl   251.70\n",
            "| epoch  83 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.46 | ppl   234.99\n",
            "| epoch  83 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.53 | ppl   251.62\n",
            "| epoch  83 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.53 | ppl   253.28\n",
            "| epoch  83 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.58 | ppl   264.06\n",
            "| epoch  83 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.52 | ppl   249.79\n",
            "| epoch  83 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.56 | ppl   259.28\n",
            "| epoch  83 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.43 | ppl   228.68\n",
            "| epoch  83 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   254.16\n",
            "| epoch  83 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   254.02\n",
            "| epoch  83 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.48 | ppl   239.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time: 43.06s | valid loss  5.41 | valid ppl   223.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |   200/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.55 | ppl   256.29\n",
            "| epoch  84 |   400/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.59 | ppl   267.72\n",
            "| epoch  84 |   600/ 2928 batches | lr 0.00 | ms/batch 14.27 | loss  5.45 | ppl   231.71\n",
            "| epoch  84 |   800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   251.85\n",
            "| epoch  84 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.46 | ppl   234.87\n",
            "| epoch  84 |  1200/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.53 | ppl   251.18\n",
            "| epoch  84 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.20 | loss  5.53 | ppl   253.26\n",
            "| epoch  84 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.12 | loss  5.58 | ppl   264.15\n",
            "| epoch  84 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.52 | ppl   248.83\n",
            "| epoch  84 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.56 | ppl   258.92\n",
            "| epoch  84 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.43 | ppl   228.48\n",
            "| epoch  84 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.24 | loss  5.53 | ppl   252.51\n",
            "| epoch  84 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   254.21\n",
            "| epoch  84 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.48 | ppl   239.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time: 43.11s | valid loss  5.41 | valid ppl   223.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |   200/ 2928 batches | lr 0.00 | ms/batch 14.21 | loss  5.55 | ppl   256.18\n",
            "| epoch  85 |   400/ 2928 batches | lr 0.00 | ms/batch 13.95 | loss  5.59 | ppl   268.15\n",
            "| epoch  85 |   600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.45 | ppl   231.89\n",
            "| epoch  85 |   800/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.53 | ppl   252.45\n",
            "| epoch  85 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.27 | loss  5.46 | ppl   234.59\n",
            "| epoch  85 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.53 | ppl   251.58\n",
            "| epoch  85 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   253.53\n",
            "| epoch  85 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.57 | ppl   263.70\n",
            "| epoch  85 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.35 | loss  5.52 | ppl   249.49\n",
            "| epoch  85 |  2000/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.56 | ppl   259.33\n",
            "| epoch  85 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.43 | ppl   228.89\n",
            "| epoch  85 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.53 | ppl   252.00\n",
            "| epoch  85 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.54 | ppl   253.62\n",
            "| epoch  85 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.48 | ppl   239.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time: 43.04s | valid loss  5.41 | valid ppl   222.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |   200/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.54 | ppl   255.94\n",
            "| epoch  86 |   400/ 2928 batches | lr 0.00 | ms/batch 14.35 | loss  5.59 | ppl   267.51\n",
            "| epoch  86 |   600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.44 | ppl   231.57\n",
            "| epoch  86 |   800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   252.60\n",
            "| epoch  86 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.46 | ppl   235.26\n",
            "| epoch  86 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.53 | ppl   251.36\n",
            "| epoch  86 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   252.82\n",
            "| epoch  86 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.58 | ppl   264.19\n",
            "| epoch  86 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.52 | ppl   249.23\n",
            "| epoch  86 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.18 | loss  5.56 | ppl   259.16\n",
            "| epoch  86 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.43 | ppl   228.10\n",
            "| epoch  86 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.53 | ppl   252.56\n",
            "| epoch  86 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   253.76\n",
            "| epoch  86 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.14 | loss  5.48 | ppl   239.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time: 43.06s | valid loss  5.41 | valid ppl   222.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |   200/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.54 | ppl   255.88\n",
            "| epoch  87 |   400/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.59 | ppl   268.01\n",
            "| epoch  87 |   600/ 2928 batches | lr 0.00 | ms/batch 14.21 | loss  5.45 | ppl   231.85\n",
            "| epoch  87 |   800/ 2928 batches | lr 0.00 | ms/batch 14.15 | loss  5.53 | ppl   252.29\n",
            "| epoch  87 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.46 | ppl   234.66\n",
            "| epoch  87 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.53 | ppl   251.68\n",
            "| epoch  87 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.08 | loss  5.54 | ppl   253.44\n",
            "| epoch  87 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.27 | loss  5.58 | ppl   263.98\n",
            "| epoch  87 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.52 | ppl   248.90\n",
            "| epoch  87 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.55 | ppl   258.43\n",
            "| epoch  87 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.43 | ppl   228.10\n",
            "| epoch  87 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.41 | loss  5.53 | ppl   252.70\n",
            "| epoch  87 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.54 | ppl   253.72\n",
            "| epoch  87 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.48 | ppl   239.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time: 43.08s | valid loss  5.41 | valid ppl   222.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |   200/ 2928 batches | lr 0.00 | ms/batch 14.33 | loss  5.54 | ppl   255.91\n",
            "| epoch  88 |   400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.59 | ppl   267.36\n",
            "| epoch  88 |   600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.45 | ppl   232.03\n",
            "| epoch  88 |   800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   251.34\n",
            "| epoch  88 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.46 | ppl   235.25\n",
            "| epoch  88 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.53 | ppl   251.19\n",
            "| epoch  88 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.03 | loss  5.54 | ppl   253.51\n",
            "| epoch  88 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.57 | ppl   263.26\n",
            "| epoch  88 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.35 | loss  5.52 | ppl   248.47\n",
            "| epoch  88 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.56 | ppl   259.14\n",
            "| epoch  88 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.43 | ppl   227.90\n",
            "| epoch  88 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.53 | ppl   252.70\n",
            "| epoch  88 |  2600/ 2928 batches | lr 0.00 | ms/batch 14.23 | loss  5.54 | ppl   254.03\n",
            "| epoch  88 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.17 | loss  5.48 | ppl   239.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time: 43.09s | valid loss  5.41 | valid ppl   222.82\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |   200/ 2928 batches | lr 0.00 | ms/batch 14.09 | loss  5.55 | ppl   256.04\n",
            "| epoch  89 |   400/ 2928 batches | lr 0.00 | ms/batch 14.31 | loss  5.59 | ppl   267.58\n",
            "| epoch  89 |   600/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.45 | ppl   231.78\n",
            "| epoch  89 |   800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.53 | ppl   251.82\n",
            "| epoch  89 |  1000/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.46 | ppl   234.76\n",
            "| epoch  89 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.17 | loss  5.53 | ppl   251.28\n",
            "| epoch  89 |  1400/ 2928 batches | lr 0.00 | ms/batch 14.15 | loss  5.54 | ppl   253.43\n",
            "| epoch  89 |  1600/ 2928 batches | lr 0.00 | ms/batch 13.96 | loss  5.58 | ppl   264.14\n",
            "| epoch  89 |  1800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.52 | ppl   248.78\n",
            "| epoch  89 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.07 | loss  5.56 | ppl   258.67\n",
            "| epoch  89 |  2200/ 2928 batches | lr 0.00 | ms/batch 14.27 | loss  5.43 | ppl   228.34\n",
            "| epoch  89 |  2400/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.53 | ppl   252.48\n",
            "| epoch  89 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.97 | loss  5.54 | ppl   253.46\n",
            "| epoch  89 |  2800/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.48 | ppl   239.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time: 43.10s | valid loss  5.41 | valid ppl   222.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |   200/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.55 | ppl   256.45\n",
            "| epoch  90 |   400/ 2928 batches | lr 0.00 | ms/batch 14.04 | loss  5.59 | ppl   267.28\n",
            "| epoch  90 |   600/ 2928 batches | lr 0.00 | ms/batch 14.05 | loss  5.45 | ppl   231.74\n",
            "| epoch  90 |   800/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.53 | ppl   252.24\n",
            "| epoch  90 |  1000/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.46 | ppl   234.48\n",
            "| epoch  90 |  1200/ 2928 batches | lr 0.00 | ms/batch 14.02 | loss  5.53 | ppl   251.97\n",
            "| epoch  90 |  1400/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.53 | ppl   252.62\n",
            "| epoch  90 |  1600/ 2928 batches | lr 0.00 | ms/batch 14.32 | loss  5.57 | ppl   263.43\n",
            "| epoch  90 |  1800/ 2928 batches | lr 0.00 | ms/batch 14.01 | loss  5.52 | ppl   249.11\n",
            "| epoch  90 |  2000/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.56 | ppl   258.98\n",
            "| epoch  90 |  2200/ 2928 batches | lr 0.00 | ms/batch 13.99 | loss  5.43 | ppl   228.12\n",
            "| epoch  90 |  2400/ 2928 batches | lr 0.00 | ms/batch 14.25 | loss  5.53 | ppl   251.96\n",
            "| epoch  90 |  2600/ 2928 batches | lr 0.00 | ms/batch 13.98 | loss  5.54 | ppl   254.26\n",
            "| epoch  90 |  2800/ 2928 batches | lr 0.00 | ms/batch 14.00 | loss  5.48 | ppl   239.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time: 43.00s | valid loss  5.41 | valid ppl   222.75\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model Evaluation\n",
        "Now, evaluate the best model on the test dataset."
      ],
      "metadata": {
        "id": "T7w8vfWuHtyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('=' * 89)\n",
        "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
        "      f'test ppl {test_ppl:8.2f}')\n",
        "print('=' * 89)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x99F9nNwD_MY",
        "outputId": "a807039b-dc4d-4172-f7c5-b003e1aa6539"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.33 | test ppl   205.73\n",
            "=========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusion\n",
        "Since, we are training a huge transformer model from scratch in our dataset, it gonna takes more than 90 epochs to perform better. This is why we are not getting the very good result, but the purpose of this notebook is not to improve the model but to implement the model."
      ],
      "metadata": {
        "id": "Ea24wLUfIgym"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}