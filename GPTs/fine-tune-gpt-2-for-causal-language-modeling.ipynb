{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine Tune GPT-2 For Causal Language Modeling\n\nThere are two categories of language modeling: \"causal\" and \"masked.\" Causal models are commonly employed for text generation tasks. These models can be utilized in various creative applications, such as crafting personalized text adventures or serving as smart coding assistants like Copilot or CodeParrot.\n\nCausal language modeling predicts the next token in s sequence of tokens, and the model can only attend to tokens on the left. This means the model cannot see future tokens. GPT-2 is an example of a causal language model.\n\nIn this notbook, we are going to fine-tune a text-generation pretrained model with a corresponsive dataset.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## 1. Installations","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.35.2\n!pip install datasets==2.15.0\n!pip install evaluate==0.4.1","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:26:24.639754Z","iopub.execute_input":"2024-02-20T17:26:24.640122Z","iopub.status.idle":"2024-02-20T17:27:20.133737Z","shell.execute_reply.started":"2024-02-20T17:26:24.640093Z","shell.execute_reply":"2024-02-20T17:27:20.132169Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.35.2\n  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.35.2) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2) (2023.11.17)\nUsing cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.37.0\n    Uninstalling transformers-4.37.0:\n      Successfully uninstalled transformers-4.37.0\nSuccessfully installed transformers-4.35.2\nCollecting datasets==2.15.0\n  Using cached datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (1.24.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15.0)\n  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.70.15)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0)\n  Using cached fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 fsspec-2023.10.0 pyarrow-hotfix-0.6\nCollecting evaluate==0.4.1\n  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (2.15.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (1.24.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (0.70.15)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.1) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (0.18.0)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (11.0.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (6.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate==0.4.1) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.1) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate==0.4.1) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate==0.4.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate==0.4.1) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.1) (1.16.0)\nUsing cached evaluate-0.4.1-py3-none-any.whl (84 kB)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Imports","metadata":{}},{"cell_type":"code","source":"import os\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:20.136118Z","iopub.execute_input":"2024-02-20T17:27:20.136513Z","iopub.status.idle":"2024-02-20T17:27:20.458571Z","shell.execute_reply.started":"2024-02-20T17:27:20.136479Z","shell.execute_reply":"2024-02-20T17:27:20.457682Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Setting up all environment variables","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\n\nlogin(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN\"))\n\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"] = \"fine-tuned-models\"\nos.environ[\"WANDB_NOTES\"] = \"fine-tuning GPT-2 model\"\nos.environ[\"WANDB_NAME\"] = \"ft-GPT2-with-lyrics\"","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:20.459606Z","iopub.execute_input":"2024-02-20T17:27:20.461057Z","iopub.status.idle":"2024-02-20T17:27:21.417062Z","shell.execute_reply.started":"2024-02-20T17:27:20.461016Z","shell.execute_reply":"2024-02-20T17:27:21.416056Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Load Dataset\nWe will start by loading a smaller subset  the ELI5 dataset. This will give us a chance to experiment and make sure everything works before spending more time training on the full dataset.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nlyrics= load_dataset(\"Nicolas-BZRD/English_French_Songs_Lyrics_Translation_Original\", split=\"train\")\nprint(lyrics)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:21.419615Z","iopub.execute_input":"2024-02-20T17:27:21.420004Z","iopub.status.idle":"2024-02-20T17:27:30.060992Z","shell.execute_reply.started":"2024-02-20T17:27:21.419977Z","shell.execute_reply":"2024-02-20T17:27:30.060016Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.31k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb44a5c62db450aad537b3a764b9c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e98478f26f244b709c018a011a301abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/122M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2825ac0289f9455a8b09bdd505d7dcb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78e27789ad54d059bbb9163f981843b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/99289 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe62e3cb76347afbbd9f3f0e7753d5a"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language'],\n    num_rows: 99289\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Selecting english lyrics.","metadata":{}},{"cell_type":"code","source":"en_lyrics = lyrics.filter(lambda sample: sample['language'] == \"en\")\nprint(en_lyrics)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:30.062339Z","iopub.execute_input":"2024-02-20T17:27:30.063270Z","iopub.status.idle":"2024-02-20T17:27:32.097260Z","shell.execute_reply.started":"2024-02-20T17:27:30.063228Z","shell.execute_reply":"2024-02-20T17:27:32.096223Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/99289 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b511c069b57846f28a481cbb07587538"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language'],\n    num_rows: 75786\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We are using the combination of Harry Styles and The Weekend songs","metadata":{}},{"cell_type":"code","source":"hw_lyrics = en_lyrics.filter(lambda sample: sample['artist_name'] == \"The Weeknd\" or sample['artist_name'] == \"Harry Styles\" )","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:32.098696Z","iopub.execute_input":"2024-02-20T17:27:32.099355Z","iopub.status.idle":"2024-02-20T17:27:36.033655Z","shell.execute_reply.started":"2024-02-20T17:27:32.099317Z","shell.execute_reply":"2024-02-20T17:27:36.032709Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/75786 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69bc6ecfe1844bd9829591e0b0c3866d"}},"metadata":{}}]},{"cell_type":"code","source":"hw_lyrics","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:36.035031Z","iopub.execute_input":"2024-02-20T17:27:36.035697Z","iopub.status.idle":"2024-02-20T17:27:36.042671Z","shell.execute_reply.started":"2024-02-20T17:27:36.035660Z","shell.execute_reply":"2024-02-20T17:27:36.041720Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language'],\n    num_rows: 177\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Split the dataset's `train` split into a train and test with the train_test_split method","metadata":{}},{"cell_type":"code","source":"hw_lyrics = hw_lyrics.train_test_split(test_size=0.2)\nprint(hw_lyrics)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:36.044003Z","iopub.execute_input":"2024-02-20T17:27:36.044308Z","iopub.status.idle":"2024-02-20T17:27:36.076838Z","shell.execute_reply.started":"2024-02-20T17:27:36.044281Z","shell.execute_reply":"2024-02-20T17:27:36.075757Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language'],\n        num_rows: 141\n    })\n    test: Dataset({\n        features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language'],\n        num_rows: 36\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(hw_lyrics[\"train\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:36.078326Z","iopub.execute_input":"2024-02-20T17:27:36.078596Z","iopub.status.idle":"2024-02-20T17:27:36.084062Z","shell.execute_reply.started":"2024-02-20T17:27:36.078572Z","shell.execute_reply":"2024-02-20T17:27:36.083184Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'artist_name': 'Harry Styles', 'album_name': 'Harry Styles', 'year': 2017, 'title': 'Sign Of The Times', 'number': 2, 'original_version': 'Just stop your crying, \\nIt’s the sign of the times.**\\nWelcome to the final show, \\nHope you’re wearing your best clothes.\\nYou can’t bribe the door on your way to the sky,\\nYou look pretty good down here,\\nBut you ain’t really good.\\nWe’ve never learned like we’ve been here before,\\nWhy are we always stuck at running from,\\nThe bullets, the bullets.\\nJust stop your crying, \\nIt’s the sign of the times.\\nWe gotta get away from here,\\nWe gotta get away from here.\\nJust stop your crying, \\nIt will be alright.\\nThey told me the end is near,\\nWe gotta get away from here.\\nJust stop your crying,\\nHave the time of your life,\\nBreaking through the atmosphere,\\nThings are pretty good from here.\\nRemember everything will be alright,\\nWe could meet again somewhere,\\nSomewhere far away from here.\\nWe’ve never learned like we’ve been here before,\\nWhy are we always stuck at running from,\\nThe bullets, the bullets.\\nJust stop your crying, \\nIt’s the sign of the times.\\nWe gotta get away from here,\\nWe gotta get away from here.\\nJust stop your crying, \\nIt will be alright.\\nThey told me the end is near,\\nWe gotta get away from here.\\nWe don’t talk enough,\\nWe should open up,\\nBefore it’s all too much.\\nWill we ever learn?\\nWe’ve been here before,\\nIt’s just what we know.\\nJust stop your crying, \\nIt’s the sign of the times.\\nWe gotta get away from here,\\nWe gotta get away from here.\\nWe got to get away x4\\nWe got to, we got to, away x3\\nMost of the stuff that hurts me about what’s going on at the moment is not politics, it’s fundamentals. Equal rights. For everyone, all races, sexes, everything. … This isn’t the first time we’ve been in a hard time, and it’s not going to be the last time. The song is written from a point of view as if a mother was giving birth to a child and there’s a complication.The mother is told, ‘The child is fine, but you’re not going to make it.’ The mother has five minutes to tell the child, ‘Go forth and conquer.’', 'french_version': 'Arrête de pleurer\\nC\\'est l’emblème actuel\\nBienvenu au dernier spectacle\\nJ\\'espère que tu portes tes plus beaux habits.\\nTu ne peux pas soudoyer la porte du paradis en allant dans le ciel\\nTu est plutôt bien ici,\\nMais tu ne te sens pas bien\\nNous n\\'avons jamais appris pourtant nous sommes déjà passé par là\\nPourquoi est-ce qu\\'on doit toujours fuir\\nLes balles, les balles\\nArrête de pleurer\\nC\\'est l\\'emblème actuel\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nArrête de pleurer\\nTout ira bien\\nIls m\\'ont dit que la fin était proche\\nNous devons partir d\\'ici\\nArrête de pleurer\\nAmuse toi comme un fou\\nEn perçant l\\'atmosphère\\nLes choses vont plutôt bien d\\'ici.\\nSouviens-toi que tout ira bien\\nOn pourrait se revoir autre part\\nQuelque part loin d\\'ici\\nNous n\\'avons jamais appris pourtant nous sommes déjà passé par là\\nPourquoi est-ce qu\\'on doit toujours fuir\\nLes balles, les balles\\nArrête de pleurer\\nC\\'est l\\'emblème actuel\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nArrête de pleurer\\nTout ira bien\\nIls m\\'ont dit que la fin était proche\\nNous devons partir d\\'ici\\nOn ne parle pas assez\\nOn devrait s\\'ouvrir aux autres\\nAvant que le vase déborde\\nApprendrons-nous un jour?\\nOn est déjà passé par là\\nC\\'est tout ce qu\\'on sait\\nArrête de pleurer\\nC\\'est l\\'emblème actuel\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nLa plupart des choses qui me font mal dans ce qui se passe en ce moment n\\'est pas la politique, ce sont les fondamentaux. Droits égaux. Pour tout le monde, toutes races, sexes, tout. … Ce n\\'est pas la première fois que nous traversons une période difficile, et ce ne sera pas la dernière. La chanson est écrite d\\'un point de vue, comme si une mère donnait naissance à un enfant et qu\\'il y avait une complication.On dit à la mère : \"L\\'enfant va bien, mais vous n\\'allez pas vous en sortir.\" La mère a cinq minutes pour dire à l\\'enfant : \"Va de l\\'avant et conquiers (le monde).\"', 'language': 'en'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Despite the large number of text fields, labels are not necessary for the language modeling jobs.\n\nThis is known as an unsupervised task, where the model predicts the next token in a sequence of tokens without the need for labeled data. By utilizing this method, NLP models have been constructed with little to no annotated data, enabling the extraction of knowledge from huge language models without the requirement for labeled data.","metadata":{}},{"cell_type":"markdown","source":"## 4. Data Pre-processing\n\nLoad a GPT2Tokenizer tokenizer to process the `original_version` subfield:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer=AutoTokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token=tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:36.087244Z","iopub.execute_input":"2024-02-20T17:27:36.087557Z","iopub.status.idle":"2024-02-20T17:27:45.594956Z","shell.execute_reply.started":"2024-02-20T17:27:36.087531Z","shell.execute_reply":"2024-02-20T17:27:45.593486Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad236d31367a492fa12fa9734cbaff83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6305ba5700a64dc1b1da399f4af7b0ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5c2894d40a4465bcdb8b4f034c6f42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7734e47308a943f6bca665d62eeb8195"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0984fe682f94eea9275b38fd0e0c51a"}},"metadata":{}}]},{"cell_type":"code","source":"hw_lyrics = hw_lyrics.flatten()\nhw_lyrics[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:45.596921Z","iopub.execute_input":"2024-02-20T17:27:45.597651Z","iopub.status.idle":"2024-02-20T17:27:45.613608Z","shell.execute_reply.started":"2024-02-20T17:27:45.597607Z","shell.execute_reply":"2024-02-20T17:27:45.612487Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'artist_name': 'Harry Styles',\n 'album_name': 'Harry Styles',\n 'year': 2017,\n 'title': 'Sign Of The Times',\n 'number': 2,\n 'original_version': 'Just stop your crying, \\nIt’s the sign of the times.**\\nWelcome to the final show, \\nHope you’re wearing your best clothes.\\nYou can’t bribe the door on your way to the sky,\\nYou look pretty good down here,\\nBut you ain’t really good.\\nWe’ve never learned like we’ve been here before,\\nWhy are we always stuck at running from,\\nThe bullets, the bullets.\\nJust stop your crying, \\nIt’s the sign of the times.\\nWe gotta get away from here,\\nWe gotta get away from here.\\nJust stop your crying, \\nIt will be alright.\\nThey told me the end is near,\\nWe gotta get away from here.\\nJust stop your crying,\\nHave the time of your life,\\nBreaking through the atmosphere,\\nThings are pretty good from here.\\nRemember everything will be alright,\\nWe could meet again somewhere,\\nSomewhere far away from here.\\nWe’ve never learned like we’ve been here before,\\nWhy are we always stuck at running from,\\nThe bullets, the bullets.\\nJust stop your crying, \\nIt’s the sign of the times.\\nWe gotta get away from here,\\nWe gotta get away from here.\\nJust stop your crying, \\nIt will be alright.\\nThey told me the end is near,\\nWe gotta get away from here.\\nWe don’t talk enough,\\nWe should open up,\\nBefore it’s all too much.\\nWill we ever learn?\\nWe’ve been here before,\\nIt’s just what we know.\\nJust stop your crying, \\nIt’s the sign of the times.\\nWe gotta get away from here,\\nWe gotta get away from here.\\nWe got to get away x4\\nWe got to, we got to, away x3\\nMost of the stuff that hurts me about what’s going on at the moment is not politics, it’s fundamentals. Equal rights. For everyone, all races, sexes, everything. … This isn’t the first time we’ve been in a hard time, and it’s not going to be the last time. The song is written from a point of view as if a mother was giving birth to a child and there’s a complication.The mother is told, ‘The child is fine, but you’re not going to make it.’ The mother has five minutes to tell the child, ‘Go forth and conquer.’',\n 'french_version': 'Arrête de pleurer\\nC\\'est l’emblème actuel\\nBienvenu au dernier spectacle\\nJ\\'espère que tu portes tes plus beaux habits.\\nTu ne peux pas soudoyer la porte du paradis en allant dans le ciel\\nTu est plutôt bien ici,\\nMais tu ne te sens pas bien\\nNous n\\'avons jamais appris pourtant nous sommes déjà passé par là\\nPourquoi est-ce qu\\'on doit toujours fuir\\nLes balles, les balles\\nArrête de pleurer\\nC\\'est l\\'emblème actuel\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nArrête de pleurer\\nTout ira bien\\nIls m\\'ont dit que la fin était proche\\nNous devons partir d\\'ici\\nArrête de pleurer\\nAmuse toi comme un fou\\nEn perçant l\\'atmosphère\\nLes choses vont plutôt bien d\\'ici.\\nSouviens-toi que tout ira bien\\nOn pourrait se revoir autre part\\nQuelque part loin d\\'ici\\nNous n\\'avons jamais appris pourtant nous sommes déjà passé par là\\nPourquoi est-ce qu\\'on doit toujours fuir\\nLes balles, les balles\\nArrête de pleurer\\nC\\'est l\\'emblème actuel\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nArrête de pleurer\\nTout ira bien\\nIls m\\'ont dit que la fin était proche\\nNous devons partir d\\'ici\\nOn ne parle pas assez\\nOn devrait s\\'ouvrir aux autres\\nAvant que le vase déborde\\nApprendrons-nous un jour?\\nOn est déjà passé par là\\nC\\'est tout ce qu\\'on sait\\nArrête de pleurer\\nC\\'est l\\'emblème actuel\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nNous devons partir d\\'ici\\nLa plupart des choses qui me font mal dans ce qui se passe en ce moment n\\'est pas la politique, ce sont les fondamentaux. Droits égaux. Pour tout le monde, toutes races, sexes, tout. … Ce n\\'est pas la première fois que nous traversons une période difficile, et ce ne sera pas la dernière. La chanson est écrite d\\'un point de vue, comme si une mère donnait naissance à un enfant et qu\\'il y avait une complication.On dit à la mère : \"L\\'enfant va bien, mais vous n\\'allez pas vous en sortir.\" La mère a cinq minutes pour dire à l\\'enfant : \"Va de l\\'avant et conquiers (le monde).\"',\n 'language': 'en'}"},"metadata":{}}]},{"cell_type":"markdown","source":"And instead of tokenizing each sentence separatelty, convert the list to a string so we can jointly tokenize them","metadata":{}},{"cell_type":"code","source":"def preprocess_function(samples):\n    return tokenizer([\" \".join(x) for x in samples[\"original_version\"]], max_length=2048, padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:45.614966Z","iopub.execute_input":"2024-02-20T17:27:45.615437Z","iopub.status.idle":"2024-02-20T17:27:45.626984Z","shell.execute_reply.started":"2024-02-20T17:27:45.615395Z","shell.execute_reply":"2024-02-20T17:27:45.623968Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"We need to apply this preprocessing function over the entire dataset.","metadata":{}},{"cell_type":"code","source":"tokenized_hw_lyrics= hw_lyrics.map(\n    preprocess_function,\n    batched=True,\n    num_proc=4,\n    remove_columns=hw_lyrics[\"train\"].column_names,\n)\ntokenized_hw_lyrics","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:45.629927Z","iopub.execute_input":"2024-02-20T17:27:45.630828Z","iopub.status.idle":"2024-02-20T17:27:46.566514Z","shell.execute_reply.started":"2024-02-20T17:27:45.630787Z","shell.execute_reply":"2024-02-20T17:27:46.565390Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/141 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6b72ffd5c346ee98ee8a294e8a0887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/36 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"214b19c8fc4a4900a2c4c4fe613ed640"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 141\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 36\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"We also need to make sure the token sequences are shorter than the maximum input length of the model, and we can also add padding if the model supported it.\n\n- concatenate all the sequences\n- split the concatenated sequences into shorter chunks defined by block_size, which should be both shorter than the maximum input length and short enough for your GPU RAM.","metadata":{}},{"cell_type":"code","source":"block_size=128\n\ndef group_texts(examples):\n    concatenated_examples={k: sum(examples[k], []) for k in examples.keys()}\n    total_length=len(concatenated_examples[list(examples.keys())[0]])\n    if total_length>=block_size:\n        total_length=(total_length//block_size)* block_size\n    # Split by chunks of block size\n    result={\n        k: [t[i: i+block_size] for i in range(0, total_length, block_size)]\n        for k,t in concatenated_examples.items()\n    }\n    \n    result[\"labels\"]=result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:46.568367Z","iopub.execute_input":"2024-02-20T17:27:46.568787Z","iopub.status.idle":"2024-02-20T17:27:46.577004Z","shell.execute_reply.started":"2024-02-20T17:27:46.568738Z","shell.execute_reply":"2024-02-20T17:27:46.576056Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Apply the `group_texts` function over the entire dataset:","metadata":{}},{"cell_type":"code","source":"lm_dataset = tokenized_hw_lyrics.map(group_texts, batched=True, num_proc=4)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:46.578081Z","iopub.execute_input":"2024-02-20T17:27:46.578383Z","iopub.status.idle":"2024-02-20T17:27:47.388783Z","shell.execute_reply.started":"2024-02-20T17:27:46.578358Z","shell.execute_reply":"2024-02-20T17:27:47.387575Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/141 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44aeeef3ef8f478e8035104b98c4266a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/36 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1737ccea8ee14d5689bd1c41febb131b"}},"metadata":{}}]},{"cell_type":"code","source":"print(lm_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:47.390733Z","iopub.execute_input":"2024-02-20T17:27:47.391289Z","iopub.status.idle":"2024-02-20T17:27:47.397719Z","shell.execute_reply.started":"2024-02-20T17:27:47.391234Z","shell.execute_reply":"2024-02-20T17:27:47.396745Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 2256\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 576\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(lm_dataset[\"train\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:47.399147Z","iopub.execute_input":"2024-02-20T17:27:47.399520Z","iopub.status.idle":"2024-02-20T17:27:47.420028Z","shell.execute_reply.started":"2024-02-20T17:27:47.399486Z","shell.execute_reply":"2024-02-20T17:27:47.419030Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'input_ids': [41, 334, 264, 256, 220, 220, 264, 256, 267, 279, 220, 220, 331, 267, 334, 374, 220, 220, 269, 374, 331, 1312, 299, 308, 837, 220, 220, 220, 198, 314, 256, 564, 247, 264, 220, 220, 256, 289, 304, 220, 220, 264, 1312, 308, 299, 220, 220, 267, 277, 220, 220, 256, 289, 304, 220, 220, 256, 1312, 285, 304, 264, 764, 1635, 1635, 220, 198, 370, 304, 300, 269, 267, 285, 304, 220, 220, 256, 267, 220, 220, 256, 289, 304, 220, 220, 277, 1312, 299, 257, 300, 220, 220, 264, 289, 267, 266, 837, 220, 220, 220, 198, 367, 267, 279, 304, 220, 220, 331, 267, 334, 564, 247, 374, 304, 220, 220, 266, 304, 257, 374, 1312, 299, 308, 220, 220, 331, 267, 334, 374], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [41, 334, 264, 256, 220, 220, 264, 256, 267, 279, 220, 220, 331, 267, 334, 374, 220, 220, 269, 374, 331, 1312, 299, 308, 837, 220, 220, 220, 198, 314, 256, 564, 247, 264, 220, 220, 256, 289, 304, 220, 220, 264, 1312, 308, 299, 220, 220, 267, 277, 220, 220, 256, 289, 304, 220, 220, 256, 1312, 285, 304, 264, 764, 1635, 1635, 220, 198, 370, 304, 300, 269, 267, 285, 304, 220, 220, 256, 267, 220, 220, 256, 289, 304, 220, 220, 277, 1312, 299, 257, 300, 220, 220, 264, 289, 267, 266, 837, 220, 220, 220, 198, 367, 267, 279, 304, 220, 220, 331, 267, 334, 564, 247, 374, 304, 220, 220, 266, 304, 257, 374, 1312, 299, 308, 220, 220, 331, 267, 334, 374]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here we are going to use `dynamically pad` the sentence to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length. ","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ntokenizer.pad_token=tokenizer.eos_token\n# Use the end of sequence token as the padding token and set `mlm=False`.\n# This will use the inputs as labels shifted to the right by one element.\ndata_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:27:47.421298Z","iopub.execute_input":"2024-02-20T17:27:47.421645Z","iopub.status.idle":"2024-02-20T17:28:04.299083Z","shell.execute_reply.started":"2024-02-20T17:27:47.421613Z","shell.execute_reply":"2024-02-20T17:28:04.298263Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2024-02-20 17:27:51.443411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-20 17:27:51.443523: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-20 17:27:51.702897: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5. Train","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n\nmodel = AutoModelForCausalLM.from_pretrained(\"gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:28:04.300472Z","iopub.execute_input":"2024-02-20T17:28:04.301983Z","iopub.status.idle":"2024-02-20T17:28:11.022357Z","shell.execute_reply.started":"2024-02-20T17:28:04.301945Z","shell.execute_reply":"2024-02-20T17:28:11.021342Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2afcfb41bfc74184a51a3c9d5667c4fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825614890e674429b734829b583eea0c"}},"metadata":{}}]},{"cell_type":"code","source":"training_args=TrainingArguments(\n    output_dir=os.getenv(\"WANDB_NAME\"),\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=30,\n    weight_decay=0.01,\n    report_to=\"wandb\",\n    run_name=os.getenv(\"WANDB_NAME\"),\n    push_to_hub=False,\n)\n\ntrainer=Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=lm_dataset[\"train\"],\n    eval_dataset=lm_dataset[\"test\"],\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:28:11.023687Z","iopub.execute_input":"2024-02-20T17:28:11.023994Z","iopub.status.idle":"2024-02-20T17:56:00.281850Z","shell.execute_reply.started":"2024-02-20T17:28:11.023967Z","shell.execute_reply":"2024-02-20T17:56:00.280808Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msurajkark\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240220_172814-hef2fidy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/surajkark/fine-tuned-models/runs/hef2fidy' target=\"_blank\">ft-GPT2-with-lyrics</a></strong> to <a href='https://wandb.ai/surajkark/fine-tuned-models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/surajkark/fine-tuned-models' target=\"_blank\">https://wandb.ai/surajkark/fine-tuned-models</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/surajkark/fine-tuned-models/runs/hef2fidy' target=\"_blank\">https://wandb.ai/surajkark/fine-tuned-models/runs/hef2fidy</a>"},"metadata":{}},{"name":"stderr","text":"You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2130' max='2130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2130/2130 27:08, Epoch 30/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.005800</td>\n      <td>1.529321</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.579700</td>\n      <td>1.381351</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.454900</td>\n      <td>1.309338</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.383700</td>\n      <td>1.266117</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.335400</td>\n      <td>1.232830</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.297600</td>\n      <td>1.214228</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.267800</td>\n      <td>1.197299</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.240100</td>\n      <td>1.182472</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.216800</td>\n      <td>1.173725</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.197100</td>\n      <td>1.160442</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.179700</td>\n      <td>1.152945</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.167100</td>\n      <td>1.145079</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.151700</td>\n      <td>1.139518</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.138900</td>\n      <td>1.135707</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.126700</td>\n      <td>1.132504</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.118900</td>\n      <td>1.127836</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.107600</td>\n      <td>1.124570</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.101900</td>\n      <td>1.120089</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.092500</td>\n      <td>1.120091</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.088500</td>\n      <td>1.115936</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.080600</td>\n      <td>1.116471</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.078500</td>\n      <td>1.117849</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.070300</td>\n      <td>1.117059</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>1.067400</td>\n      <td>1.112956</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>1.060400</td>\n      <td>1.113158</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.062000</td>\n      <td>1.112012</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.054500</td>\n      <td>1.112319</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.053400</td>\n      <td>1.110598</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.052800</td>\n      <td>1.111486</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.051600</td>\n      <td>1.111208</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2130, training_loss=1.1961356722692928, metrics={'train_runtime': 1667.2868, 'train_samples_per_second': 40.593, 'train_steps_per_second': 1.278, 'total_flos': 4421061181440000.0, 'train_loss': 1.1961356722692928, 'epoch': 30.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(os.getenv(\"WANDB_NAME\"))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:56:00.286149Z","iopub.execute_input":"2024-02-20T17:56:00.286468Z","iopub.status.idle":"2024-02-20T17:56:01.269993Z","shell.execute_reply.started":"2024-02-20T17:56:00.286441Z","shell.execute_reply":"2024-02-20T17:56:01.268832Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"loaded_model = AutoModelForCausalLM.from_pretrained(os.getenv(\"WANDB_NAME\"))\nprint(loaded_model)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:56:01.271479Z","iopub.execute_input":"2024-02-20T17:56:01.271889Z","iopub.status.idle":"2024-02-20T17:56:03.577535Z","shell.execute_reply.started":"2024-02-20T17:56:01.271845Z","shell.execute_reply":"2024-02-20T17:56:03.576503Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.push_to_hub(os.getenv(\"WANDB_NAME\"))\ntokenizer.push_to_hub(os.getenv(\"WANDB_NAME\"))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:01:49.596717Z","iopub.execute_input":"2024-02-20T18:01:49.597514Z","iopub.status.idle":"2024-02-20T18:02:07.922722Z","shell.execute_reply.started":"2024-02-20T18:01:49.597480Z","shell.execute_reply":"2024-02-20T18:02:07.921645Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799edcc27ce846d9838d3b1717fa59e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ff41cb745b046f5bca1afd5b8f0586a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c49071c38cb4f36915ca4672402a546"}},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/surajkarki/ft-GPT2-with-lyrics/commit/57b59036418ce3baa6b8a47fd46443ea96295942', commit_message='Upload tokenizer', commit_description='', oid='57b59036418ce3baa6b8a47fd46443ea96295942', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"## 6.Evaluate","metadata":{}},{"cell_type":"code","source":"import math\n\neval_results = trainer.evaluate()\nprint(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-20T17:56:13.160400Z","iopub.execute_input":"2024-02-20T17:56:13.161249Z","iopub.status.idle":"2024-02-20T17:56:18.236181Z","shell.execute_reply.started":"2024-02-20T17:56:13.161215Z","shell.execute_reply":"2024-02-20T17:56:18.235014Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [18/18 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Perplexity: 3.04\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 7. Inference","metadata":{}},{"cell_type":"code","source":"prompt1=\"Remember that time\"","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:11:42.719698Z","iopub.execute_input":"2024-02-20T18:11:42.720480Z","iopub.status.idle":"2024-02-20T18:11:42.726887Z","shell.execute_reply.started":"2024-02-20T18:11:42.720442Z","shell.execute_reply":"2024-02-20T18:11:42.725691Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=os.getenv(\"WANDB_NAME\"))\n\ngenerator(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:12:02.076742Z","iopub.execute_input":"2024-02-20T18:12:02.077190Z","iopub.status.idle":"2024-02-20T18:12:06.205439Z","shell.execute_reply.started":"2024-02-20T18:12:02.077155Z","shell.execute_reply":"2024-02-20T18:12:06.203588Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Remember that time I d on't   h a v e   y o u   m a k e   m y   f a l l \\n A n d   y o u   b e\"}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Tokenize the text and return the input_ids as PyTorch tensors:","metadata":{}},{"cell_type":"code","source":"prompt2 = \"I'm just tryna live life\"","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:12:31.087625Z","iopub.execute_input":"2024-02-20T18:12:31.088027Z","iopub.status.idle":"2024-02-20T18:12:31.101161Z","shell.execute_reply.started":"2024-02-20T18:12:31.087996Z","shell.execute_reply":"2024-02-20T18:12:31.099226Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer=AutoTokenizer.from_pretrained(\"gpt2\")\ntokenizer.pad_token=tokenizer.eos_token\ntrainer\ninputs=tokenizer(prompt2, return_tensors=\"pt\").input_ids","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:12:35.731864Z","iopub.execute_input":"2024-02-20T18:12:35.732416Z","iopub.status.idle":"2024-02-20T18:12:35.954701Z","shell.execute_reply.started":"2024-02-20T18:12:35.732381Z","shell.execute_reply":"2024-02-20T18:12:35.953523Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel=AutoModelForCausalLM.from_pretrained(os.getenv(\"WANDB_NAME\"))\noutputs=model.generate(inputs, max_new_tokens=100, do_sample=True, top_k=5, top_p=0.95)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:12:37.232473Z","iopub.execute_input":"2024-02-20T18:12:37.233283Z","iopub.status.idle":"2024-02-20T18:12:43.542971Z","shell.execute_reply.started":"2024-02-20T18:12:37.233246Z","shell.execute_reply":"2024-02-20T18:12:43.541795Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.batch_decode(outputs, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T18:12:45.155301Z","iopub.execute_input":"2024-02-20T18:12:45.156021Z","iopub.status.idle":"2024-02-20T18:12:45.165033Z","shell.execute_reply.started":"2024-02-20T18:12:45.155989Z","shell.execute_reply":"2024-02-20T18:12:45.163745Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"[\"I'm just tryna live life's   a   l e a r n   a g a i n \\n I   d on't   w a n n a   b e   t h e   w a y \\n A n d   I   c a n   f e e l   y o u   t h i n k i n'  i t's   l o v e   t o\"]"},"metadata":{}}]},{"cell_type":"markdown","source":"## 8. Conclusion\nTo get the better result, we need to train the model for more epochs.","metadata":{}}]}