{"metadata":{"colab":{"name":"Summarization","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine tuning the T5 for text summarization\n## T5\n- It is a text to text transfer transformer. \n- T5 alone can be used to perform different NLP taska such as Text classification, language translation, text summarization, question answering makes itself a most flexible model.","metadata":{"id":"X4cRE8IbIrIV"}},{"cell_type":"markdown","source":"**What it does?**  \n1. Convert all problems to text to text generation.\n    - For example: In Language Translation, English to Italian  \n    Input: I love you  \n    Output: Ti amo\n    \n    - For example: In Text Classification,  \n    Input: This product is trash.  \n    Output: Negative\n\n2. Learns to predict [MASK] words.\n3. Use task specific prefixes to guide the model during fine tuning.\n   For example, it adds specific token at the beginning of the input text to indicate what  task is it performing.","metadata":{}},{"cell_type":"markdown","source":"T5 has been shown to achieve state-of-the-art results on a wide range of NLP tasks, and it‚Äôs considered a highly sophisticated and powerful NLP model, showing a high level of versatility, fine-tuning capability, and an efficient way to transfer knowledge.","metadata":{}},{"cell_type":"markdown","source":"## Implementation","metadata":{}},{"cell_type":"code","source":"!pip install datasets evaluate transformers rouge-score nltk","metadata":{"id":"MOsHUjgdIrIW","execution":{"iopub.status.busy":"2024-02-18T19:43:00.135446Z","iopub.execute_input":"2024-02-18T19:43:00.135783Z","iopub.status.idle":"2024-02-18T19:43:17.068009Z","shell.execute_reply.started":"2024-02-18T19:43:00.135756Z","shell.execute_reply":"2024-02-18T19:43:17.066856Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3aa9bfbebbbf257e5eb7b26c906a452b326077d1154a975407688a9261c90a05\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score, evaluate\nSuccessfully installed evaluate-0.4.1 rouge-score-0.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.","metadata":{"id":"PT25C83nlSgw"}},{"cell_type":"markdown","source":"Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:","metadata":{"id":"Sa3BgAnElSg3"}},{"cell_type":"code","source":"import transformers\n\nprint(transformers.__version__)","metadata":{"id":"9K-5jSF5lSg4","execution":{"iopub.status.busy":"2024-02-18T19:43:17.070139Z","iopub.execute_input":"2024-02-18T19:43:17.070510Z","iopub.status.idle":"2024-02-18T19:43:22.114101Z","shell.execute_reply.started":"2024-02-18T19:43:17.070467Z","shell.execute_reply":"2024-02-18T19:43:22.113193Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"4.37.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely.","metadata":{"id":"4v-v-y8flSg8"}},{"cell_type":"code","source":"from transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"summarization_notebook\", framework=\"pytorch\")","metadata":{"id":"k7QTfPOFlSg9","execution":{"iopub.status.busy":"2024-02-18T19:43:22.115287Z","iopub.execute_input":"2024-02-18T19:43:22.115689Z","iopub.status.idle":"2024-02-18T19:43:22.122941Z","shell.execute_reply.started":"2024-02-18T19:43:22.115663Z","shell.execute_reply":"2024-02-18T19:43:22.121480Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"t5-small\"","metadata":{"id":"R2wxeenHlShB","execution":{"iopub.status.busy":"2024-02-18T19:43:22.125778Z","iopub.execute_input":"2024-02-18T19:43:22.126149Z","iopub.status.idle":"2024-02-18T19:43:22.131850Z","shell.execute_reply.started":"2024-02-18T19:43:22.126122Z","shell.execute_reply":"2024-02-18T19:43:22.130886Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`t5-small`](https://huggingface.co/t5-small) checkpoint.","metadata":{"id":"4RRkXuteIrIh"}},{"cell_type":"markdown","source":"### 1. Loading the dataset","metadata":{"id":"whPRbBNbIrIl"}},{"cell_type":"markdown","source":"We will use the [ü§ó Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  ","metadata":{"id":"W7QYTpxXIrIl"}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom evaluate import load\n\nraw_datasets = load_dataset(\"xsum\")\nmetric = load(\"rouge\")","metadata":{"id":"IreSlFmlIrIm","outputId":"56be1c91-dada-4c65-d4e3-dabdb676fdd1","colab":{"referenced_widgets":["ef1e01985867419f9bb6a46bc1f93ffe"]},"execution":{"iopub.status.busy":"2024-02-18T19:58:04.268502Z","iopub.execute_input":"2024-02-18T19:58:04.269268Z","iopub.status.idle":"2024-02-18T19:58:05.348214Z","shell.execute_reply.started":"2024-02-18T19:58:04.269235Z","shell.execute_reply":"2024-02-18T19:58:05.347104Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3d90f1d209346baaf70363fff79998f"}},"metadata":{}}]},{"cell_type":"markdown","source":"The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:","metadata":{"id":"RzfPtOMoIrIu"}},{"cell_type":"code","source":"print(raw_datasets)","metadata":{"id":"GWiVUF0jIrIv","outputId":"35e3ea43-f397-4a54-c90c-f2cf8d36873e","execution":{"iopub.status.busy":"2024-02-18T19:58:10.856199Z","iopub.execute_input":"2024-02-18T19:58:10.857089Z","iopub.status.idle":"2024-02-18T19:58:10.864020Z","shell.execute_reply.started":"2024-02-18T19:58:10.857040Z","shell.execute_reply":"2024-02-18T19:58:10.862822Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['document', 'summary', 'id'],\n        num_rows: 204045\n    })\n    validation: Dataset({\n        features: ['document', 'summary', 'id'],\n        num_rows: 11332\n    })\n    test: Dataset({\n        features: ['document', 'summary', 'id'],\n        num_rows: 11334\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To access an actual element, you need to select a split first, then give an index:","metadata":{"id":"u3EtYfeHIrIz"}},{"cell_type":"code","source":"print(raw_datasets[\"train\"][0])","metadata":{"id":"X6HrpprwIrIz","outputId":"d7670bc0-42e4-4c09-8a6a-5c018ded7d95","execution":{"iopub.status.busy":"2024-02-18T19:58:31.420264Z","iopub.execute_input":"2024-02-18T19:58:31.420996Z","iopub.status.idle":"2024-02-18T19:58:31.428206Z","shell.execute_reply.started":"2024-02-18T19:58:31.420966Z","shell.execute_reply":"2024-02-18T19:58:31.427116Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"{'document': 'The full cost of damage in Newton Stewart, one of the areas worst affected, is still being assessed.\\nRepair work is ongoing in Hawick and many roads in Peeblesshire remain badly affected by standing water.\\nTrains on the west coast mainline face disruption due to damage at the Lamington Viaduct.\\nMany businesses and householders were affected by flooding in Newton Stewart after the River Cree overflowed into the town.\\nFirst Minister Nicola Sturgeon visited the area to inspect the damage.\\nThe waters breached a retaining wall, flooding many commercial properties on Victoria Street - the main shopping thoroughfare.\\nJeanette Tate, who owns the Cinnamon Cafe which was badly affected, said she could not fault the multi-agency response once the flood hit.\\nHowever, she said more preventative work could have been carried out to ensure the retaining wall did not fail.\\n\"It is difficult but I do think there is so much publicity for Dumfries and the Nith - and I totally appreciate that - but it is almost like we\\'re neglected or forgotten,\" she said.\\n\"That may not be true but it is perhaps my perspective over the last few days.\\n\"Why were you not ready to help us a bit more when the warning and the alarm alerts had gone out?\"\\nMeanwhile, a flood alert remains in place across the Borders because of the constant rain.\\nPeebles was badly hit by problems, sparking calls to introduce more defences in the area.\\nScottish Borders Council has put a list on its website of the roads worst affected and drivers have been urged not to ignore closure signs.\\nThe Labour Party\\'s deputy Scottish leader Alex Rowley was in Hawick on Monday to see the situation first hand.\\nHe said it was important to get the flood protection plan right but backed calls to speed up the process.\\n\"I was quite taken aback by the amount of damage that has been done,\" he said.\\n\"Obviously it is heart-breaking for people who have been forced out of their homes and the impact on businesses.\"\\nHe said it was important that \"immediate steps\" were taken to protect the areas most vulnerable and a clear timetable put in place for flood prevention plans.\\nHave you been affected by flooding in Dumfries and Galloway or the Borders? Tell us about your experience of the situation and how it was handled. Email us on selkirk.news@bbc.co.uk or dumfries@bbc.co.uk.', 'summary': 'Clean-up operations are continuing across the Scottish Borders and Dumfries and Galloway after flooding caused by Storm Frank.', 'id': '35232142'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset.","metadata":{"id":"WHUmphG3IrI3"}},{"cell_type":"code","source":"import datasets\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=5):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n\n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, datasets.ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n    display(HTML(df.to_html()))","metadata":{"id":"i3j8APAoIrI3","execution":{"iopub.status.busy":"2024-02-18T19:45:37.249381Z","iopub.execute_input":"2024-02-18T19:45:37.249639Z","iopub.status.idle":"2024-02-18T19:45:37.261109Z","shell.execute_reply.started":"2024-02-18T19:45:37.249616Z","shell.execute_reply":"2024-02-18T19:45:37.260099Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"show_random_elements(raw_datasets[\"train\"])","metadata":{"id":"SZy5tRB_IrI7","outputId":"ba8f2124-e485-488f-8c0c-254f34f24f13","execution":{"iopub.status.busy":"2024-02-18T19:58:37.137019Z","iopub.execute_input":"2024-02-18T19:58:37.137944Z","iopub.status.idle":"2024-02-18T19:58:37.149740Z","shell.execute_reply.started":"2024-02-18T19:58:37.137908Z","shell.execute_reply":"2024-02-18T19:58:37.148359Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>summary</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The sentences were suspended for three years, meaning they will not go to prison unless they reoffend, he adds.\\nThe video shows three men and three unveiled women dancing on the streets and rooftops of Tehran.\\nIn six months, it has been viewed by over one million people on YouTube.\\nThe majority of people involved in the video were sentenced to six months in prison, with one member of the group given one year, lawyer Farshid Rofugaran was quoted by Iran Wire as saying.\\nThe \"Happy we are from Tehran\" video was brought to the attention of the Iranian authorities in May, after receiving more than 150,000 views.\\nMembers of the group behind the video were subsequently arrested by Iranian police for violating Islamic laws of the country, which prohibit dancing with members of the opposite sex and women from appearing without a headscarf.\\nThey later appeared on state-run TV saying they were actors who had been tricked into make the Happy video for an audition.\\nThe arrests drew condemnation from international rights groups and sparked a social media campaign calling for their release.\\nWilliams, whose song was nominated for an Oscar earlier this year, also protested at the arrests.\\n\"It is beyond sad that these kids were arrested for trying to spread happiness,\" he wrote on Facebook.</td>\n      <td>Six Iranians arrested for appearing in a video dancing to Pharrell Williams' song Happy have been sentenced to up to one year in prison and 91 lashes, their lawyer says.</td>\n      <td>29272732</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Romelu Lukaku put the visitors in front with a penalty after keeper Jack Butland had brought down Tom Cleverley.\\nSeamus Coleman headed in a Cleverley corner and Aaron Lennon intercepted a pass before slotting in as Everton went 3-0 up at the break.\\nLukaku also had a header tipped on to the crossbar by Butland, while a poor Stoke struggled to create chances.\\nRelive Everton's win against Stoke\\nFollow reaction to Saturday's games\\nMedia playback is not supported on this device\\nA lot was made about Everton boss Roberto Martinez's dance moves at a Jason Derulo concert in the week, but it was his team impressing with their performance at the Britannia Stadium.\\nEngland manager Roy Hodgson was at the game and he will have liked what he saw from Toffees midfielders Cleverley and Ross Barkley.\\nThe industrious Cleverley burst through before being brought down for Everton's penalty, while his delivery from corners was a constant threat and led to Coleman's goal.\\nBarkley's attacking instincts also played a part in the win and he could have had an assist when he crossed for Lukaku, whose header from close range was brilliantly saved by Butland.\\n\"I thought we were very strong in every department,\" said Martinez. \"Cleverley had a big influence in the game throughout.\"\\nStoke have endured a month to forget since their last league win against Norwich on 13 January.\\nMark Hughes' side have been knocked out the Capital One Cup after a semi-final defeat on penalties by Liverpool, while they were beaten by Crystal Palace in the FA Cup.\\nThe Potters have gained just one point from 12 in the league, dropping from seventh to 11th, and scored just one goal in six games.\\nThe home side gave a debut to record ¬£18.3m signing Gianelli Imbula but, like the rest of his team-mates, the midfielder struggled to make any kind of impact.\\n\"I thought Imbila did OK. I felt sorry for him because as a debut that was a hard one to come into,\" said Hughes.\\nStoke boss Mark Hughes: \"We huffed and puffed and didn't really create again and that is a concern for us.\\nMedia playback is not supported on this device\\n\"A disappointing day. We made mistakes at key times in the game and couldn't recover.\\n\"We have to pick ourselves up and start doing the fundamentals and basics.\"\\nEverton manager Roberto Martinez: \"We defended really well when we had to but the amount of opportunities we created is pleasing. If anything we should have scored three or four more in the second half.\\n\"We have to make sure we don't drop our standards now.\"\\nStoke's next game is at Bournemouth on 13 February, while Everton host West Brom on the same day with both games kicking off at 15:00 GMT.\\nMatch ends, Stoke City 0, Everton 3.\\nSecond Half ends, Stoke City 0, Everton 3.\\nAttempt saved. Mame Biram Diouf (Stoke City) header from the right side of the six yard box is saved in the centre of the goal. Assisted by Joselu with a cross.\\nFoul by Peter Odemwingie (Stoke City).\\nBryan Oviedo (Everton) wins a free kick on the left wing.\\nSubstitution, Everton. Leon Osman replaces James McCarthy.\\nCorner,  Everton. Conceded by Marc Muniesa.\\nSubstitution, Everton. Kevin Mirallas replaces Ross Barkley.\\nAttempt missed. Stephen Ireland (Stoke City) right footed shot from outside the box is too high. Assisted by Joselu.\\nCorner,  Stoke City. Conceded by Phil Jagielka.\\nOffside, Stoke City. Joselu tries a through ball, but Glen Johnson is caught offside.\\nAttempt missed. Ramiro Funes Mori (Everton) header from the centre of the box misses to the right. Assisted by Tom Cleverley with a cross.\\nCorner,  Everton. Conceded by Jack Butland.\\nAttempt saved. Arouna Kon√© (Everton) right footed shot from the centre of the box is saved in the bottom left corner. Assisted by Ross Barkley.\\nSubstitution, Stoke City. Joselu replaces Marko Arnautovic.\\nSubstitution, Everton. Arouna Kon√© replaces Romelu Lukaku.\\nGiannelli Imbula (Stoke City) wins a free kick in the defensive half.\\nFoul by Gareth Barry (Everton).\\nCorner,  Stoke City. Conceded by Ramiro Funes Mori.\\nAttempt blocked. Giannelli Imbula (Stoke City) left footed shot from the centre of the box is blocked. Assisted by Stephen Ireland.\\nAttempt blocked. Ross Barkley (Everton) right footed shot from the centre of the box is blocked. Assisted by Romelu Lukaku.\\nAttempt saved. Glen Johnson (Stoke City) left footed shot from outside the box is saved in the top centre of the goal. Assisted by Marko Arnautovic.\\nAttempt missed. James McCarthy (Everton) right footed shot from outside the box is close, but misses to the left. Assisted by Romelu Lukaku.\\nAttempt blocked. Ross Barkley (Everton) right footed shot from the left side of the box is blocked. Assisted by Romelu Lukaku.\\nAttempt blocked. Peter Odemwingie (Stoke City) left footed shot from the centre of the box is blocked.\\nOffside, Everton. Seamus Coleman tries a through ball, but Aaron Lennon is caught offside.\\nAttempt blocked. Ross Barkley (Everton) right footed shot from the left side of the box is blocked. Assisted by Gareth Barry with a cross.\\nAttempt saved. Romelu Lukaku (Everton) left footed shot from the centre of the box is saved in the centre of the goal.\\nAttempt blocked. Romelu Lukaku (Everton) left footed shot from the centre of the box is blocked. Assisted by Aaron Lennon.\\nSubstitution, Stoke City. Peter Odemwingie replaces Xherdan Shaqiri.\\nSubstitution, Stoke City. Stephen Ireland replaces Ibrahim Afellay.\\nXherdan Shaqiri (Stoke City) wins a free kick on the right wing.\\nFoul by Bryan Oviedo (Everton).\\nMame Biram Diouf (Stoke City) is shown the yellow card for a bad foul.\\nFoul by Mame Biram Diouf (Stoke City).\\nAaron Lennon (Everton) wins a free kick on the right wing.\\nAttempt saved. Romelu Lukaku (Everton) header from very close range is saved in the top centre of the goal. Assisted by Ross Barkley with a cross.\\nFoul by Erik Pieters (Stoke City).\\nSeamus Coleman (Everton) wins a free kick on the right wing.\\nCorner,  Stoke City. Conceded by Gareth Barry.</td>\n      <td>Everton moved up to seventh after beating Stoke, who suffered a third successive Premier League defeat.</td>\n      <td>35447704</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The large billboard on Warwick Road urged electors to vote for Cat Smith - Labour's candidate for Lancaster and Fleetwood, 70 miles away.\\nLabour's candidate for Carlisle is Lee Sherriff.\\nA Labour spokesman said the advertising company working for the Lancaster party branch had made the error.\\nThe spokesman said: \"This has now been removed. Carlisle Labour Party campaign were not involved in any way.\"\\nThe candidates for the Carlisle constituency are:\\nThe candidates for the Lancaster and Fleetwood constituency are:</td>\n      <td>Labour has admitted a mistake was made after a poster featuring the wrong election candidate was put up in Carlisle.</td>\n      <td>32333596</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The images capture everything from personal moments to be shared with friends and family to large public events, image curation on a global scale.\\nPenguin art director Jim Stoddart has pulled together a selection of those that caught his eye, for publication in a book.\\nLife on Instagram, curated by Jim Stoddart, is published by Particular Books.</td>\n      <td>Since its launch in 2010, the photo-sharing site Instagram has grown at a phenomenal rate, with nearly 100 million pictures and videos being posted everyday.</td>\n      <td>37230012</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Swiss, 32, broke Raonic in the first game and went on to win 6-4 6-4 6-4 in one hour and 42 minutes.\\nHe will take on top seed Novak Djokovic in Sunday's final, after  in four sets.\\nFederer is trying to win his 18th Grand Slam title, and his first since beating Andy Murray at Wimbledon in 2012.\\nFifteen years after making his first appearance at the All England Club, Federer has the chance to extend the record he has already set for major victories and break new ground for Wimbledon titles in the men's game.\\n\"That was a big victory,\" said the Swiss, who lost in the second round last year. \"I really had to focus on every point. I know that is always the case at this stage but it was hard.\\n\"I had to be very careful on my service games and I knew there were only going to be a few chances on his serve, but I am very, very happy.\\n\"I played some great tennis under pressure at times because I didn't play well here last year, and I expect a lot of myself. In the second week I have played better as the week has gone on.\\n\"Now I can look forward to another great match with Novak.\"\\nRaonic had made history just by reaching the last four, as the first Canadian man to do so, but suggestions the 23-year-old was ready to strike a blow for the younger generation proved misguided.\\nThe difference in experience was vast, with Federer playing in his 35th Grand Slam semi-final and unbeaten in eight previous Wimbledon semi-finals.\\nMoving superbly, attacking the net when possible and patiently waiting for his chances on the return, the Swiss looked as sharp as ever on the familiar ground of Centre Court.\\nRaonic topped the standings for aces going into the semi-final, hit the second-fastest serve of the tournament at 141mph and dropped serve just twice.\\nBut despite lacking his opponent's raw power, Federer had only been broken once and he offered up just a single break point as he dominated the match.\\nHe got a huge boost with an immediate break following a double fault and an error from Raonic, and calmly served his way out of trouble at 4-3 on his way to clinching the set.\\nThere was the expected flow of huge Raonic serves as the second set sped by, before Federer made his move at 4-4.\\nA sweeping backhand down the line put the pressure on at 0-30 and Raonic succumbed with a wayward smash, allowing Federer to arrow another backhand winner.\\nThe pattern repeated itself at 4-4 in the third, when Raonic opened with a double fault and soon found himself at 0-40, thumping a forehand over the baseline on the second break point.\\nFederer drew a gasp from the 15,000 spectators with an unexpectedly rash forehand drive-volley when trying to close out the match, but a forehand into the corner brought up match point and a big serve finished the job.</td>\n      <td>Seven-time champion Roger Federer dismantled the big-serving game of Canadian Milos Raonic to reach his ninth Wimbledon final.</td>\n      <td>28165048</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):","metadata":{"id":"lnjDIuQ3IrI-"}},{"cell_type":"code","source":"metric","metadata":{"id":"5o4rUteaIrI_","outputId":"18038ef5-554c-45c5-e00a-133b02ec10f1","execution":{"iopub.status.busy":"2024-02-18T19:58:41.577383Z","iopub.execute_input":"2024-02-18T19:58:41.578200Z","iopub.status.idle":"2024-02-18T19:58:41.590284Z","shell.execute_reply.started":"2024-02-18T19:58:41.578159Z","shell.execute_reply":"2024-02-18T19:58:41.588647Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\nCalculates average rouge scores for a list of hypotheses and references\nArgs:\n    predictions: list of predictions to score. Each prediction\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\n    rouge_types: A list of rouge types to calculate.\n        Valid names:\n        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n        `\"rougeL\"`: Longest common subsequence based scoring.\n        `\"rougeLsum\"`: rougeLsum splits text using `\"\n\"`.\n        See details in https://github.com/huggingface/datasets/issues/617\n    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n    use_aggregator: Return aggregates if this is set to True\nReturns:\n    rouge1: rouge_1 (f1),\n    rouge2: rouge_2 (f1),\n    rougeL: rouge_l (f1),\n    rougeLsum: rouge_lsum (f1)\nExamples:\n\n    >>> rouge = evaluate.load('rouge')\n    >>> predictions = [\"hello there\", \"general kenobi\"]\n    >>> references = [\"hello there\", \"general kenobi\"]\n    >>> results = rouge.compute(predictions=predictions, references=references)\n    >>> print(results)\n    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n\"\"\", stored examples: 0)"},"metadata":{}}]},{"cell_type":"markdown","source":"You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:","metadata":{"id":"jAWdqcUBIrJC"}},{"cell_type":"code","source":"fake_preds = [\"hello there\", \"general kenobi\"]\nfake_labels = [\"hello there\", \"general kenobi\"]\nmetric.compute(predictions=fake_preds, references=fake_labels)","metadata":{"id":"6XN1Rq0aIrJC","outputId":"a4405435-a8a9-41ff-9f79-a13077b587c7","execution":{"iopub.status.busy":"2024-02-18T19:45:37.297573Z","iopub.execute_input":"2024-02-18T19:45:37.297840Z","iopub.status.idle":"2024-02-18T19:45:37.524338Z","shell.execute_reply.started":"2024-02-18T19:45:37.297816Z","shell.execute_reply":"2024-02-18T19:45:37.523303Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2. Preprocessing the data","metadata":{"id":"n9qywopnIrJH"}},{"cell_type":"markdown","source":"Before we can feed those texts to our model, we need to preprocess them. This is done by a ü§ó Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n\nTo do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n\n- we get a tokenizer that corresponds to the model architecture we want to use,\n- we download the vocabulary used when pretraining this specific checkpoint.\n\nThat vocabulary will be cached, so it's not downloaded again the next time we run the cell.","metadata":{"id":"YVx71GdAIrJH"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"eXNLu_-nIrJI","execution":{"iopub.status.busy":"2024-02-18T19:45:37.525733Z","iopub.execute_input":"2024-02-18T19:45:37.526058Z","iopub.status.idle":"2024-02-18T19:45:38.758940Z","shell.execute_reply.started":"2024-02-18T19:45:37.526030Z","shell.execute_reply":"2024-02-18T19:45:38.758106Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7766f5f6fa049a2951232dd2ab80b3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7140c75576487f954c216694fce068"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0764fd5c1ae343e9a5fddbd944729fe6"}},"metadata":{}}]},{"cell_type":"markdown","source":"By default, the call above will use one of the fast tokenizers (backed by Rust) from the ü§ó Tokenizers library.","metadata":{"id":"Vl6IidfdIrJK"}},{"cell_type":"markdown","source":"You can directly call this tokenizer on one sentence or a pair of sentences:","metadata":{"id":"rowT4iCLIrJK"}},{"cell_type":"code","source":"tokenizer(\"Hello, this one sentence!\")","metadata":{"id":"a5hBlsrHIrJL","outputId":"acdaa98a-a8cd-4a20-89b8-cc26437bbe90","execution":{"iopub.status.busy":"2024-02-18T19:45:38.760241Z","iopub.execute_input":"2024-02-18T19:45:38.760592Z","iopub.status.idle":"2024-02-18T19:45:38.768509Z","shell.execute_reply.started":"2024-02-18T19:45:38.760558Z","shell.execute_reply":"2024-02-18T19:45:38.767627Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [8774, 6, 48, 80, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n\nInstead of one sentence, we can pass along a list of sentences:","metadata":{"id":"qo_0B1M2IrJM"}},{"cell_type":"code","source":"tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])","metadata":{"id":"xNYMeV6YlShO","outputId":"1bdaa13e-29f0-4bdb-b0e2-7e70ca2a032b","execution":{"iopub.status.busy":"2024-02-18T19:45:38.769604Z","iopub.execute_input":"2024-02-18T19:45:38.769886Z","iopub.status.idle":"2024-02-18T19:45:38.828793Z","shell.execute_reply.started":"2024-02-18T19:45:38.769860Z","shell.execute_reply":"2024-02-18T19:45:38.827838Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"markdown","source":"To prepare the targets for our model, we need to tokenize them using the `text_target` parameter. This will make sure the tokenizer uses the special tokens corresponding to the targets:","metadata":{"id":"eOFgvGJnlShO"}},{"cell_type":"code","source":"print(tokenizer(text_target=[\"Hello, this one sentence!\", \"This is another sentence.\"]))","metadata":{"id":"SGIcOD7JlShO","outputId":"00c6d6dd-bbbc-4f6a-afbb-82b49128bc4d","execution":{"iopub.status.busy":"2024-02-18T19:45:38.830030Z","iopub.execute_input":"2024-02-18T19:45:38.830384Z","iopub.status.idle":"2024-02-18T19:45:38.836471Z","shell.execute_reply.started":"2024-02-18T19:45:38.830350Z","shell.execute_reply":"2024-02-18T19:45:38.835488Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If you are using one of the five T5 checkpoints we have to prefix the inputs with \"summarize:\" (the model can also translate and it needs the prefix to know which task it has to perform).","metadata":{"id":"2C0hcmp9IrJQ"}},{"cell_type":"code","source":"if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n    prefix = \"summarize: \"\nelse:\n    prefix = \"\"","metadata":{"id":"ezYRLHEFlShP","execution":{"iopub.status.busy":"2024-02-18T19:45:38.837843Z","iopub.execute_input":"2024-02-18T19:45:38.838288Z","iopub.status.idle":"2024-02-18T19:45:38.846771Z","shell.execute_reply.started":"2024-02-18T19:45:38.838257Z","shell.execute_reply":"2024-02-18T19:45:38.845823Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset.","metadata":{"id":"5-eVO9dClShQ"}},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 128\n\ndef preprocess_function(examples):\n    inputs = [prefix + doc for doc in examples[\"document\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"vc0BSBLIIrJQ","execution":{"iopub.status.busy":"2024-02-18T19:45:38.847919Z","iopub.execute_input":"2024-02-18T19:45:38.848320Z","iopub.status.idle":"2024-02-18T19:45:38.857118Z","shell.execute_reply.started":"2024-02-18T19:45:38.848287Z","shell.execute_reply":"2024-02-18T19:45:38.856103Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:","metadata":{"id":"0lm8ozrJIrJR"}},{"cell_type":"code","source":"preprocess_function(raw_datasets['train'][:2])","metadata":{"id":"-b70jh26IrJS","outputId":"acd3a42d-985b-44ee-9daa-af5d944ce1d9","execution":{"iopub.status.busy":"2024-02-18T19:58:52.029810Z","iopub.execute_input":"2024-02-18T19:58:52.030485Z","iopub.status.idle":"2024-02-18T19:58:52.043294Z","shell.execute_reply.started":"2024-02-18T19:58:52.030452Z","shell.execute_reply":"2024-02-18T19:58:52.042228Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[21603, 10, 37, 423, 583, 13, 1783, 16, 20126, 16496, 6, 80, 13, 8, 844, 6025, 4161, 6, 19, 341, 271, 14841, 5, 7057, 161, 19, 4912, 16, 1626, 5981, 11, 186, 7540, 16, 1276, 15, 2296, 7, 5718, 2367, 14621, 4161, 57, 4125, 387, 5, 15059, 7, 30, 8, 4653, 4939, 711, 747, 522, 17879, 788, 12, 1783, 44, 8, 15763, 6029, 1813, 9, 7472, 5, 1404, 1623, 11, 5699, 277, 130, 4161, 57, 18368, 16, 20126, 16496, 227, 8, 2473, 5895, 15, 147, 89, 22411, 139, 8, 1511, 5, 1485, 3271, 3, 21926, 9, 472, 19623, 5251, 8, 616, 12, 15614, 8, 1783, 5, 37, 13818, 10564, 15, 26, 3, 9, 3, 19513, 1481, 6, 18368, 186, 1328, 2605, 30, 7488, 1887, 3, 18, 8, 711, 2309, 9517, 89, 355, 5, 3966, 1954, 9233, 15, 6, 113, 293, 7, 8, 16548, 13363, 106, 14022, 84, 47, 14621, 4161, 6, 243, 255, 228, 59, 7828, 8, 1249, 18, 545, 11298, 1773, 728, 8, 8347, 1560, 5, 611, 6, 255, 243, 72, 1709, 1528, 161, 228, 43, 118, 4006, 91, 12, 766, 8, 3, 19513, 1481, 410, 59, 5124, 5, 96, 196, 17, 19, 1256, 68, 27, 103, 317, 132, 19, 78, 231, 23546, 21, 970, 51, 89, 2593, 11, 8, 2504, 189, 3, 18, 11, 27, 3536, 3653, 24, 3, 18, 68, 34, 19, 966, 114, 62, 31, 60, 23708, 42, 11821, 976, 255, 243, 5, 96, 11880, 164, 59, 36, 1176, 68, 34, 19, 2361, 82, 3503, 147, 8, 336, 360, 477, 5, 96, 17891, 130, 25, 59, 1065, 12, 199, 178, 3, 9, 720, 72, 116, 8, 6337, 11, 8, 6196, 5685, 7, 141, 2767, 91, 4609, 7940, 6, 3, 9, 8347, 5685, 3048, 16, 286, 640, 8, 17600, 7, 250, 13, 8, 3917, 3412, 5, 1276, 15, 2296, 7, 47, 14621, 1560, 57, 982, 6, 13233, 53, 3088, 12, 4277, 72, 13613, 7, 16, 8, 616, 5, 12580, 17600, 7, 2063, 65, 474, 3, 9, 570, 30, 165, 475, 13, 8, 7540, 6025, 4161, 11, 3863, 43, 118, 3, 19492, 59, 12, 9751, 12493, 3957, 5, 37, 16117, 3450, 31, 7, 21108, 12580, 2488, 5104, 11768, 1306, 47, 16, 1626, 5981, 30, 2089, 12, 217, 8, 1419, 166, 609, 5, 216, 243, 34, 47, 359, 12, 129, 8, 8347, 1711, 515, 269, 68, 3, 9485, 3088, 12, 1634, 95, 8, 433, 5, 96, 196, 47, 882, 1026, 3, 9, 1549, 57, 8, 866, 13, 1783, 24, 65, 118, 612, 976, 3, 88, 243, 5, 96, 14116, 34, 19, 842, 18, 18087, 21, 151, 113, 43, 118, 5241, 91, 13, 70, 2503, 11, 8, 1113, 30, 1623, 535, 216, 243, 34, 47, 359, 24, 96, 603, 5700, 342, 2245, 121, 130, 1026, 12, 1822, 8, 844, 167, 9930, 11, 3, 9, 964, 97, 3869, 474, 16, 286, 21, 8347, 9793, 1390, 5, 2114, 25, 118, 4161, 57, 18368, 16, 970, 51, 89, 2593, 11, 10987, 32, 1343, 42, 8, 17600, 7, 58, 8779, 178, 81, 39, 351, 13, 8, 1419, 11, 149, 34, 47, 10298, 5, 8601, 178, 30, 142, 40, 157, 12546, 5, 15808, 1741, 115, 115, 75, 5, 509, 5, 1598, 42, 146, 51, 89, 2593, 1741, 115, 115, 75, 5, 509, 5, 1598, 5, 1], [21603, 10, 71, 1472, 6196, 877, 326, 44, 8, 9108, 86, 29, 16, 6000, 1887, 44, 81, 11484, 10, 1755, 272, 4209, 30, 1856, 11, 2554, 130, 1380, 12, 1175, 8, 1595, 5, 282, 79, 3, 9094, 1067, 79, 1509, 8, 192, 14264, 6, 3, 16669, 596, 18, 969, 18, 1583, 16, 8, 443, 2447, 6, 3, 35, 6106, 19565, 57, 12314, 7, 5, 555, 13, 8, 1552, 1637, 19, 45, 3434, 6, 8, 119, 45, 1473, 11, 14441, 5, 94, 47, 70, 166, 706, 16, 5961, 5316, 5, 37, 2535, 13, 80, 13, 8, 14264, 243, 186, 13, 8, 9234, 141, 646, 525, 12770, 7, 30, 1476, 11, 175, 141, 118, 10932, 5, 2867, 1637, 43, 13666, 3709, 11210, 11, 56, 1731, 70, 1552, 13, 8, 3457, 4939, 865, 145, 79, 141, 4355, 5, 5076, 43, 3958, 15, 26, 21, 251, 81, 8, 3211, 5, 86, 7, 102, 1955, 24723, 243, 10, 96, 196, 17, 3475, 38, 713, 8, 1472, 708, 365, 80, 13, 8, 14264, 274, 16436, 12, 8, 511, 5, 96, 27674, 8, 2883, 1137, 19, 341, 365, 4962, 6, 34, 19, 816, 24, 8, 1472, 47, 708, 24067, 535, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[7433, 18, 413, 2673, 33, 6168, 640, 8, 12580, 17600, 7, 11, 970, 51, 89, 2593, 11, 10987, 32, 1343, 227, 18368, 2953, 57, 16133, 4937, 5, 1], [2759, 8548, 14264, 43, 118, 10932, 57, 1472, 16, 3, 9, 18024, 1584, 739, 3211, 16, 27874, 690, 2050, 5, 1]]}"},"metadata":{}}]},{"cell_type":"markdown","source":"To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command.","metadata":{"id":"zS-6iXTkIrJT"}},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)","metadata":{"id":"DDtsaJeVIrJT","outputId":"aa4734bf-4ef5-4437-9948-2c16363da719","execution":{"iopub.status.busy":"2024-02-18T19:58:58.457093Z","iopub.execute_input":"2024-02-18T19:58:58.457494Z","iopub.status.idle":"2024-02-18T20:03:02.448527Z","shell.execute_reply.started":"2024-02-18T19:58:58.457465Z","shell.execute_reply":"2024-02-18T20:03:02.446259Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/205 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa230aeacdf0486292f704cb000f194c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc05566f92b469ca4ea04343f6d17ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c855458cca39449fb228267e203bac83"}},"metadata":{}}]},{"cell_type":"markdown","source":"Even better, the results are automatically cached by the ü§ó Datasets library to avoid spending time on this step the next time you run your notebook. The ü§ó Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ü§ó Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n\nNote that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently.","metadata":{"id":"voWiw8C7IrJV"}},{"cell_type":"markdown","source":"### 3. Fine-tuning the model","metadata":{"id":"545PP3o8IrJV"}},{"cell_type":"markdown","source":"Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us.","metadata":{"id":"FBiW8UpKIrJW"}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"id":"TlqNaB8jIrJW","execution":{"iopub.status.busy":"2024-02-18T20:03:02.450513Z","iopub.execute_input":"2024-02-18T20:03:02.451264Z","iopub.status.idle":"2024-02-18T20:03:03.192611Z","shell.execute_reply.started":"2024-02-18T20:03:02.451227Z","shell.execute_reply":"2024-02-18T20:03:03.191396Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case.","metadata":{"id":"CczA5lJlIrJX"}},{"cell_type":"markdown","source":"To instantiate a `Seq2SeqTrainer`, we will need to define three more things. The most important is the [`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:","metadata":{"id":"_N8urzhyIrJY"}},{"cell_type":"code","source":"batch_size = 16\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-xsum\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    fp16=True,\n)","metadata":{"id":"hWbWpRmXlShV","execution":{"iopub.status.busy":"2024-02-18T20:03:03.193965Z","iopub.execute_input":"2024-02-18T20:03:03.194312Z","iopub.status.idle":"2024-02-18T20:03:03.211558Z","shell.execute_reply.started":"2024-02-18T20:03:03.194282Z","shell.execute_reply":"2024-02-18T20:03:03.210243Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"id":"-X0pv2gAlShY","execution":{"iopub.status.busy":"2024-02-18T20:03:03.214458Z","iopub.execute_input":"2024-02-18T20:03:03.214889Z","iopub.status.idle":"2024-02-18T20:03:03.220987Z","shell.execute_reply.started":"2024-02-18T20:03:03.214841Z","shell.execute_reply":"2024-02-18T20:03:03.219795Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:","metadata":{"id":"7sZOdRlRIrJd"}},{"cell_type":"code","source":"import nltk\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n\n    # Note that other metrics may not have a `use_aggregator` parameter\n    # and thus will return a list, computing a metric for each sentence.\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    # Extract a few results\n    result = {key: value * 100 for key, value in result.items()}\n\n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"id":"UmvbnJ9JIrJd","execution":{"iopub.status.busy":"2024-02-18T20:03:03.222515Z","iopub.execute_input":"2024-02-18T20:03:03.222926Z","iopub.status.idle":"2024-02-18T20:03:03.235966Z","shell.execute_reply.started":"2024-02-18T20:03:03.222888Z","shell.execute_reply":"2024-02-18T20:03:03.234590Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:","metadata":{"id":"rXuFTAzDIrJe"}},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"id":"imY1oC3SIrJf","execution":{"iopub.status.busy":"2024-02-18T20:03:03.237558Z","iopub.execute_input":"2024-02-18T20:03:03.237935Z","iopub.status.idle":"2024-02-18T20:03:03.335039Z","shell.execute_reply.started":"2024-02-18T20:03:03.237903Z","shell.execute_reply":"2024-02-18T20:03:03.333799Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"We can now finetune our model by just calling the `train` method:","metadata":{"id":"CdzABDVcIrJg"}},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"uNx5pyRlIrJh","outputId":"077e661e-d36c-469b-89b8-7ff7f73541ec","execution":{"iopub.status.busy":"2024-02-18T20:03:03.336479Z","iopub.execute_input":"2024-02-18T20:03:03.336812Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='202' max='12753' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  202/12753 02:36 < 2:44:12, 1.27 it/s, Epoch 0.02/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"The training works, so we are not gonna train it to even a single epoch, cause it takes almost 3 hours for a single epoch.","metadata":{}}]}