{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "Here, I will show the example of how each module of the transformer works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.input_embedding import InputEmbeddings\n",
    "from modules.positional_encoding import PositionalEncoding\n",
    "from modules.layer_normalization import LayerNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. InputEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"My\", \"name\", \"is\", \"Suraj\", \".\"]\n",
    "token_with_ids = torch.tensor([11, 34, 56, 345, 342]) #consider\n",
    "seq_len = len(tokens)\n",
    "d_model = 512\n",
    "vocab_size = 1000 #assume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_with_ids.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_emb = InputEmbeddings(d_model,vocab_size)\n",
    "out = in_emb(token_with_ids.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.6234e-03,  1.0019e+01,  2.1082e+01,  ..., -4.7293e+01,\n",
      "          -8.4366e+00, -3.8666e+01],\n",
      "         [ 2.8218e+01,  2.8161e+01,  3.0798e+01,  ...,  2.5059e+01,\n",
      "           8.7762e+00, -3.4430e+01],\n",
      "         [-1.8044e+01,  3.1904e+00, -2.9956e+01,  ..., -1.0892e+01,\n",
      "           1.2342e+01, -2.1765e+01],\n",
      "         [ 3.8006e+01, -1.2280e+00,  1.0837e+01,  ...,  1.1567e+01,\n",
      "           2.6801e+01, -2.1436e+01],\n",
      "         [-6.9735e+00, -2.9129e+01,  4.5194e+00,  ...,  4.6453e+01,\n",
      "          -9.8099e+00, -5.3919e-01]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_emb = PositionalEncoding(d_model, seq_len, 0.4)\n",
    "out_p = po_emb(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.3724e-03,  1.8366e+01,  3.5137e+01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -6.2777e+01],\n",
      "         [ 4.8432e+01,  4.7836e+01,  5.2700e+01,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -5.5717e+01],\n",
      "         [-2.8558e+01,  0.0000e+00, -4.8366e+01,  ..., -1.6486e+01,\n",
      "           2.0570e+01, -3.4608e+01],\n",
      "         [ 0.0000e+00, -3.6966e+00,  1.8470e+01,  ...,  0.0000e+00,\n",
      "           4.4670e+01, -3.4060e+01],\n",
      "         [-1.2884e+01, -0.0000e+00,  6.4370e+00,  ...,  7.9088e+01,\n",
      "          -1.6349e+01,  7.6801e-01]]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "print(out_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
