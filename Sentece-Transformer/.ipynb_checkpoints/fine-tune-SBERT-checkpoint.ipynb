{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42194e70",
   "metadata": {},
   "source": [
    "# Fine-tune the SentenceBERT\n",
    "In this experiment, we gonna learn about SBERT and going to see a practical demonstration of finetuning a SBERT on a custom dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de497528",
   "metadata": {},
   "source": [
    "## SBERT\n",
    "- It is based on Siamese Neural Network.\n",
    "\n",
    "**Intuition**  \n",
    "- A siamese network is a class of neural network that contains two identical networks(the same configurations, same parameters and weights).\n",
    "- Parameter updating is mirrored across both networks.\n",
    "- Siamese nn find similarity of inputs by comparing its feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387a2e9",
   "metadata": {},
   "source": [
    "Let's understand the high-level overview of SBERT architecture.\n",
    "\n",
    "![Screenshot from 16-02-24 22:01:29](https://github.com/surajkarki66/shortIT/assets/50628520/f62a89c5-220c-4c63-bbd7-2486f60d35e8)\n",
    "\n",
    "- Sentence BERT uses pre-trained BERT networks and only fine tune it to yield useful sentence embeddings.\n",
    "- To fine-tune our model, we create Siamese networks (bi-encoder) to update the weights such that the produced sentence embeddings are semantically meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650372d",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d21b20",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
